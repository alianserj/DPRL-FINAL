{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defb1f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INIT] True sensor mode = chase_robot\n",
      "[INIT] Robot start = (10, 2) Sensor start = (2, 2) Goal = (1, 16)\n",
      "\n",
      "[INIT] Initial belief mode posterior: patrol_left:0.268 | random_walk:0.260 | patrol_mid:0.248 | chase_robot:0.224\n",
      "[INIT] Initial ESS: 250.0\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=0\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      "..S......#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..R...............\n",
      "..................\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(2, 3) (true sensor_pos=(2, 2))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(2, 3), time t=0\n",
      "[Belief] Prior mode posterior: patrol_left:0.268 | random_walk:0.260 | patrol_mid:0.248 | chase_robot:0.224\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: patrol_left:0.352 | patrol_mid:0.306 | random_walk:0.185 | chase_robot:0.157\n",
      "[Belief] Posterior ESS: 91.58/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: patrol_left:0.348 | patrol_mid:0.296 | chase_robot:0.184 | random_walk:0.172\n",
      "[Belief] Mode posterior top: patrol_left:0.348 | patrol_mid:0.296 | chase_robot:0.184\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(10, 2), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(3, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=41.989 expanded=116\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.774 expanded=114\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(2, 3), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.248 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.677 expanded=123\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(3, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.783 expanded=116\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.012 expanded=113\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(3, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=37.670 expanded=107\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.082 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(2, 3), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.238 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.039 expanded=119\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(2, 1), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=38.355 expanded=120\n",
      "[Modes]  Attempt 2: Path found len=24 cost=34.910 expanded=110\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(2, 3), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.163 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.247 expanded=121\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(2, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.999 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.494 expanded=123\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(2, 1), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=37.526 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=24 cost=35.885 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(2, 3), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=38.237 expanded=115\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.538 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(2, 3), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=37.900 expanded=115\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.644 expanded=122\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(2, 3), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=38.326 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=24 cost=38.572 expanded=115\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(3, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.797 expanded=113\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.059 expanded=115\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(2, 3), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.363 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=24 cost=41.189 expanded=124\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(2, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.266 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=24 cost=36.851 expanded=114\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(2, 3), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.958 expanded=124\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.797 expanded=119\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(3, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=44.635 expanded=125\n",
      "[Modes]  Attempt 2: Path found len=24 cost=43.926 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(1, 0), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=24 cost=34.828 expanded=113\n",
      "[Modes]  Attempt 2: Path found len=24 cost=35.119 expanded=121\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(1, 3), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.411 expanded=123\n",
      "[Modes]  Attempt 2: Path found len=24 cost=37.925 expanded=122\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(2, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.434 expanded=124\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.123 expanded=122\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(2, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=37.060 expanded=112\n",
      "[Modes]  Attempt 2: Path found len=24 cost=38.625 expanded=118\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(2, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.517 expanded=124\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.193 expanded=118\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(3, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.006 expanded=113\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.006 expanded=118\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(2, 3), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.069 expanded=120\n",
      "[Modes]  Attempt 2: Path found len=24 cost=38.465 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(1, 1), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=24 cost=35.464 expanded=113\n",
      "[Modes]  Attempt 2: Path found len=24 cost=35.944 expanded=116\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=34.828, hyp_sensor=(1, 0), hyp_mode=random_walk, path_len=24\n",
      "[Modes] Mode 1: cost=34.910, hyp_sensor=(2, 1), hyp_mode=patrol_left, path_len=24\n",
      "[Modes] Mode 2: cost=35.464, hyp_sensor=(1, 1), hyp_mode=random_walk, path_len=24\n",
      "[Modes] Mode 3: cost=37.526, hyp_sensor=(2, 1), hyp_mode=patrol_left, path_len=24\n",
      "[Modes] Mode 4: cost=39.783, hyp_sensor=(3, 2), hyp_mode=chase_robot, path_len=24\n",
      "[Modes] Mode 5: cost=40.677, hyp_sensor=(2, 3), hyp_mode=patrol_mid, path_len=24\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   1 Q= -25.941 P=0.020\n",
      "  a=D N=   3 Q= -24.191 P=0.020\n",
      "  a=L N=   4 Q= -22.815 P=0.020\n",
      "  a=R N= 241 Q= -17.517 P=0.920\n",
      "  a=S N=   1 Q= -24.874 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=R, moves (2, 2)->(2, 3)\n",
      "[STEP] Robot moves (10, 2)->(10, 3)\n",
      "[DETECT] p_det=0.191 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=1\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      "...S.....#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "...R..............\n",
      "..................\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(1, 5) (true sensor_pos=(2, 3))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(1, 5), time t=1\n",
      "[Belief] Prior mode posterior: patrol_left:0.348 | patrol_mid:0.296 | chase_robot:0.184 | random_walk:0.172\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: patrol_mid:0.498 | patrol_left:0.385 | random_walk:0.077 | chase_robot:0.039\n",
      "[Belief] Posterior ESS: 140.55/250\n",
      "[Belief] No resampling needed.\n",
      "[Belief] Mode posterior top: patrol_mid:0.498 | patrol_left:0.385 | random_walk:0.077\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(10, 3), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(2, 3), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=23 cost=36.877 expanded=111\n",
      "[Modes]  Attempt 2: Path found len=23 cost=38.117 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(2, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=40.705 expanded=123\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.303 expanded=122\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(2, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=23 cost=38.515 expanded=122\n",
      "[Modes]  Attempt 2: Path found len=23 cost=38.940 expanded=119\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(2, 4), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=23 cost=39.242 expanded=123\n",
      "[Modes]  Attempt 2: Path found len=23 cost=38.472 expanded=121\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(1, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=23 cost=36.111 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=23 cost=35.554 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(2, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=23 cost=35.794 expanded=109\n",
      "[Modes]  Attempt 2: Path found len=23 cost=35.372 expanded=110\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(2, 3), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=23 cost=37.251 expanded=116\n",
      "[Modes]  Attempt 2: Path found len=23 cost=38.013 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(2, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=38.288 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.488 expanded=118\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(2, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=23 cost=42.391 expanded=125\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.756 expanded=125\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(1, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=23 cost=37.649 expanded=121\n",
      "[Modes]  Attempt 2: Path found len=23 cost=36.063 expanded=119\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(2, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=38.726 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.035 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(2, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=23 cost=39.065 expanded=121\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.219 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(2, 3), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=23 cost=36.063 expanded=109\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.873 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(2, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=40.896 expanded=124\n",
      "[Modes]  Attempt 2: Path found len=23 cost=41.173 expanded=123\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(1, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=23 cost=38.152 expanded=122\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.341 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(3, 2), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=23 cost=35.825 expanded=107\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.208 expanded=112\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(2, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=37.335 expanded=112\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.930 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(2, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=37.911 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.622 expanded=124\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(2, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=23 cost=38.102 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.911 expanded=122\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(2, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=39.522 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=23 cost=38.757 expanded=119\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(2, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=38.246 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.501 expanded=123\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(3, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=37.611 expanded=108\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.585 expanded=112\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(1, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=36.724 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=23 cost=38.433 expanded=123\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(1, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=23 cost=35.155 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.672 expanded=122\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(2, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=23 cost=42.201 expanded=126\n",
      "[Modes]  Attempt 2: Path found len=23 cost=41.503 expanded=124\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=35.155, hyp_sensor=(1, 4), hyp_mode=patrol_mid, path_len=23\n",
      "[Modes] Mode 1: cost=35.372, hyp_sensor=(2, 3), hyp_mode=chase_robot, path_len=23\n",
      "[Modes] Mode 2: cost=36.111, hyp_sensor=(1, 3), hyp_mode=chase_robot, path_len=23\n",
      "[Modes] Mode 3: cost=36.877, hyp_sensor=(2, 3), hyp_mode=random_walk, path_len=23\n",
      "[Modes] Mode 4: cost=38.433, hyp_sensor=(1, 4), hyp_mode=patrol_left, path_len=23\n",
      "[Modes] Mode 5: cost=39.035, hyp_sensor=(2, 4), hyp_mode=patrol_left, path_len=23\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   1 Q= -32.320 P=0.020\n",
      "  a=D N= 242 Q= -16.251 P=0.020\n",
      "  a=L N=   2 Q= -24.680 P=0.020\n",
      "  a=R N=   1 Q= -32.320 P=0.920\n",
      "  a=S N=   4 Q= -25.228 P=0.020\n",
      "[MCTS-FIX] Chosen action = D\n",
      "\n",
      "[ACT] Robot takes action aR=D\n",
      "[ACT] True sensor action aS=D, moves (2, 3)->(3, 3)\n",
      "[STEP] Robot moves (10, 3)->(11, 3)\n",
      "[DETECT] p_det=0.191 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=2\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      "...S.....#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "...R..............\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(5, 5) (true sensor_pos=(3, 3))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(5, 5), time t=2\n",
      "[Belief] Prior mode posterior: patrol_mid:0.498 | patrol_left:0.385 | random_walk:0.077 | chase_robot:0.039\n",
      "[Belief] Prior ESS: 140.55/250\n",
      "[Belief] Posterior mode posterior: patrol_mid:0.599 | patrol_left:0.325 | random_walk:0.042 | chase_robot:0.033\n",
      "[Belief] Posterior ESS: 76.58/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: patrol_mid:0.612 | patrol_left:0.324 | random_walk:0.048 | chase_robot:0.016\n",
      "[Belief] Mode posterior top: patrol_mid:0.612 | patrol_left:0.324 | random_walk:0.048\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 3), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(2, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=42.475 expanded=126\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.147 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(2, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=41.611 expanded=121\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.545 expanded=118\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(1, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=37.645 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.479 expanded=127\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(3, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=42.749 expanded=116\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.015 expanded=107\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(2, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=38.642 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=24 cost=41.020 expanded=127\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(3, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=38.642 expanded=112\n",
      "[Modes]  Attempt 2: Path found len=24 cost=37.840 expanded=109\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(2, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.461 expanded=122\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.264 expanded=123\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(1, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.864 expanded=127\n",
      "[Modes]  Attempt 2: Path found len=24 cost=37.957 expanded=123\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(3, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=41.844 expanded=113\n",
      "[Modes]  Attempt 2: Path found len=24 cost=41.635 expanded=119\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(3, 5), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=24 cost=42.344 expanded=120\n",
      "[Modes]  Attempt 2: Path found len=24 cost=43.189 expanded=119\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(2, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.613 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=24 cost=42.121 expanded=124\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(3, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=42.033 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.302 expanded=113\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(3, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.325 expanded=109\n",
      "[Modes]  Attempt 2: Path found len=24 cost=42.785 expanded=118\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(3, 5), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=24 cost=42.350 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=24 cost=43.350 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(2, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.107 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=24 cost=38.570 expanded=115\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(3, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.626 expanded=115\n",
      "[Modes]  Attempt 2: Path found len=24 cost=41.111 expanded=115\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(3, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=44.706 expanded=123\n",
      "[Modes]  Attempt 2: Path found len=24 cost=41.251 expanded=115\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(3, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=43.655 expanded=116\n",
      "[Modes]  Attempt 2: Path found len=24 cost=43.322 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(2, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.987 expanded=122\n",
      "[Modes]  Attempt 2: Path found len=24 cost=41.858 expanded=123\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(2, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.568 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=24 cost=38.791 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(3, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=41.577 expanded=115\n",
      "[Modes]  Attempt 2: Path found len=24 cost=43.462 expanded=122\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(2, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.942 expanded=121\n",
      "[Modes]  Attempt 2: Path found len=24 cost=36.899 expanded=112\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(2, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.748 expanded=125\n",
      "[Modes]  Attempt 2: Path found len=24 cost=42.324 expanded=123\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(2, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.565 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.853 expanded=125\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(2, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.060 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.069 expanded=120\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=36.899, hyp_sensor=(2, 4), hyp_mode=patrol_mid, path_len=24\n",
      "[Modes] Mode 1: cost=37.645, hyp_sensor=(1, 5), hyp_mode=patrol_mid, path_len=24\n",
      "[Modes] Mode 2: cost=39.461, hyp_sensor=(2, 5), hyp_mode=patrol_mid, path_len=24\n",
      "[Modes] Mode 3: cost=39.568, hyp_sensor=(2, 4), hyp_mode=patrol_mid, path_len=24\n",
      "[Modes] Mode 4: cost=40.069, hyp_sensor=(2, 5), hyp_mode=patrol_left, path_len=24\n",
      "[Modes] Mode 5: cost=40.302, hyp_sensor=(3, 4), hyp_mode=patrol_mid, path_len=24\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   1 Q= -27.447 P=0.020\n",
      "  a=D N=   1 Q= -33.011 P=0.020\n",
      "  a=L N= 245 Q= -15.563 P=0.020\n",
      "  a=R N=   2 Q= -27.356 P=0.920\n",
      "  a=S N=   1 Q= -31.140 P=0.020\n",
      "[MCTS-FIX] Chosen action = L\n",
      "\n",
      "[ACT] Robot takes action aR=L\n",
      "[ACT] True sensor action aS=L, moves (3, 3)->(3, 2)\n",
      "[STEP] Robot moves (11, 3)->(11, 2)\n",
      "[DETECT] p_det=0.191 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=3\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      "..S......#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "..R...............\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(4, 4) (true sensor_pos=(3, 2))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(4, 4), time t=3\n",
      "[Belief] Prior mode posterior: patrol_mid:0.612 | patrol_left:0.324 | random_walk:0.048 | chase_robot:0.016\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: patrol_mid:0.589 | patrol_left:0.348 | random_walk:0.051 | chase_robot:0.013\n",
      "[Belief] Posterior ESS: 136.51/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: patrol_mid:0.588 | patrol_left:0.360 | random_walk:0.044 | chase_robot:0.008\n",
      "[Belief] Mode posterior top: patrol_mid:0.588 | patrol_left:0.360 | random_walk:0.044\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 2), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(3, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=45.676 expanded=123\n",
      "[Modes]  Attempt 2: Path found len=25 cost=46.306 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(3, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=45.251 expanded=123\n",
      "[Modes]  Attempt 2: Path found len=25 cost=44.391 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(4, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=47.609 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=25 cost=49.329 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(3, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=43.474 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=25 cost=45.628 expanded=123\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(4, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=49.030 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=25 cost=49.633 expanded=118\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=45.505 expanded=115\n",
      "[Modes]  Attempt 2: Path found len=25 cost=44.868 expanded=111\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(4, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=41.439 expanded=103\n",
      "[Modes]  Attempt 2: Path found len=25 cost=46.254 expanded=115\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(3, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=43.286 expanded=116\n",
      "[Modes]  Attempt 2: Path found len=25 cost=43.702 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(4, 6), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=48.079 expanded=123\n",
      "[Modes]  Attempt 2: Path found len=25 cost=49.093 expanded=126\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(3, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=45.509 expanded=122\n",
      "[Modes]  Attempt 2: Path found len=25 cost=45.922 expanded=128\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(4, 5), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=25 cost=46.535 expanded=113\n",
      "[Modes]  Attempt 2: Path found len=25 cost=49.854 expanded=119\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(4, 6), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=46.669 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=25 cost=49.721 expanded=131\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(3, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=47.331 expanded=123\n",
      "[Modes]  Attempt 2: Path found len=25 cost=46.407 expanded=122\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(4, 6), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=51.634 expanded=134\n",
      "[Modes]  Attempt 2: Path found len=25 cost=50.976 expanded=136\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(4, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=45.024 expanded=115\n",
      "[Modes]  Attempt 2: Path found len=25 cost=44.905 expanded=112\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(4, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=47.633 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=25 cost=47.083 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(4, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=48.625 expanded=121\n",
      "[Modes]  Attempt 2: Path found len=25 cost=48.748 expanded=121\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(3, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=43.704 expanded=121\n",
      "[Modes]  Attempt 2: Path found len=25 cost=44.575 expanded=118\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(4, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=47.447 expanded=121\n",
      "[Modes]  Attempt 2: Path found len=25 cost=44.654 expanded=109\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=45.781 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=25 cost=46.957 expanded=117\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(3, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=44.189 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=25 cost=43.002 expanded=118\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(4, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=46.675 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=25 cost=47.132 expanded=114\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=45.357 expanded=112\n",
      "[Modes]  Attempt 2: Path found len=25 cost=44.787 expanded=111\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(4, 4), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=46.804 expanded=115\n",
      "[Modes]  Attempt 2: Path found len=25 cost=47.123 expanded=117\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=46.157 expanded=114\n",
      "[Modes]  Attempt 2: Path found len=25 cost=46.258 expanded=117\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=41.439, hyp_sensor=(4, 4), hyp_mode=patrol_mid, path_len=25\n",
      "[Modes] Mode 1: cost=43.002, hyp_sensor=(3, 4), hyp_mode=patrol_left, path_len=25\n",
      "[Modes] Mode 2: cost=43.474, hyp_sensor=(3, 5), hyp_mode=patrol_mid, path_len=25\n",
      "[Modes] Mode 3: cost=45.357, hyp_sensor=(4, 4), hyp_mode=patrol_left, path_len=25\n",
      "[Modes] Mode 4: cost=46.157, hyp_sensor=(4, 4), hyp_mode=patrol_left, path_len=25\n",
      "[Modes] Mode 5: cost=47.132, hyp_sensor=(4, 4), hyp_mode=patrol_mid, path_len=25\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   1 Q= -31.085 P=0.020\n",
      "  a=D N=   1 Q= -28.322 P=0.020\n",
      "  a=L N=   1 Q= -28.079 P=0.020\n",
      "  a=R N=   1 Q= -40.049 P=0.920\n",
      "  a=S N= 246 Q= -15.052 P=0.020\n",
      "[MCTS-FIX] Chosen action = S\n",
      "\n",
      "[ACT] Robot takes action aR=S\n",
      "[ACT] True sensor action aS=D, moves (3, 2)->(4, 2)\n",
      "[STEP] Robot moves (11, 2)->(11, 2)\n",
      "[DETECT] p_det=0.240 => detected=True\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=4\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      "..S......#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "..R...............\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(5, 0) (true sensor_pos=(4, 2))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(5, 0), time t=4\n",
      "[Belief] Prior mode posterior: patrol_mid:0.588 | patrol_left:0.360 | random_walk:0.044 | chase_robot:0.008\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: patrol_left:0.595 | patrol_mid:0.257 | chase_robot:0.107 | random_walk:0.041\n",
      "[Belief] Posterior ESS: 71.18/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: patrol_left:0.584 | patrol_mid:0.260 | chase_robot:0.108 | random_walk:0.048\n",
      "[Belief] Mode posterior top: patrol_left:0.584 | patrol_mid:0.260 | chase_robot:0.108\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 2), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(2, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=38.831 expanded=112\n",
      "[Modes]  Attempt 2: Path found len=25 cost=41.151 expanded=123\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(4, 6), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=50.174 expanded=133\n",
      "[Modes]  Attempt 2: Path found len=25 cost=49.047 expanded=126\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(4, 5), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=25 cost=49.218 expanded=121\n",
      "[Modes]  Attempt 2: Path found len=25 cost=47.072 expanded=117\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(4, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=43.667 expanded=109\n",
      "[Modes]  Attempt 2: Path found len=25 cost=44.186 expanded=111\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(3, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=40.094 expanded=111\n",
      "[Modes]  Attempt 2: Path found len=25 cost=40.524 expanded=114\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(4, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=47.152 expanded=117\n",
      "[Modes]  Attempt 2: Path found len=25 cost=49.711 expanded=122\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(4, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=44.188 expanded=109\n",
      "[Modes]  Attempt 2: Path found len=25 cost=45.786 expanded=114\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(2, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=42.240 expanded=128\n",
      "[Modes]  Attempt 2: Path found len=25 cost=44.324 expanded=130\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(3, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=42.709 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=25 cost=41.977 expanded=118\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(2, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=42.055 expanded=128\n",
      "[Modes]  Attempt 2: Path found len=25 cost=42.304 expanded=124\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(3, 5), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=25 cost=44.318 expanded=120\n",
      "[Modes]  Attempt 2: Path found len=25 cost=46.175 expanded=126\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(3, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=39.657 expanded=113\n",
      "[Modes]  Attempt 2: Path found len=25 cost=40.091 expanded=113\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(4, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=43.950 expanded=109\n",
      "[Modes]  Attempt 2: Path found len=25 cost=44.041 expanded=107\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(4, 6), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=49.007 expanded=133\n",
      "[Modes]  Attempt 2: Path found len=25 cost=47.932 expanded=122\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(4, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=45.067 expanded=112\n",
      "[Modes]  Attempt 2: Path found len=25 cost=42.790 expanded=107\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(3, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=46.088 expanded=123\n",
      "[Modes]  Attempt 2: Path found len=25 cost=43.074 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(4, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=43.794 expanded=109\n",
      "[Modes]  Attempt 2: Path found len=25 cost=46.045 expanded=113\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(4, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=43.097 expanded=110\n",
      "[Modes]  Attempt 2: Path found len=25 cost=43.202 expanded=109\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(4, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=42.352 expanded=109\n",
      "[Modes]  Attempt 2: Path found len=25 cost=43.303 expanded=113\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(3, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=46.217 expanded=124\n",
      "[Modes]  Attempt 2: Path found len=25 cost=44.996 expanded=120\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(3, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=41.392 expanded=114\n",
      "[Modes]  Attempt 2: Path found len=25 cost=42.439 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(3, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=41.589 expanded=114\n",
      "[Modes]  Attempt 2: Path found len=25 cost=43.249 expanded=119\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(4, 4), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=25 cost=45.171 expanded=110\n",
      "[Modes]  Attempt 2: Path found len=25 cost=44.330 expanded=107\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(4, 7), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=25 cost=52.159 expanded=143\n",
      "[Modes]  Attempt 2: Path found len=25 cost=52.939 expanded=142\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(2, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=25 cost=37.439 expanded=112\n",
      "[Modes]  Attempt 2: Path found len=25 cost=37.684 expanded=115\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=37.439, hyp_sensor=(2, 2), hyp_mode=patrol_left, path_len=25\n",
      "[Modes] Mode 1: cost=37.684, hyp_sensor=(2, 2), hyp_mode=patrol_left, path_len=25\n",
      "[Modes] Mode 2: cost=39.657, hyp_sensor=(3, 2), hyp_mode=patrol_left, path_len=25\n",
      "[Modes] Mode 3: cost=40.094, hyp_sensor=(3, 2), hyp_mode=patrol_left, path_len=25\n",
      "[Modes] Mode 4: cost=41.589, hyp_sensor=(3, 3), hyp_mode=patrol_left, path_len=25\n",
      "[Modes] Mode 5: cost=43.303, hyp_sensor=(4, 3), hyp_mode=patrol_left, path_len=25\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   1 Q= -22.782 P=0.020\n",
      "  a=D N=   1 Q= -31.085 P=0.020\n",
      "  a=L N=   1 Q= -24.277 P=0.020\n",
      "  a=R N= 246 Q= -20.081 P=0.920\n",
      "  a=S N=   1 Q= -29.722 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=D, moves (4, 2)->(5, 2)\n",
      "[STEP] Robot moves (11, 2)->(11, 3)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=5\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "..S####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "...R..............\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(5, 0) (true sensor_pos=(5, 2))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(5, 0), time t=5\n",
      "[Belief] Prior mode posterior: patrol_left:0.584 | patrol_mid:0.260 | chase_robot:0.108 | random_walk:0.048\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:0.538 | patrol_left:0.394 | patrol_mid:0.041 | random_walk:0.027\n",
      "[Belief] Posterior ESS: 67.78/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:0.540 | patrol_left:0.404 | patrol_mid:0.032 | random_walk:0.024\n",
      "[Belief] Mode posterior top: chase_robot:0.540 | patrol_left:0.404 | patrol_mid:0.032\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 3), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=42.297 expanded=112\n",
      "[Modes]  Attempt 2: Path found len=24 cost=43.155 expanded=111\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(2, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=36.875 expanded=112\n",
      "[Modes]  Attempt 2: Path found len=24 cost=35.000 expanded=105\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(3, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=37.211 expanded=106\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.653 expanded=110\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(2, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=35.343 expanded=107\n",
      "[Modes]  Attempt 2: Path found len=24 cost=36.629 expanded=112\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(4, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.412 expanded=106\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.558 expanded=102\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(6, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=41.774 expanded=94\n",
      "[Modes]  Attempt 2: Path found len=24 cost=42.052 expanded=98\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=43.122 expanded=107\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.654 expanded=103\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(6, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=43.405 expanded=99\n",
      "[Modes]  Attempt 2: Path found len=24 cost=41.292 expanded=95\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(3, 5), mode=patrol_mid\n",
      "[Modes]  Attempt 1: Path found len=24 cost=43.414 expanded=119\n",
      "[Modes]  Attempt 2: Path found len=24 cost=41.855 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=42.490 expanded=113\n",
      "[Modes]  Attempt 2: Path found len=24 cost=41.136 expanded=106\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(6, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=42.621 expanded=94\n",
      "[Modes]  Attempt 2: Path found len=24 cost=44.920 expanded=107\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(6, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=42.956 expanded=95\n",
      "[Modes]  Attempt 2: Path found len=24 cost=43.433 expanded=100\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(2, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=36.562 expanded=112\n",
      "[Modes]  Attempt 2: Path found len=24 cost=35.652 expanded=110\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(4, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.711 expanded=100\n",
      "[Modes]  Attempt 2: Path found len=24 cost=41.399 expanded=105\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.728 expanded=104\n",
      "[Modes]  Attempt 2: Path found len=24 cost=43.697 expanded=110\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(3, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=38.425 expanded=110\n",
      "[Modes]  Attempt 2: Path found len=24 cost=38.422 expanded=108\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(5, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.888 expanded=102\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.152 expanded=101\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(6, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=42.145 expanded=95\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.403 expanded=96\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(3, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.418 expanded=112\n",
      "[Modes]  Attempt 2: Path found len=24 cost=41.060 expanded=116\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(4, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.355 expanded=105\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.623 expanded=101\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(5, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.263 expanded=98\n",
      "[Modes]  Attempt 2: Path found len=24 cost=39.410 expanded=98\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(6, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=40.398 expanded=94\n",
      "[Modes]  Attempt 2: Path found len=24 cost=42.290 expanded=96\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(5, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=39.284 expanded=96\n",
      "[Modes]  Attempt 2: Path found len=24 cost=40.497 expanded=101\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(6, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=44.081 expanded=99\n",
      "[Modes]  Attempt 2: Path found len=24 cost=42.492 expanded=98\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(5, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=24 cost=42.531 expanded=108\n",
      "[Modes]  Attempt 2: Path found len=24 cost=42.483 expanded=105\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=35.000, hyp_sensor=(2, 2), hyp_mode=patrol_left, path_len=24\n",
      "[Modes] Mode 1: cost=35.343, hyp_sensor=(2, 2), hyp_mode=patrol_left, path_len=24\n",
      "[Modes] Mode 2: cost=35.652, hyp_sensor=(2, 2), hyp_mode=patrol_left, path_len=24\n",
      "[Modes] Mode 3: cost=36.629, hyp_sensor=(2, 2), hyp_mode=patrol_left, path_len=24\n",
      "[Modes] Mode 4: cost=36.875, hyp_sensor=(2, 2), hyp_mode=patrol_left, path_len=24\n",
      "[Modes] Mode 5: cost=39.558, hyp_sensor=(4, 3), hyp_mode=chase_robot, path_len=24\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   5 Q= -30.934 P=0.020\n",
      "  a=D N=   6 Q= -30.325 P=0.020\n",
      "  a=L N=   1 Q= -40.505 P=0.020\n",
      "  a=R N= 237 Q= -25.829 P=0.920\n",
      "  a=S N=   1 Q= -33.348 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=D, moves (5, 2)->(6, 2)\n",
      "[STEP] Robot moves (11, 3)->(11, 4)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=6\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..S...............\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "....R.............\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(4, 4) (true sensor_pos=(6, 2))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(4, 4), time t=6\n",
      "[Belief] Prior mode posterior: chase_robot:0.540 | patrol_left:0.404 | patrol_mid:0.032 | random_walk:0.024\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: patrol_left:0.673 | chase_robot:0.238 | random_walk:0.047 | patrol_mid:0.042\n",
      "[Belief] Posterior ESS: 103.82/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: patrol_left:0.676 | chase_robot:0.240 | random_walk:0.044 | patrol_mid:0.040\n",
      "[Belief] Mode posterior top: patrol_left:0.676 | chase_robot:0.240 | random_walk:0.044\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 4), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=39.318 expanded=104\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.799 expanded=109\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(4, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=39.786 expanded=105\n",
      "[Modes]  Attempt 2: Path found len=23 cost=43.132 expanded=118\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=39.005 expanded=104\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.313 expanded=98\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(4, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=41.339 expanded=107\n",
      "[Modes]  Attempt 2: Path found len=23 cost=42.502 expanded=108\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(4, 6), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=45.677 expanded=118\n",
      "[Modes]  Attempt 2: Path found len=23 cost=42.531 expanded=112\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=41.220 expanded=111\n",
      "[Modes]  Attempt 2: Path found len=23 cost=40.030 expanded=101\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(4, 3), mode=random_walk\n",
      "[Modes]  Attempt 1: Path found len=23 cost=38.510 expanded=103\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.826 expanded=100\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=40.237 expanded=104\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.338 expanded=100\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=38.719 expanded=98\n",
      "[Modes]  Attempt 2: Path found len=23 cost=41.093 expanded=105\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(6, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=23 cost=40.895 expanded=88\n",
      "[Modes]  Attempt 2: Path found len=23 cost=41.945 expanded=95\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(4, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=23 cost=41.039 expanded=106\n",
      "[Modes]  Attempt 2: Path found len=23 cost=38.471 expanded=99\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(4, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=41.824 expanded=107\n",
      "[Modes]  Attempt 2: Path found len=23 cost=40.847 expanded=106\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(6, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=23 cost=42.211 expanded=93\n",
      "[Modes]  Attempt 2: Path found len=23 cost=40.132 expanded=91\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(3, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=39.355 expanded=115\n",
      "[Modes]  Attempt 2: Path found len=23 cost=38.966 expanded=111\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(3, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=37.816 expanded=107\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.975 expanded=106\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(3, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=36.756 expanded=104\n",
      "[Modes]  Attempt 2: Path found len=23 cost=36.785 expanded=102\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=39.669 expanded=100\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.442 expanded=97\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(4, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=44.045 expanded=115\n",
      "[Modes]  Attempt 2: Path found len=23 cost=44.100 expanded=115\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(3, 5), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=39.427 expanded=109\n",
      "[Modes]  Attempt 2: Path found len=23 cost=40.435 expanded=113\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(4, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=23 cost=41.840 expanded=110\n",
      "[Modes]  Attempt 2: Path found len=23 cost=39.977 expanded=103\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(3, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=37.707 expanded=106\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.610 expanded=106\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(4, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=40.447 expanded=106\n",
      "[Modes]  Attempt 2: Path found len=23 cost=38.438 expanded=100\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(3, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=38.622 expanded=106\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.903 expanded=105\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(4, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=38.404 expanded=101\n",
      "[Modes]  Attempt 2: Path found len=23 cost=36.103 expanded=91\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(3, 4), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=23 cost=37.433 expanded=108\n",
      "[Modes]  Attempt 2: Path found len=23 cost=37.941 expanded=106\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=36.103, hyp_sensor=(4, 3), hyp_mode=patrol_left, path_len=23\n",
      "[Modes] Mode 1: cost=36.756, hyp_sensor=(3, 3), hyp_mode=patrol_left, path_len=23\n",
      "[Modes] Mode 2: cost=37.313, hyp_sensor=(4, 4), hyp_mode=patrol_left, path_len=23\n",
      "[Modes] Mode 3: cost=37.610, hyp_sensor=(3, 4), hyp_mode=patrol_left, path_len=23\n",
      "[Modes] Mode 4: cost=37.903, hyp_sensor=(3, 4), hyp_mode=patrol_left, path_len=23\n",
      "[Modes] Mode 5: cost=39.005, hyp_sensor=(4, 4), hyp_mode=patrol_left, path_len=23\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   1 Q= -33.392 P=0.020\n",
      "  a=D N=   1 Q= -25.156 P=0.020\n",
      "  a=L N=   1 Q= -29.698 P=0.020\n",
      "  a=R N= 246 Q= -18.429 P=0.920\n",
      "  a=S N=   1 Q= -39.117 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=D, moves (6, 2)->(7, 2)\n",
      "[STEP] Robot moves (11, 4)->(11, 5)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=7\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      "..S......#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      ".....R............\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(8, 0) (true sensor_pos=(7, 2))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(8, 0), time t=7\n",
      "[Belief] Prior mode posterior: patrol_left:0.676 | chase_robot:0.240 | random_walk:0.044 | patrol_mid:0.040\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:0.643 | patrol_left:0.346 | random_walk:0.009 | patrol_mid:0.003\n",
      "[Belief] Posterior ESS: 38.62/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:0.648 | patrol_left:0.336 | random_walk:0.012 | patrol_mid:0.004\n",
      "[Belief] Mode posterior top: chase_robot:0.648 | patrol_left:0.336 | random_walk:0.012\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 5), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=38.793 expanded=80\n",
      "[Modes]  Attempt 2: Path found len=22 cost=39.200 expanded=79\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(6, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=41.489 expanded=88\n",
      "[Modes]  Attempt 2: Path found len=22 cost=40.959 expanded=86\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(7, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=36.566 expanded=80\n",
      "[Modes]  Attempt 2: Path found len=22 cost=38.390 expanded=84\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(7, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=35.392 expanded=84\n",
      "[Modes]  Attempt 2: Path found len=22 cost=37.008 expanded=86\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(4, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=22 cost=34.966 expanded=97\n",
      "[Modes]  Attempt 2: Path found len=22 cost=33.095 expanded=92\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(4, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=22 cost=34.568 expanded=91\n",
      "[Modes]  Attempt 2: Path found len=22 cost=33.951 expanded=89\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=39.515 expanded=82\n",
      "[Modes]  Attempt 2: Path found len=22 cost=38.900 expanded=85\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(7, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=37.400 expanded=86\n",
      "[Modes]  Attempt 2: Path found len=22 cost=36.673 expanded=84\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(4, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=39.585 expanded=107\n",
      "[Modes]  Attempt 2: Path found len=22 cost=37.755 expanded=98\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=38.055 expanded=81\n",
      "[Modes]  Attempt 2: Path found len=22 cost=37.661 expanded=79\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(7, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=37.454 expanded=87\n",
      "[Modes]  Attempt 2: Path found len=22 cost=36.765 expanded=82\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(4, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=22 cost=35.240 expanded=97\n",
      "[Modes]  Attempt 2: Path found len=22 cost=32.141 expanded=89\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(7, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=36.375 expanded=81\n",
      "[Modes]  Attempt 2: Path found len=22 cost=37.742 expanded=87\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=40.427 expanded=87\n",
      "[Modes]  Attempt 2: Path found len=22 cost=39.491 expanded=85\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(4, 3), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=22 cost=34.896 expanded=90\n",
      "[Modes]  Attempt 2: Path found len=22 cost=36.484 expanded=95\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=38.729 expanded=81\n",
      "[Modes]  Attempt 2: Path found len=22 cost=39.590 expanded=82\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(5, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=22 cost=33.326 expanded=87\n",
      "[Modes]  Attempt 2: Path found len=22 cost=34.775 expanded=91\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(4, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=22 cost=34.888 expanded=97\n",
      "[Modes]  Attempt 2: Path found len=22 cost=33.265 expanded=93\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=38.506 expanded=81\n",
      "[Modes]  Attempt 2: Path found len=22 cost=39.537 expanded=82\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(4, 1), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=22 cost=32.332 expanded=94\n",
      "[Modes]  Attempt 2: Path found len=22 cost=30.397 expanded=86\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(7, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=38.058 expanded=84\n",
      "[Modes]  Attempt 2: Path found len=22 cost=39.288 expanded=89\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=40.188 expanded=85\n",
      "[Modes]  Attempt 2: Path found len=22 cost=40.099 expanded=84\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(7, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=35.766 expanded=80\n",
      "[Modes]  Attempt 2: Path found len=22 cost=35.554 expanded=83\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=39.658 expanded=81\n",
      "[Modes]  Attempt 2: Path found len=22 cost=41.503 expanded=87\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(7, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=22 cost=36.220 expanded=81\n",
      "[Modes]  Attempt 2: Path found len=22 cost=36.583 expanded=86\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=30.397, hyp_sensor=(4, 1), hyp_mode=patrol_left, path_len=22\n",
      "[Modes] Mode 1: cost=32.141, hyp_sensor=(4, 2), hyp_mode=patrol_left, path_len=22\n",
      "[Modes] Mode 2: cost=33.095, hyp_sensor=(4, 2), hyp_mode=patrol_left, path_len=22\n",
      "[Modes] Mode 3: cost=33.265, hyp_sensor=(4, 2), hyp_mode=patrol_left, path_len=22\n",
      "[Modes] Mode 4: cost=34.568, hyp_sensor=(4, 3), hyp_mode=patrol_left, path_len=22\n",
      "[Modes] Mode 5: cost=36.765, hyp_sensor=(7, 2), hyp_mode=chase_robot, path_len=22\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=  15 Q= -31.078 P=0.020\n",
      "  a=D N=   3 Q= -31.812 P=0.020\n",
      "  a=L N=  23 Q= -31.031 P=0.020\n",
      "  a=R N= 158 Q= -28.001 P=0.920\n",
      "  a=S N=  51 Q= -30.986 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=D, moves (7, 2)->(8, 2)\n",
      "[STEP] Robot moves (11, 5)->(11, 6)\n",
      "[DETECT] p_det=0.240 => detected=True\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=8\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      "..S......#........\n",
      "..................\n",
      "..................\n",
      "......R...........\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(7, 0) (true sensor_pos=(8, 2))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(7, 0), time t=8\n",
      "[Belief] Prior mode posterior: chase_robot:0.648 | patrol_left:0.336 | random_walk:0.012 | patrol_mid:0.004\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:0.914 | patrol_left:0.083 | random_walk:0.003 | patrol_mid:0.000\n",
      "[Belief] Posterior ESS: 150.77/250\n",
      "[Belief] No resampling needed.\n",
      "[Belief] Mode posterior top: chase_robot:0.914 | patrol_left:0.083 | random_walk:0.003\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 6), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=34.351 expanded=73\n",
      "[Modes]  Attempt 2: Path found len=21 cost=38.863 expanded=80\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=37.426 expanded=83\n",
      "[Modes]  Attempt 2: Path found len=21 cost=34.345 expanded=78\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=39.242 expanded=80\n",
      "[Modes]  Attempt 2: Path found len=21 cost=35.398 expanded=75\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=35.969 expanded=83\n",
      "[Modes]  Attempt 2: Path found len=21 cost=35.648 expanded=80\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(3, 2), mode=patrol_left\n",
      "[Modes]  Attempt 1: Path found len=21 cost=31.421 expanded=91\n",
      "[Modes]  Attempt 2: Path found len=21 cost=30.500 expanded=89\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=34.995 expanded=81\n",
      "[Modes]  Attempt 2: Path found len=21 cost=35.423 expanded=81\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(7, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=36.240 expanded=70\n",
      "[Modes]  Attempt 2: Path found len=21 cost=38.981 expanded=76\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=35.948 expanded=77\n",
      "[Modes]  Attempt 2: Path found len=21 cost=34.766 expanded=80\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=35.393 expanded=80\n",
      "[Modes]  Attempt 2: Path found len=21 cost=36.620 expanded=81\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=36.080 expanded=79\n",
      "[Modes]  Attempt 2: Path found len=21 cost=34.934 expanded=74\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=35.129 expanded=71\n",
      "[Modes]  Attempt 2: Path found len=21 cost=35.410 expanded=77\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=35.686 expanded=81\n",
      "[Modes]  Attempt 2: Path found len=21 cost=37.160 expanded=79\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=36.403 expanded=79\n",
      "[Modes]  Attempt 2: Path found len=21 cost=34.091 expanded=75\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=37.303 expanded=84\n",
      "[Modes]  Attempt 2: Path found len=21 cost=35.885 expanded=78\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=39.708 expanded=82\n",
      "[Modes]  Attempt 2: Path found len=21 cost=37.292 expanded=75\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(9, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=36.629 expanded=80\n",
      "[Modes]  Attempt 2: Path found len=21 cost=37.383 expanded=82\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=37.785 expanded=76\n",
      "[Modes]  Attempt 2: Path found len=21 cost=37.225 expanded=76\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(7, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=40.093 expanded=77\n",
      "[Modes]  Attempt 2: Path found len=21 cost=39.242 expanded=73\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(6, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=37.078 expanded=85\n",
      "[Modes]  Attempt 2: Path found len=21 cost=36.259 expanded=82\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=34.693 expanded=79\n",
      "[Modes]  Attempt 2: Path found len=21 cost=34.518 expanded=79\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=32.924 expanded=73\n",
      "[Modes]  Attempt 2: Path found len=21 cost=37.421 expanded=84\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=34.541 expanded=81\n",
      "[Modes]  Attempt 2: Path found len=21 cost=35.825 expanded=81\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=37.735 expanded=77\n",
      "[Modes]  Attempt 2: Path found len=21 cost=37.576 expanded=73\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(7, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=36.156 expanded=79\n",
      "[Modes]  Attempt 2: Path found len=21 cost=37.153 expanded=79\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=21 cost=38.146 expanded=78\n",
      "[Modes]  Attempt 2: Path found len=21 cost=37.136 expanded=79\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=30.500, hyp_sensor=(3, 2), hyp_mode=patrol_left, path_len=21\n",
      "[Modes] Mode 1: cost=31.421, hyp_sensor=(3, 2), hyp_mode=patrol_left, path_len=21\n",
      "[Modes] Mode 2: cost=34.766, hyp_sensor=(8, 2), hyp_mode=chase_robot, path_len=21\n",
      "[Modes] Mode 3: cost=35.398, hyp_sensor=(8, 3), hyp_mode=chase_robot, path_len=21\n",
      "[Modes] Mode 4: cost=35.423, hyp_sensor=(8, 2), hyp_mode=chase_robot, path_len=21\n",
      "[Modes] Mode 5: cost=36.403, hyp_sensor=(7, 3), hyp_mode=chase_robot, path_len=21\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   1 Q= -26.476 P=0.020\n",
      "  a=D N=   2 Q= -26.665 P=0.020\n",
      "  a=L N=   1 Q= -27.379 P=0.020\n",
      "  a=R N= 245 Q= -23.971 P=0.920\n",
      "  a=S N=   1 Q= -37.300 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=R, moves (8, 2)->(8, 3)\n",
      "[STEP] Robot moves (11, 6)->(11, 7)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=9\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      "...S.....#........\n",
      "..................\n",
      "..................\n",
      ".......R..........\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(8, 2) (true sensor_pos=(8, 3))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(8, 2), time t=9\n",
      "[Belief] Prior mode posterior: chase_robot:0.914 | patrol_left:0.083 | random_walk:0.003 | patrol_mid:0.000\n",
      "[Belief] Prior ESS: 150.77/250\n",
      "[Belief] Posterior mode posterior: chase_robot:0.994 | patrol_left:0.004 | random_walk:0.001 | patrol_mid:0.000\n",
      "[Belief] Posterior ESS: 71.29/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:0.996 | patrol_left:0.004\n",
      "[Belief] Mode posterior top: chase_robot:0.996 | patrol_left:0.004\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 7), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=35.148 expanded=73\n",
      "[Modes]  Attempt 2: Path found len=20 cost=34.193 expanded=73\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(7, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=34.016 expanded=72\n",
      "[Modes]  Attempt 2: Path found len=20 cost=35.292 expanded=75\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(10, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=36.477 expanded=84\n",
      "[Modes]  Attempt 2: Path found len=20 cost=35.250 expanded=81\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(9, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=33.377 expanded=74\n",
      "[Modes]  Attempt 2: Path found len=20 cost=32.265 expanded=76\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=35.869 expanded=72\n",
      "[Modes]  Attempt 2: Path found len=20 cost=37.506 expanded=73\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=33.781 expanded=70\n",
      "[Modes]  Attempt 2: Path found len=20 cost=34.657 expanded=77\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=33.928 expanded=75\n",
      "[Modes]  Attempt 2: Path found len=20 cost=35.928 expanded=77\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=36.256 expanded=72\n",
      "[Modes]  Attempt 2: Path found len=20 cost=35.623 expanded=76\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=34.837 expanded=76\n",
      "[Modes]  Attempt 2: Path found len=20 cost=34.368 expanded=75\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=31.130 expanded=71\n",
      "[Modes]  Attempt 2: Path found len=20 cost=32.694 expanded=75\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(9, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=33.587 expanded=69\n",
      "[Modes]  Attempt 2: Path found len=20 cost=35.522 expanded=74\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=33.575 expanded=74\n",
      "[Modes]  Attempt 2: Path found len=20 cost=35.441 expanded=76\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(7, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=37.195 expanded=76\n",
      "[Modes]  Attempt 2: Path found len=20 cost=34.961 expanded=75\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=34.247 expanded=75\n",
      "[Modes]  Attempt 2: Path found len=20 cost=33.280 expanded=73\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(7, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=37.986 expanded=74\n",
      "[Modes]  Attempt 2: Path found len=20 cost=38.655 expanded=77\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=32.406 expanded=74\n",
      "[Modes]  Attempt 2: Path found len=20 cost=31.359 expanded=72\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(9, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=36.776 expanded=79\n",
      "[Modes]  Attempt 2: Path found len=20 cost=37.892 expanded=79\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(8, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=32.652 expanded=75\n",
      "[Modes]  Attempt 2: Path found len=20 cost=33.408 expanded=76\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(10, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=35.077 expanded=85\n",
      "[Modes]  Attempt 2: Path found len=20 cost=34.012 expanded=81\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=34.987 expanded=77\n",
      "[Modes]  Attempt 2: Path found len=20 cost=33.901 expanded=74\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(9, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=32.333 expanded=73\n",
      "[Modes]  Attempt 2: Path found len=20 cost=33.386 expanded=74\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(9, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=33.696 expanded=78\n",
      "[Modes]  Attempt 2: Path found len=20 cost=32.037 expanded=72\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=34.410 expanded=74\n",
      "[Modes]  Attempt 2: Path found len=20 cost=35.636 expanded=76\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=34.754 expanded=80\n",
      "[Modes]  Attempt 2: Path found len=20 cost=33.781 expanded=73\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=20 cost=35.806 expanded=76\n",
      "[Modes]  Attempt 2: Path found len=20 cost=35.205 expanded=76\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=31.130, hyp_sensor=(8, 2), hyp_mode=chase_robot, path_len=20\n",
      "[Modes] Mode 1: cost=31.359, hyp_sensor=(8, 2), hyp_mode=chase_robot, path_len=20\n",
      "[Modes] Mode 2: cost=32.406, hyp_sensor=(8, 2), hyp_mode=chase_robot, path_len=20\n",
      "[Modes] Mode 3: cost=33.575, hyp_sensor=(8, 3), hyp_mode=chase_robot, path_len=20\n",
      "[Modes] Mode 4: cost=34.012, hyp_sensor=(10, 2), hyp_mode=chase_robot, path_len=20\n",
      "[Modes] Mode 5: cost=34.410, hyp_sensor=(8, 3), hyp_mode=chase_robot, path_len=20\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   4 Q= -27.332 P=0.020\n",
      "  a=D N=   4 Q= -27.051 P=0.020\n",
      "  a=L N=   1 Q= -37.300 P=0.020\n",
      "  a=R N= 238 Q= -22.186 P=0.920\n",
      "  a=S N=   3 Q= -27.505 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=D, moves (8, 3)->(9, 3)\n",
      "[STEP] Robot moves (11, 7)->(11, 8)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=10\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "...S..............\n",
      "..................\n",
      "........R.........\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(8, 4) (true sensor_pos=(9, 3))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(8, 4), time t=10\n",
      "[Belief] Prior mode posterior: chase_robot:0.996 | patrol_left:0.004\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000 | patrol_left:0.000\n",
      "[Belief] Posterior ESS: 145.12/250\n",
      "[Belief] No resampling needed.\n",
      "[Belief] Mode posterior top: chase_robot:1.000 | patrol_left:0.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 8), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(9, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=31.608 expanded=71\n",
      "[Modes]  Attempt 2: Path found len=19 cost=30.712 expanded=74\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=33.792 expanded=70\n",
      "[Modes]  Attempt 2: Path found len=19 cost=33.557 expanded=68\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=34.534 expanded=72\n",
      "[Modes]  Attempt 2: Path found len=19 cost=34.507 expanded=67\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(9, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=33.415 expanded=71\n",
      "[Modes]  Attempt 2: Path found len=19 cost=32.382 expanded=72\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=34.160 expanded=72\n",
      "[Modes]  Attempt 2: Path found len=19 cost=32.333 expanded=67\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(8, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=36.407 expanded=62\n",
      "[Modes]  Attempt 2: Path found len=19 cost=36.399 expanded=65\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=35.856 expanded=75\n",
      "[Modes]  Attempt 2: Path found len=19 cost=35.094 expanded=67\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=31.953 expanded=65\n",
      "[Modes]  Attempt 2: Path found len=19 cost=33.134 expanded=70\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(9, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=31.189 expanded=73\n",
      "[Modes]  Attempt 2: Path found len=19 cost=30.758 expanded=73\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=33.531 expanded=69\n",
      "[Modes]  Attempt 2: Path found len=19 cost=34.926 expanded=71\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(9, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=32.102 expanded=70\n",
      "[Modes]  Attempt 2: Path found len=19 cost=31.794 expanded=69\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=32.945 expanded=69\n",
      "[Modes]  Attempt 2: Path found len=19 cost=33.933 expanded=68\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=32.610 expanded=68\n",
      "[Modes]  Attempt 2: Path found len=19 cost=33.574 expanded=70\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(9, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=32.274 expanded=72\n",
      "[Modes]  Attempt 2: Path found len=19 cost=32.100 expanded=70\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=31.962 expanded=62\n",
      "[Modes]  Attempt 2: Path found len=19 cost=34.616 expanded=72\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=33.481 expanded=69\n",
      "[Modes]  Attempt 2: Path found len=19 cost=33.428 expanded=70\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=34.120 expanded=73\n",
      "[Modes]  Attempt 2: Path found len=19 cost=33.205 expanded=72\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(10, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=32.426 expanded=73\n",
      "[Modes]  Attempt 2: Path found len=19 cost=31.465 expanded=73\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=32.279 expanded=69\n",
      "[Modes]  Attempt 2: Path found len=19 cost=33.989 expanded=70\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=32.184 expanded=67\n",
      "[Modes]  Attempt 2: Path found len=19 cost=32.597 expanded=66\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=35.162 expanded=69\n",
      "[Modes]  Attempt 2: Path found len=19 cost=35.006 expanded=68\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=34.857 expanded=67\n",
      "[Modes]  Attempt 2: Path found len=19 cost=33.522 expanded=66\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(10, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=35.437 expanded=70\n",
      "[Modes]  Attempt 2: Path found len=19 cost=34.961 expanded=69\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=31.541 expanded=68\n",
      "[Modes]  Attempt 2: Path found len=19 cost=35.415 expanded=74\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(8, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=19 cost=32.666 expanded=74\n",
      "[Modes]  Attempt 2: Path found len=19 cost=30.376 expanded=68\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=30.376, hyp_sensor=(8, 3), hyp_mode=chase_robot, path_len=19\n",
      "[Modes] Mode 1: cost=30.712, hyp_sensor=(9, 2), hyp_mode=chase_robot, path_len=19\n",
      "[Modes] Mode 2: cost=30.758, hyp_sensor=(9, 2), hyp_mode=chase_robot, path_len=19\n",
      "[Modes] Mode 3: cost=31.465, hyp_sensor=(10, 2), hyp_mode=chase_robot, path_len=19\n",
      "[Modes] Mode 4: cost=31.794, hyp_sensor=(9, 3), hyp_mode=chase_robot, path_len=19\n",
      "[Modes] Mode 5: cost=32.100, hyp_sensor=(9, 3), hyp_mode=chase_robot, path_len=19\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   5 Q= -29.537 P=0.020\n",
      "  a=D N=   3 Q= -29.492 P=0.020\n",
      "  a=L N=   1 Q= -26.476 P=0.020\n",
      "  a=R N= 240 Q= -22.728 P=0.920\n",
      "  a=S N=   1 Q= -28.537 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=D, moves (9, 3)->(10, 3)\n",
      "[STEP] Robot moves (11, 8)->(11, 9)\n",
      "[DETECT] p_det=0.240 => detected=True\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=11\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "...S..............\n",
      ".........R........\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(8, 2) (true sensor_pos=(10, 3))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(8, 2), time t=11\n",
      "[Belief] Prior mode posterior: chase_robot:1.000 | patrol_left:0.000\n",
      "[Belief] Prior ESS: 145.12/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000 | patrol_left:0.000\n",
      "[Belief] Posterior ESS: 127.17/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:1.000\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 9), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(8, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=31.899 expanded=60\n",
      "[Modes]  Attempt 2: Path found len=18 cost=32.991 expanded=63\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(10, 2), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=27.377 expanded=65\n",
      "[Modes]  Attempt 2: Path found len=18 cost=26.909 expanded=64\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(10, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=32.513 expanded=68\n",
      "[Modes]  Attempt 2: Path found len=18 cost=32.805 expanded=68\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(8, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=31.618 expanded=66\n",
      "[Modes]  Attempt 2: Path found len=18 cost=33.074 expanded=66\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(10, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=31.503 expanded=68\n",
      "[Modes]  Attempt 2: Path found len=18 cost=31.577 expanded=68\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=31.878 expanded=64\n",
      "[Modes]  Attempt 2: Path found len=18 cost=31.220 expanded=65\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=30.990 expanded=68\n",
      "[Modes]  Attempt 2: Path found len=18 cost=29.705 expanded=66\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(8, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=32.342 expanded=61\n",
      "[Modes]  Attempt 2: Path found len=18 cost=32.854 expanded=65\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=31.139 expanded=66\n",
      "[Modes]  Attempt 2: Path found len=18 cost=31.533 expanded=68\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(8, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=29.526 expanded=64\n",
      "[Modes]  Attempt 2: Path found len=18 cost=28.776 expanded=62\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=31.189 expanded=67\n",
      "[Modes]  Attempt 2: Path found len=18 cost=32.063 expanded=65\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=31.951 expanded=64\n",
      "[Modes]  Attempt 2: Path found len=18 cost=30.656 expanded=63\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=30.967 expanded=66\n",
      "[Modes]  Attempt 2: Path found len=18 cost=30.024 expanded=61\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(8, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=31.258 expanded=60\n",
      "[Modes]  Attempt 2: Path found len=18 cost=32.934 expanded=66\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(8, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=32.955 expanded=63\n",
      "[Modes]  Attempt 2: Path found len=18 cost=30.551 expanded=58\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(9, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=32.257 expanded=56\n",
      "[Modes]  Attempt 2: Path found len=18 cost=34.935 expanded=63\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=30.952 expanded=61\n",
      "[Modes]  Attempt 2: Path found len=18 cost=31.155 expanded=64\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=32.382 expanded=67\n",
      "[Modes]  Attempt 2: Path found len=18 cost=31.071 expanded=66\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=30.103 expanded=64\n",
      "[Modes]  Attempt 2: Path found len=18 cost=31.138 expanded=63\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=30.598 expanded=62\n",
      "[Modes]  Attempt 2: Path found len=18 cost=31.541 expanded=64\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(8, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=32.808 expanded=65\n",
      "[Modes]  Attempt 2: Path found len=18 cost=31.297 expanded=62\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=29.941 expanded=65\n",
      "[Modes]  Attempt 2: Path found len=18 cost=30.451 expanded=60\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=30.435 expanded=66\n",
      "[Modes]  Attempt 2: Path found len=18 cost=30.192 expanded=63\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=30.691 expanded=64\n",
      "[Modes]  Attempt 2: Path found len=18 cost=31.208 expanded=66\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(8, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=18 cost=32.282 expanded=60\n",
      "[Modes]  Attempt 2: Path found len=18 cost=33.160 expanded=63\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=26.909, hyp_sensor=(10, 2), hyp_mode=chase_robot, path_len=18\n",
      "[Modes] Mode 1: cost=27.377, hyp_sensor=(10, 2), hyp_mode=chase_robot, path_len=18\n",
      "[Modes] Mode 2: cost=29.526, hyp_sensor=(8, 4), hyp_mode=chase_robot, path_len=18\n",
      "[Modes] Mode 3: cost=30.024, hyp_sensor=(9, 4), hyp_mode=chase_robot, path_len=18\n",
      "[Modes] Mode 4: cost=30.967, hyp_sensor=(9, 4), hyp_mode=chase_robot, path_len=18\n",
      "[Modes] Mode 5: cost=31.220, hyp_sensor=(9, 4), hyp_mode=chase_robot, path_len=18\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.000 | D:0.000 | L:0.000 | R:1.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   5 Q= -24.964 P=0.020\n",
      "  a=D N=   1 Q= -27.866 P=0.020\n",
      "  a=L N=   1 Q= -31.215 P=0.020\n",
      "  a=R N= 235 Q= -22.246 P=0.920\n",
      "  a=S N=   8 Q= -25.097 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=D, moves (10, 3)->(11, 3)\n",
      "[STEP] Robot moves (11, 9)->(11, 10)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=12\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "...S......R.......\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(9, 4) (true sensor_pos=(11, 3))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(9, 4), time t=12\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 172.90/250\n",
      "[Belief] No resampling needed.\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 10), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(11, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=27.116 expanded=63\n",
      "[Modes]  Attempt 2: Path found len=17 cost=26.231 expanded=60\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(10, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=29.846 expanded=62\n",
      "[Modes]  Attempt 2: Path found len=17 cost=28.560 expanded=62\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=28.712 expanded=59\n",
      "[Modes]  Attempt 2: Path found len=17 cost=28.493 expanded=62\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(10, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=31.160 expanded=64\n",
      "[Modes]  Attempt 2: Path found len=17 cost=27.689 expanded=60\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(9, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=27.980 expanded=62\n",
      "[Modes]  Attempt 2: Path found len=17 cost=25.044 expanded=54\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(9, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=31.477 expanded=63\n",
      "[Modes]  Attempt 2: Path found len=17 cost=29.446 expanded=58\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(9, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=30.250 expanded=60\n",
      "[Modes]  Attempt 2: Path found len=17 cost=28.919 expanded=58\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=31.387 expanded=60\n",
      "[Modes]  Attempt 2: Path found len=17 cost=33.485 expanded=60\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=29.150 expanded=63\n",
      "[Modes]  Attempt 2: Path found len=17 cost=29.168 expanded=62\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(8, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=29.251 expanded=58\n",
      "[Modes]  Attempt 2: Path found len=17 cost=29.632 expanded=62\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(10, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=29.257 expanded=64\n",
      "[Modes]  Attempt 2: Path found len=17 cost=29.804 expanded=61\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(9, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=29.144 expanded=58\n",
      "[Modes]  Attempt 2: Path found len=17 cost=30.760 expanded=62\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=27.683 expanded=59\n",
      "[Modes]  Attempt 2: Path found len=17 cost=30.089 expanded=64\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=29.898 expanded=65\n",
      "[Modes]  Attempt 2: Path found len=17 cost=27.810 expanded=63\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(9, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=26.948 expanded=61\n",
      "[Modes]  Attempt 2: Path found len=17 cost=26.640 expanded=62\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(9, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=32.371 expanded=66\n",
      "[Modes]  Attempt 2: Path found len=17 cost=30.653 expanded=62\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(9, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=29.754 expanded=61\n",
      "[Modes]  Attempt 2: Path found len=17 cost=29.834 expanded=58\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=27.843 expanded=62\n",
      "[Modes]  Attempt 2: Path found len=17 cost=28.563 expanded=64\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=28.005 expanded=62\n",
      "[Modes]  Attempt 2: Path found len=17 cost=29.175 expanded=64\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(9, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=28.611 expanded=58\n",
      "[Modes]  Attempt 2: Path found len=17 cost=28.998 expanded=57\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(10, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=30.964 expanded=63\n",
      "[Modes]  Attempt 2: Path found len=17 cost=29.984 expanded=62\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=28.017 expanded=60\n",
      "[Modes]  Attempt 2: Path found len=17 cost=29.244 expanded=63\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(10, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=29.689 expanded=62\n",
      "[Modes]  Attempt 2: Path found len=17 cost=29.809 expanded=63\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(10, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=28.408 expanded=59\n",
      "[Modes]  Attempt 2: Path found len=17 cost=30.246 expanded=63\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(9, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=17 cost=29.001 expanded=63\n",
      "[Modes]  Attempt 2: Path found len=17 cost=28.965 expanded=63\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=25.044, hyp_sensor=(9, 3), hyp_mode=chase_robot, path_len=17\n",
      "[Modes] Mode 1: cost=26.231, hyp_sensor=(11, 3), hyp_mode=chase_robot, path_len=17\n",
      "[Modes] Mode 2: cost=26.948, hyp_sensor=(9, 3), hyp_mode=chase_robot, path_len=17\n",
      "[Modes] Mode 3: cost=27.116, hyp_sensor=(11, 3), hyp_mode=chase_robot, path_len=17\n",
      "[Modes] Mode 4: cost=27.810, hyp_sensor=(9, 4), hyp_mode=chase_robot, path_len=17\n",
      "[Modes] Mode 5: cost=28.712, hyp_sensor=(9, 4), hyp_mode=chase_robot, path_len=17\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.171 | D:0.000 | L:0.000 | R:0.829 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   1 Q= -26.476 P=0.174\n",
      "  a=D N=   3 Q= -23.511 P=0.020\n",
      "  a=L N=   2 Q= -24.437 P=0.020\n",
      "  a=R N= 243 Q= -21.883 P=0.766\n",
      "  a=S N=   1 Q= -22.634 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=R, moves (11, 3)->(11, 4)\n",
      "[STEP] Robot moves (11, 10)->(11, 11)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=13\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "....S......R......\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(11, 5) (true sensor_pos=(11, 4))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(11, 5), time t=13\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 172.90/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 141.89/250\n",
      "[Belief] No resampling needed.\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 11), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=27.403 expanded=60\n",
      "[Modes]  Attempt 2: Path found len=16 cost=27.802 expanded=56\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=29.059 expanded=56\n",
      "[Modes]  Attempt 2: Path found len=16 cost=28.249 expanded=57\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=29.130 expanded=65\n",
      "[Modes]  Attempt 2: Path found len=16 cost=28.032 expanded=56\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(9, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=26.875 expanded=56\n",
      "[Modes]  Attempt 2: Path found len=16 cost=27.023 expanded=56\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=27.476 expanded=56\n",
      "[Modes]  Attempt 2: Path found len=16 cost=27.531 expanded=59\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=29.024 expanded=58\n",
      "[Modes]  Attempt 2: Path found len=16 cost=26.747 expanded=57\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=28.079 expanded=59\n",
      "[Modes]  Attempt 2: Path found len=16 cost=28.835 expanded=58\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(11, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=25.994 expanded=59\n",
      "[Modes]  Attempt 2: Path found len=16 cost=25.592 expanded=58\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=26.787 expanded=55\n",
      "[Modes]  Attempt 2: Path found len=16 cost=28.969 expanded=59\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(11, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=25.850 expanded=58\n",
      "[Modes]  Attempt 2: Path found len=16 cost=26.429 expanded=55\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(10, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=27.684 expanded=61\n",
      "[Modes]  Attempt 2: Path found len=16 cost=27.646 expanded=58\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=27.642 expanded=59\n",
      "[Modes]  Attempt 2: Path found len=16 cost=27.562 expanded=54\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(11, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=25.421 expanded=60\n",
      "[Modes]  Attempt 2: Path found len=16 cost=26.648 expanded=57\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(11, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=26.366 expanded=59\n",
      "[Modes]  Attempt 2: Path found len=16 cost=25.416 expanded=59\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=27.478 expanded=55\n",
      "[Modes]  Attempt 2: Path found len=16 cost=27.851 expanded=60\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(11, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=25.512 expanded=54\n",
      "[Modes]  Attempt 2: Path found len=16 cost=25.097 expanded=54\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=28.403 expanded=57\n",
      "[Modes]  Attempt 2: Path found len=16 cost=27.435 expanded=55\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=27.625 expanded=56\n",
      "[Modes]  Attempt 2: Path found len=16 cost=27.090 expanded=58\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(10, 3), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=25.646 expanded=57\n",
      "[Modes]  Attempt 2: Path found len=16 cost=23.680 expanded=55\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=29.454 expanded=55\n",
      "[Modes]  Attempt 2: Path found len=16 cost=29.677 expanded=58\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=29.120 expanded=58\n",
      "[Modes]  Attempt 2: Path found len=16 cost=28.460 expanded=60\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(10, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=27.221 expanded=59\n",
      "[Modes]  Attempt 2: Path found len=16 cost=26.203 expanded=58\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(11, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=26.036 expanded=59\n",
      "[Modes]  Attempt 2: Path found len=16 cost=25.060 expanded=53\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=27.833 expanded=56\n",
      "[Modes]  Attempt 2: Path found len=16 cost=27.255 expanded=60\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(10, 4), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=16 cost=26.986 expanded=60\n",
      "[Modes]  Attempt 2: Path found len=16 cost=26.444 expanded=57\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=23.680, hyp_sensor=(10, 3), hyp_mode=chase_robot, path_len=16\n",
      "[Modes] Mode 1: cost=25.060, hyp_sensor=(11, 4), hyp_mode=chase_robot, path_len=16\n",
      "[Modes] Mode 2: cost=25.416, hyp_sensor=(11, 4), hyp_mode=chase_robot, path_len=16\n",
      "[Modes] Mode 3: cost=25.421, hyp_sensor=(11, 4), hyp_mode=chase_robot, path_len=16\n",
      "[Modes] Mode 4: cost=25.646, hyp_sensor=(10, 3), hyp_mode=chase_robot, path_len=16\n",
      "[Modes] Mode 5: cost=25.850, hyp_sensor=(11, 4), hyp_mode=chase_robot, path_len=16\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.330 | D:0.000 | L:0.000 | R:0.670 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=  14 Q= -23.120 P=0.317\n",
      "  a=D N=  11 Q= -22.911 P=0.020\n",
      "  a=L N=   1 Q= -25.429 P=0.020\n",
      "  a=R N= 219 Q= -22.434 P=0.623\n",
      "  a=S N=   5 Q= -23.042 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=R, moves (11, 4)->(11, 5)\n",
      "[STEP] Robot moves (11, 11)->(11, 12)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=14\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      ".....S......R.....\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(9, 7) (true sensor_pos=(11, 5))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(9, 7), time t=14\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 141.89/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 105.45/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:1.000\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 12), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=25.240 expanded=54\n",
      "[Modes]  Attempt 2: Path found len=15 cost=25.285 expanded=53\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=23.492 expanded=49\n",
      "[Modes]  Attempt 2: Path found len=15 cost=24.348 expanded=51\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=24.337 expanded=52\n",
      "[Modes]  Attempt 2: Path found len=15 cost=24.549 expanded=57\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(9, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=28.300 expanded=48\n",
      "[Modes]  Attempt 2: Path found len=15 cost=29.416 expanded=54\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=30.506 expanded=52\n",
      "[Modes]  Attempt 2: Path found len=15 cost=29.303 expanded=51\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=26.645 expanded=53\n",
      "[Modes]  Attempt 2: Path found len=15 cost=26.658 expanded=53\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=28.589 expanded=50\n",
      "[Modes]  Attempt 2: Path found len=15 cost=30.726 expanded=52\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=30.224 expanded=49\n",
      "[Modes]  Attempt 2: Path found len=15 cost=29.542 expanded=52\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=25.016 expanded=49\n",
      "[Modes]  Attempt 2: Path found len=15 cost=24.722 expanded=52\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=23.821 expanded=47\n",
      "[Modes]  Attempt 2: Path found len=15 cost=26.055 expanded=55\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=27.141 expanded=56\n",
      "[Modes]  Attempt 2: Path found len=15 cost=24.600 expanded=49\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=27.852 expanded=55\n",
      "[Modes]  Attempt 2: Path found len=15 cost=25.726 expanded=43\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=24.626 expanded=50\n",
      "[Modes]  Attempt 2: Path found len=15 cost=23.680 expanded=52\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=27.981 expanded=57\n",
      "[Modes]  Attempt 2: Path found len=15 cost=27.413 expanded=52\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=26.119 expanded=47\n",
      "[Modes]  Attempt 2: Path found len=15 cost=23.988 expanded=42\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=27.052 expanded=50\n",
      "[Modes]  Attempt 2: Path found len=15 cost=26.646 expanded=49\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(9, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=30.531 expanded=58\n",
      "[Modes]  Attempt 2: Path found len=15 cost=29.269 expanded=51\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=24.465 expanded=43\n",
      "[Modes]  Attempt 2: Path found len=15 cost=26.862 expanded=53\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=27.469 expanded=53\n",
      "[Modes]  Attempt 2: Path found len=15 cost=27.858 expanded=53\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=26.906 expanded=54\n",
      "[Modes]  Attempt 2: Path found len=15 cost=27.335 expanded=52\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=27.185 expanded=54\n",
      "[Modes]  Attempt 2: Path found len=15 cost=26.618 expanded=51\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=26.049 expanded=51\n",
      "[Modes]  Attempt 2: Path found len=15 cost=25.779 expanded=54\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=26.598 expanded=50\n",
      "[Modes]  Attempt 2: Path found len=15 cost=27.173 expanded=50\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=27.849 expanded=53\n",
      "[Modes]  Attempt 2: Path found len=15 cost=27.287 expanded=53\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=15 cost=28.482 expanded=53\n",
      "[Modes]  Attempt 2: Path found len=15 cost=28.198 expanded=54\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=23.492, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=15\n",
      "[Modes] Mode 1: cost=23.680, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=15\n",
      "[Modes] Mode 2: cost=23.821, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=15\n",
      "[Modes] Mode 3: cost=23.988, hyp_sensor=(9, 6), hyp_mode=chase_robot, path_len=15\n",
      "[Modes] Mode 4: cost=24.337, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=15\n",
      "[Modes] Mode 5: cost=25.016, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=15\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.664 | D:0.000 | L:0.000 | R:0.336 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=   7 Q= -24.957 P=0.617\n",
      "  a=D N=   6 Q= -23.333 P=0.020\n",
      "  a=L N=   2 Q= -25.238 P=0.020\n",
      "  a=R N= 233 Q= -23.008 P=0.323\n",
      "  a=S N=   2 Q= -24.222 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=R, moves (11, 5)->(11, 6)\n",
      "[STEP] Robot moves (11, 12)->(11, 13)\n",
      "[DETECT] p_det=0.240 => detected=True\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=15\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "......S......R....\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(11, 4) (true sensor_pos=(11, 6))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(11, 4), time t=15\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 127.29/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:1.000\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 13), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=22.032 expanded=46\n",
      "[Modes]  Attempt 2: Path found len=14 cost=22.101 expanded=47\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=21.214 expanded=46\n",
      "[Modes]  Attempt 2: Path found len=14 cost=21.283 expanded=44\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=22.974 expanded=42\n",
      "[Modes]  Attempt 2: Path found len=14 cost=23.573 expanded=43\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=22.524 expanded=45\n",
      "[Modes]  Attempt 2: Path found len=14 cost=22.331 expanded=45\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=23.038 expanded=46\n",
      "[Modes]  Attempt 2: Path found len=14 cost=23.353 expanded=42\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=23.329 expanded=46\n",
      "[Modes]  Attempt 2: Path found len=14 cost=23.331 expanded=47\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=23.441 expanded=45\n",
      "[Modes]  Attempt 2: Path found len=14 cost=23.363 expanded=47\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=22.894 expanded=46\n",
      "[Modes]  Attempt 2: Path found len=14 cost=23.764 expanded=46\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=25.177 expanded=46\n",
      "[Modes]  Attempt 2: Path found len=14 cost=25.573 expanded=49\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=24.899 expanded=45\n",
      "[Modes]  Attempt 2: Path found len=14 cost=26.443 expanded=49\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=22.019 expanded=48\n",
      "[Modes]  Attempt 2: Path found len=14 cost=21.523 expanded=44\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=21.455 expanded=44\n",
      "[Modes]  Attempt 2: Path found len=14 cost=22.023 expanded=46\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=27.132 expanded=50\n",
      "[Modes]  Attempt 2: Path found len=14 cost=24.845 expanded=42\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=20.842 expanded=42\n",
      "[Modes]  Attempt 2: Path found len=14 cost=22.741 expanded=48\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=22.569 expanded=46\n",
      "[Modes]  Attempt 2: Path found len=14 cost=22.148 expanded=45\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=24.183 expanded=48\n",
      "[Modes]  Attempt 2: Path found len=14 cost=22.604 expanded=43\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=21.141 expanded=45\n",
      "[Modes]  Attempt 2: Path found len=14 cost=22.672 expanded=47\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=24.838 expanded=47\n",
      "[Modes]  Attempt 2: Path found len=14 cost=23.978 expanded=43\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=24.852 expanded=48\n",
      "[Modes]  Attempt 2: Path found len=14 cost=23.935 expanded=45\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=23.150 expanded=42\n",
      "[Modes]  Attempt 2: Path found len=14 cost=23.688 expanded=45\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=24.287 expanded=47\n",
      "[Modes]  Attempt 2: Path found len=14 cost=24.121 expanded=48\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=28.145 expanded=47\n",
      "[Modes]  Attempt 2: Path found len=14 cost=28.333 expanded=45\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=21.520 expanded=42\n",
      "[Modes]  Attempt 2: Path found len=14 cost=23.043 expanded=42\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=22.121 expanded=44\n",
      "[Modes]  Attempt 2: Path found len=14 cost=22.709 expanded=49\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=14 cost=21.590 expanded=45\n",
      "[Modes]  Attempt 2: Path found len=14 cost=21.061 expanded=45\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=20.842, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=14\n",
      "[Modes] Mode 1: cost=21.061, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=14\n",
      "[Modes] Mode 2: cost=21.214, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=14\n",
      "[Modes] Mode 3: cost=22.101, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=14\n",
      "[Modes] Mode 4: cost=22.331, hyp_sensor=(11, 6), hyp_mode=chase_robot, path_len=14\n",
      "[Modes] Mode 5: cost=22.672, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=14\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.501 | D:0.000 | L:0.000 | R:0.499 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=  59 Q= -20.829 P=0.471\n",
      "  a=D N=  11 Q= -21.313 P=0.020\n",
      "  a=L N=   3 Q= -21.042 P=0.020\n",
      "  a=R N= 170 Q= -20.673 P=0.469\n",
      "  a=S N=   7 Q= -21.451 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=R, moves (11, 6)->(11, 7)\n",
      "[STEP] Robot moves (11, 13)->(11, 14)\n",
      "[DETECT] p_det=0.240 => detected=True\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=16\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      ".......S......R...\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(10, 5) (true sensor_pos=(11, 7))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(10, 5), time t=16\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 165.23/250\n",
      "[Belief] No resampling needed.\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 14), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=21.733 expanded=41\n",
      "[Modes]  Attempt 2: Path found len=13 cost=21.008 expanded=38\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=21.459 expanded=42\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.967 expanded=39\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=23.368 expanded=42\n",
      "[Modes]  Attempt 2: Path found len=13 cost=21.267 expanded=37\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=20.836 expanded=37\n",
      "[Modes]  Attempt 2: Path found len=13 cost=21.716 expanded=42\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=20.353 expanded=38\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.056 expanded=38\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=22.298 expanded=44\n",
      "[Modes]  Attempt 2: Path found len=13 cost=21.686 expanded=44\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=21.555 expanded=38\n",
      "[Modes]  Attempt 2: Path found len=13 cost=22.799 expanded=44\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=21.747 expanded=41\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.690 expanded=39\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=20.955 expanded=40\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.391 expanded=41\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=20.806 expanded=40\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.483 expanded=39\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=20.823 expanded=40\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.732 expanded=40\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=20.533 expanded=35\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.590 expanded=40\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=20.825 expanded=40\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.206 expanded=40\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=21.737 expanded=43\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.595 expanded=37\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=21.423 expanded=39\n",
      "[Modes]  Attempt 2: Path found len=13 cost=19.714 expanded=34\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(10, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=21.814 expanded=45\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.593 expanded=41\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=21.463 expanded=39\n",
      "[Modes]  Attempt 2: Path found len=13 cost=22.547 expanded=40\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=20.987 expanded=37\n",
      "[Modes]  Attempt 2: Path found len=13 cost=21.822 expanded=37\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(11, 5), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=19.188 expanded=35\n",
      "[Modes]  Attempt 2: Path found len=13 cost=19.157 expanded=36\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=21.667 expanded=38\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.987 expanded=39\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=20.140 expanded=38\n",
      "[Modes]  Attempt 2: Path found len=13 cost=20.396 expanded=40\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=24.834 expanded=40\n",
      "[Modes]  Attempt 2: Path found len=13 cost=26.080 expanded=42\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=23.282 expanded=38\n",
      "[Modes]  Attempt 2: Path found len=13 cost=23.565 expanded=42\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=24.080 expanded=43\n",
      "[Modes]  Attempt 2: Path found len=13 cost=22.949 expanded=44\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=13 cost=22.244 expanded=43\n",
      "[Modes]  Attempt 2: Path found len=13 cost=19.934 expanded=38\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=19.157, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=13\n",
      "[Modes] Mode 1: cost=19.188, hyp_sensor=(11, 5), hyp_mode=chase_robot, path_len=13\n",
      "[Modes] Mode 2: cost=19.714, hyp_sensor=(11, 6), hyp_mode=chase_robot, path_len=13\n",
      "[Modes] Mode 3: cost=19.934, hyp_sensor=(11, 6), hyp_mode=chase_robot, path_len=13\n",
      "[Modes] Mode 4: cost=20.206, hyp_sensor=(11, 6), hyp_mode=chase_robot, path_len=13\n",
      "[Modes] Mode 5: cost=21.686, hyp_sensor=(10, 6), hyp_mode=chase_robot, path_len=13\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.507 | D:0.000 | L:0.000 | R:0.493 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=  38 Q= -20.893 P=0.476\n",
      "  a=D N=  21 Q= -20.707 P=0.020\n",
      "  a=L N=   2 Q= -20.997 P=0.020\n",
      "  a=R N= 184 Q= -20.547 P=0.464\n",
      "  a=S N=   5 Q= -21.127 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=R, moves (11, 7)->(11, 8)\n",
      "[STEP] Robot moves (11, 14)->(11, 15)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=17\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "........S......R..\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(11, 6) (true sensor_pos=(11, 8))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(11, 6), time t=17\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 165.23/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 76.56/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:1.000\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(11, 15), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=21.060 expanded=33\n",
      "[Modes]  Attempt 2: Path found len=12 cost=21.157 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=19.734 expanded=37\n",
      "[Modes]  Attempt 2: Path found len=12 cost=20.020 expanded=36\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=18.937 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=12 cost=20.772 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=20.213 expanded=35\n",
      "[Modes]  Attempt 2: Path found len=12 cost=18.703 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=18.917 expanded=35\n",
      "[Modes]  Attempt 2: Path found len=12 cost=18.826 expanded=35\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=18.321 expanded=33\n",
      "[Modes]  Attempt 2: Path found len=12 cost=19.147 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=21.685 expanded=36\n",
      "[Modes]  Attempt 2: Path found len=12 cost=22.049 expanded=30\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=18.883 expanded=36\n",
      "[Modes]  Attempt 2: Path found len=12 cost=18.649 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=19.496 expanded=37\n",
      "[Modes]  Attempt 2: Path found len=12 cost=20.787 expanded=36\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=19.901 expanded=36\n",
      "[Modes]  Attempt 2: Path found len=12 cost=20.419 expanded=34\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=20.012 expanded=33\n",
      "[Modes]  Attempt 2: Path found len=12 cost=19.770 expanded=31\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=20.471 expanded=33\n",
      "[Modes]  Attempt 2: Path found len=12 cost=20.610 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=19.181 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=12 cost=21.089 expanded=37\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=20.087 expanded=36\n",
      "[Modes]  Attempt 2: Path found len=12 cost=19.086 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=18.783 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=12 cost=19.041 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=19.211 expanded=30\n",
      "[Modes]  Attempt 2: Path found len=12 cost=18.954 expanded=34\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=19.089 expanded=36\n",
      "[Modes]  Attempt 2: Path found len=12 cost=18.902 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=20.056 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=12 cost=21.140 expanded=31\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=20.639 expanded=33\n",
      "[Modes]  Attempt 2: Path found len=12 cost=20.586 expanded=34\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=20.349 expanded=34\n",
      "[Modes]  Attempt 2: Path found len=12 cost=19.733 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=17.896 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=12 cost=17.799 expanded=31\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=20.852 expanded=34\n",
      "[Modes]  Attempt 2: Path found len=12 cost=20.000 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=18.776 expanded=33\n",
      "[Modes]  Attempt 2: Path found len=12 cost=20.562 expanded=36\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(11, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=18.151 expanded=31\n",
      "[Modes]  Attempt 2: Path found len=12 cost=17.750 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=12 cost=19.476 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=12 cost=19.409 expanded=31\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=17.750, hyp_sensor=(11, 6), hyp_mode=chase_robot, path_len=12\n",
      "[Modes] Mode 1: cost=18.649, hyp_sensor=(11, 6), hyp_mode=chase_robot, path_len=12\n",
      "[Modes] Mode 2: cost=18.703, hyp_sensor=(11, 7), hyp_mode=chase_robot, path_len=12\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.672 | D:0.000 | L:0.000 | R:0.328 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N= 145 Q= -19.005 P=0.625\n",
      "  a=D N=   1 Q= -19.224 P=0.020\n",
      "  a=L N=   2 Q= -20.177 P=0.020\n",
      "  a=R N=  86 Q= -19.009 P=0.315\n",
      "  a=S N=  16 Q= -19.069 P=0.020\n",
      "[MCTS-FIX] Chosen action = U\n",
      "\n",
      "[ACT] Robot takes action aR=U\n",
      "[ACT] True sensor action aS=R, moves (11, 8)->(11, 9)\n",
      "[STEP] Robot moves (11, 15)->(10, 15)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=18\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "...............R..\n",
      ".........S........\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(11, 10) (true sensor_pos=(11, 9))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(11, 10), time t=18\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 140.60/250\n",
      "[Belief] No resampling needed.\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(10, 15), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.814 expanded=35\n",
      "[Modes]  Attempt 2: Path found len=11 cost=18.541 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.063 expanded=29\n",
      "[Modes]  Attempt 2: Path found len=11 cost=17.511 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(11, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=19.184 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=11 cost=18.811 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.256 expanded=31\n",
      "[Modes]  Attempt 2: Path found len=11 cost=19.817 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=17.287 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=11 cost=18.859 expanded=34\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.114 expanded=36\n",
      "[Modes]  Attempt 2: Path found len=11 cost=17.002 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(11, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=20.442 expanded=37\n",
      "[Modes]  Attempt 2: Path found len=11 cost=20.488 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.329 expanded=33\n",
      "[Modes]  Attempt 2: Path found len=11 cost=17.937 expanded=30\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=17.075 expanded=29\n",
      "[Modes]  Attempt 2: Path found len=11 cost=17.999 expanded=35\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=17.389 expanded=30\n",
      "[Modes]  Attempt 2: Path found len=11 cost=18.631 expanded=31\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(11, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=17.107 expanded=31\n",
      "[Modes]  Attempt 2: Path found len=11 cost=17.548 expanded=34\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=17.527 expanded=31\n",
      "[Modes]  Attempt 2: Path found len=11 cost=18.750 expanded=36\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(11, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=19.336 expanded=34\n",
      "[Modes]  Attempt 2: Path found len=11 cost=19.232 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.606 expanded=35\n",
      "[Modes]  Attempt 2: Path found len=11 cost=18.429 expanded=34\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(11, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.840 expanded=30\n",
      "[Modes]  Attempt 2: Path found len=11 cost=19.495 expanded=34\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=17.820 expanded=29\n",
      "[Modes]  Attempt 2: Path found len=11 cost=17.365 expanded=30\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.980 expanded=34\n",
      "[Modes]  Attempt 2: Path found len=11 cost=18.358 expanded=36\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(11, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.934 expanded=33\n",
      "[Modes]  Attempt 2: Path found len=11 cost=18.788 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.742 expanded=34\n",
      "[Modes]  Attempt 2: Path found len=11 cost=18.100 expanded=34\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(10, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=16.321 expanded=29\n",
      "[Modes]  Attempt 2: Path found len=11 cost=17.683 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.889 expanded=35\n",
      "[Modes]  Attempt 2: Path found len=11 cost=17.851 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=17.227 expanded=29\n",
      "[Modes]  Attempt 2: Path found len=11 cost=19.234 expanded=35\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=16.834 expanded=28\n",
      "[Modes]  Attempt 2: Path found len=11 cost=18.130 expanded=30\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(11, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=20.657 expanded=35\n",
      "[Modes]  Attempt 2: Path found len=11 cost=21.311 expanded=36\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=11 cost=18.803 expanded=33\n",
      "[Modes]  Attempt 2: Path found len=11 cost=18.940 expanded=35\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=16.321, hyp_sensor=(10, 6), hyp_mode=chase_robot, path_len=11\n",
      "[Modes] Mode 1: cost=17.075, hyp_sensor=(10, 7), hyp_mode=chase_robot, path_len=11\n",
      "[Modes] Mode 2: cost=17.527, hyp_sensor=(10, 7), hyp_mode=chase_robot, path_len=11\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.677 | D:0.000 | L:0.000 | R:0.323 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N= 197 Q= -16.304 P=0.630\n",
      "  a=D N=   2 Q= -20.650 P=0.020\n",
      "  a=L N=   1 Q= -24.429 P=0.020\n",
      "  a=R N=  49 Q= -16.358 P=0.310\n",
      "  a=S N=   1 Q= -19.224 P=0.020\n",
      "[MCTS-FIX] Chosen action = U\n",
      "\n",
      "[ACT] Robot takes action aR=U\n",
      "[ACT] True sensor action aS=U, moves (11, 9)->(10, 9)\n",
      "[STEP] Robot moves (10, 15)->(9, 15)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=19\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "...............R..\n",
      ".........S........\n",
      "..................\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(9, 8) (true sensor_pos=(10, 9))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(9, 8), time t=19\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 140.60/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 125.07/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:1.000\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(9, 15), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(11, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=15.844 expanded=25\n",
      "[Modes]  Attempt 2: Path found len=10 cost=17.262 expanded=29\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=15.413 expanded=28\n",
      "[Modes]  Attempt 2: Path found len=10 cost=14.958 expanded=27\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=17.243 expanded=33\n",
      "[Modes]  Attempt 2: Path found len=10 cost=17.709 expanded=33\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=17.379 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=10 cost=18.015 expanded=34\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=16.725 expanded=30\n",
      "[Modes]  Attempt 2: Path found len=10 cost=16.423 expanded=26\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=16.615 expanded=27\n",
      "[Modes]  Attempt 2: Path found len=10 cost=16.935 expanded=28\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(9, 6), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=15.724 expanded=28\n",
      "[Modes]  Attempt 2: Path found len=10 cost=14.883 expanded=24\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(11, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=15.763 expanded=27\n",
      "[Modes]  Attempt 2: Path found len=10 cost=15.722 expanded=25\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=16.055 expanded=27\n",
      "[Modes]  Attempt 2: Path found len=10 cost=15.572 expanded=27\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=17.633 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=10 cost=18.628 expanded=34\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=17.401 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=10 cost=17.281 expanded=31\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=17.689 expanded=31\n",
      "[Modes]  Attempt 2: Path found len=10 cost=18.524 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(11, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=16.931 expanded=29\n",
      "[Modes]  Attempt 2: Path found len=10 cost=16.344 expanded=27\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=18.595 expanded=34\n",
      "[Modes]  Attempt 2: Path found len=10 cost=17.165 expanded=30\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=18.736 expanded=36\n",
      "[Modes]  Attempt 2: Path found len=10 cost=17.657 expanded=30\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(10, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=15.389 expanded=28\n",
      "[Modes]  Attempt 2: Path found len=10 cost=15.363 expanded=27\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(10, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=16.992 expanded=26\n",
      "[Modes]  Attempt 2: Path found len=10 cost=17.163 expanded=29\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(10, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=18.135 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=10 cost=17.961 expanded=28\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=17.898 expanded=34\n",
      "[Modes]  Attempt 2: Path found len=10 cost=17.176 expanded=30\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(11, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=16.730 expanded=29\n",
      "[Modes]  Attempt 2: Path found len=10 cost=17.300 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=15.992 expanded=28\n",
      "[Modes]  Attempt 2: Path found len=10 cost=17.161 expanded=31\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=17.830 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=10 cost=17.453 expanded=32\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=16.183 expanded=28\n",
      "[Modes]  Attempt 2: Path found len=10 cost=16.423 expanded=29\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(9, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=16.090 expanded=30\n",
      "[Modes]  Attempt 2: Path found len=10 cost=15.861 expanded=28\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=10 cost=17.567 expanded=32\n",
      "[Modes]  Attempt 2: Path found len=10 cost=16.574 expanded=28\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=14.883, hyp_sensor=(9, 6), hyp_mode=chase_robot, path_len=10\n",
      "[Modes] Mode 1: cost=14.958, hyp_sensor=(11, 8), hyp_mode=chase_robot, path_len=10\n",
      "[Modes] Mode 2: cost=15.389, hyp_sensor=(10, 7), hyp_mode=chase_robot, path_len=10\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.662 | D:0.000 | L:0.000 | R:0.338 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N= 181 Q= -13.130 P=0.616\n",
      "  a=D N=   1 Q= -21.439 P=0.020\n",
      "  a=L N=   1 Q= -19.224 P=0.020\n",
      "  a=R N=  44 Q= -13.285 P=0.324\n",
      "  a=S N=  23 Q= -13.280 P=0.020\n",
      "[MCTS-FIX] Chosen action = U\n",
      "\n",
      "[ACT] Robot takes action aR=U\n",
      "[ACT] True sensor action aS=U, moves (10, 9)->(9, 9)\n",
      "[STEP] Robot moves (9, 15)->(8, 15)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=20\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#.....R..\n",
      ".........S........\n",
      "..................\n",
      "..................\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(7, 8) (true sensor_pos=(9, 9))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(7, 8), time t=20\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 122.83/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:1.000\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(8, 15), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=16.944 expanded=31\n",
      "[Modes]  Attempt 2: Path found len=9 cost=16.709 expanded=29\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(10, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=15.988 expanded=24\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.726 expanded=25\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=16.389 expanded=27\n",
      "[Modes]  Attempt 2: Path found len=9 cost=16.030 expanded=24\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(8, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=13.942 expanded=23\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.045 expanded=24\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=15.692 expanded=23\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.941 expanded=29\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(9, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=15.571 expanded=23\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.733 expanded=23\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=14.478 expanded=23\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.448 expanded=25\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=14.634 expanded=23\n",
      "[Modes]  Attempt 2: Path found len=9 cost=14.682 expanded=24\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(10, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=13.541 expanded=21\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.241 expanded=24\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=14.329 expanded=24\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.151 expanded=25\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(9, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=15.724 expanded=24\n",
      "[Modes]  Attempt 2: Path found len=9 cost=16.435 expanded=25\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=15.846 expanded=25\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.406 expanded=25\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=16.095 expanded=25\n",
      "[Modes]  Attempt 2: Path found len=9 cost=17.077 expanded=30\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(9, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=14.408 expanded=22\n",
      "[Modes]  Attempt 2: Path found len=9 cost=16.519 expanded=23\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=13.662 expanded=22\n",
      "[Modes]  Attempt 2: Path found len=9 cost=14.321 expanded=23\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=13.844 expanded=23\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.075 expanded=25\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(10, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=16.012 expanded=25\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.612 expanded=23\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=16.758 expanded=27\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.637 expanded=25\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(7, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=17.859 expanded=30\n",
      "[Modes]  Attempt 2: Path found len=9 cost=18.125 expanded=30\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=17.440 expanded=29\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.960 expanded=25\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=17.062 expanded=29\n",
      "[Modes]  Attempt 2: Path found len=9 cost=16.126 expanded=26\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=14.605 expanded=25\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.273 expanded=24\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=15.245 expanded=23\n",
      "[Modes]  Attempt 2: Path found len=9 cost=15.664 expanded=25\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=15.782 expanded=22\n",
      "[Modes]  Attempt 2: Path found len=9 cost=16.276 expanded=24\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(10, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=9 cost=14.014 expanded=24\n",
      "[Modes]  Attempt 2: Path found len=9 cost=13.931 expanded=24\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=13.541, hyp_sensor=(10, 9), hyp_mode=chase_robot, path_len=9\n",
      "[Modes] Mode 1: cost=13.844, hyp_sensor=(9, 8), hyp_mode=chase_robot, path_len=9\n",
      "[Modes] Mode 2: cost=15.241, hyp_sensor=(10, 9), hyp_mode=chase_robot, path_len=9\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.690 | D:0.000 | L:0.000 | R:0.310 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N= 160 Q=  -5.823 P=0.641\n",
      "  a=D N=   6 Q=  -7.810 P=0.020\n",
      "  a=L N=   4 Q=  -6.089 P=0.020\n",
      "  a=R N=  66 Q=  -5.772 P=0.299\n",
      "  a=S N=  14 Q=  -5.796 P=0.020\n",
      "[MCTS-FIX] Chosen action = U\n",
      "\n",
      "[ACT] Robot takes action aR=U\n",
      "[ACT] True sensor action aS=R, moves (9, 9)->(9, 10)\n",
      "[STEP] Robot moves (8, 15)->(7, 15)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=21\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#.....R..\n",
      ".........#........\n",
      "..........S.......\n",
      "..................\n",
      "..................\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(10, 8) (true sensor_pos=(9, 10))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(10, 8), time t=21\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 190.05/250\n",
      "[Belief] No resampling needed.\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(7, 15), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(8, 7), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=12.799 expanded=19\n",
      "[Modes]  Attempt 2: Path found len=8 cost=13.619 expanded=24\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=12.450 expanded=20\n",
      "[Modes]  Attempt 2: Path found len=8 cost=13.044 expanded=19\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=15.114 expanded=26\n",
      "[Modes]  Attempt 2: Path found len=8 cost=13.569 expanded=19\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=12.435 expanded=20\n",
      "[Modes]  Attempt 2: Path found len=8 cost=13.439 expanded=22\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(7, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=14.360 expanded=21\n",
      "[Modes]  Attempt 2: Path found len=8 cost=14.579 expanded=21\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(9, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=13.400 expanded=20\n",
      "[Modes]  Attempt 2: Path found len=8 cost=14.446 expanded=23\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(7, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=15.435 expanded=25\n",
      "[Modes]  Attempt 2: Path found len=8 cost=14.687 expanded=22\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=12.702 expanded=20\n",
      "[Modes]  Attempt 2: Path found len=8 cost=12.489 expanded=20\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(9, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=13.100 expanded=19\n",
      "[Modes]  Attempt 2: Path found len=8 cost=14.437 expanded=21\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(9, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=14.337 expanded=22\n",
      "[Modes]  Attempt 2: Path found len=8 cost=13.145 expanded=20\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=12.903 expanded=19\n",
      "[Modes]  Attempt 2: Path found len=8 cost=13.357 expanded=21\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=12.515 expanded=19\n",
      "[Modes]  Attempt 2: Path found len=8 cost=11.924 expanded=17\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=13.451 expanded=20\n",
      "[Modes]  Attempt 2: Path found len=8 cost=12.404 expanded=18\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(9, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=12.637 expanded=18\n",
      "[Modes]  Attempt 2: Path found len=8 cost=13.211 expanded=20\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(7, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=14.105 expanded=20\n",
      "[Modes]  Attempt 2: Path found len=8 cost=15.047 expanded=22\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(9, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=13.444 expanded=19\n",
      "[Modes]  Attempt 2: Path found len=8 cost=15.128 expanded=20\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(9, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=13.920 expanded=20\n",
      "[Modes]  Attempt 2: Path found len=8 cost=14.231 expanded=21\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=13.652 expanded=20\n",
      "[Modes]  Attempt 2: Path found len=8 cost=12.273 expanded=18\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=13.331 expanded=21\n",
      "[Modes]  Attempt 2: Path found len=8 cost=12.879 expanded=19\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(9, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=13.543 expanded=21\n",
      "[Modes]  Attempt 2: Path found len=8 cost=12.386 expanded=20\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(9, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=13.481 expanded=21\n",
      "[Modes]  Attempt 2: Path found len=8 cost=13.122 expanded=21\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=11.875 expanded=15\n",
      "[Modes]  Attempt 2: Path found len=8 cost=13.938 expanded=23\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(10, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=13.411 expanded=20\n",
      "[Modes]  Attempt 2: Path found len=8 cost=14.257 expanded=23\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=14.254 expanded=21\n",
      "[Modes]  Attempt 2: Path found len=8 cost=12.654 expanded=16\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(7, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=8 cost=14.051 expanded=21\n",
      "[Modes]  Attempt 2: Path found len=8 cost=14.416 expanded=20\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=11.875, hyp_sensor=(8, 8), hyp_mode=chase_robot, path_len=8\n",
      "[Modes] Mode 1: cost=11.924, hyp_sensor=(9, 8), hyp_mode=chase_robot, path_len=8\n",
      "[Modes] Mode 2: cost=13.357, hyp_sensor=(8, 8), hyp_mode=chase_robot, path_len=8\n",
      "\n",
      "[Prior] Derived action prior from modes: U:0.653 | D:0.000 | L:0.000 | R:0.347 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N=  92 Q=  -0.941 P=0.608\n",
      "  a=D N=   6 Q=  -5.578 P=0.020\n",
      "  a=L N=   4 Q=  -1.039 P=0.020\n",
      "  a=R N= 132 Q= +12.362 P=0.332\n",
      "  a=S N=  16 Q=  -0.883 P=0.020\n",
      "[MCTS-FIX] Chosen action = R\n",
      "\n",
      "[ACT] Robot takes action aR=R\n",
      "[ACT] True sensor action aS=U, moves (9, 10)->(8, 10)\n",
      "[STEP] Robot moves (7, 15)->(7, 16)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=22\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#......R.\n",
      ".........#S.......\n",
      "..................\n",
      "..................\n",
      "..................\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(8, 10) (true sensor_pos=(8, 10))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(8, 10), time t=22\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 190.05/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 115.08/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:1.000\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(7, 16), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(9, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=12.932 expanded=15\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.680 expanded=13\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=11.685 expanded=16\n",
      "[Modes]  Attempt 2: Path found len=7 cost=11.230 expanded=13\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(7, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=11.898 expanded=14\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.856 expanded=16\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(8, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=13.943 expanded=15\n",
      "[Modes]  Attempt 2: Path found len=7 cost=13.952 expanded=15\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(7, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=12.760 expanded=15\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.547 expanded=17\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(10, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=11.532 expanded=14\n",
      "[Modes]  Attempt 2: Path found len=7 cost=11.241 expanded=12\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(8, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=13.797 expanded=13\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.140 expanded=13\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(9, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=12.071 expanded=15\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.374 expanded=16\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(7, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=12.665 expanded=16\n",
      "[Modes]  Attempt 2: Path found len=7 cost=13.183 expanded=17\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(8, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=13.685 expanded=16\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.597 expanded=13\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(9, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=13.520 expanded=15\n",
      "[Modes]  Attempt 2: Path found len=7 cost=14.175 expanded=14\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(9, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=12.295 expanded=14\n",
      "[Modes]  Attempt 2: Path found len=7 cost=11.331 expanded=12\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(9, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=12.290 expanded=13\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.592 expanded=15\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(8, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=12.175 expanded=12\n",
      "[Modes]  Attempt 2: Path found len=7 cost=14.974 expanded=18\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(9, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=11.606 expanded=13\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.106 expanded=14\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(9, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=11.310 expanded=13\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.226 expanded=14\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(9, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=12.476 expanded=14\n",
      "[Modes]  Attempt 2: Path found len=7 cost=11.149 expanded=12\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(7, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=11.991 expanded=15\n",
      "[Modes]  Attempt 2: Path found len=7 cost=11.136 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(9, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=12.465 expanded=14\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.530 expanded=13\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(8, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=11.344 expanded=14\n",
      "[Modes]  Attempt 2: Path found len=7 cost=11.474 expanded=12\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(9, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=12.853 expanded=17\n",
      "[Modes]  Attempt 2: Path found len=7 cost=10.973 expanded=13\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(7, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=13.026 expanded=17\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.938 expanded=17\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(9, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=12.253 expanded=14\n",
      "[Modes]  Attempt 2: Path found len=7 cost=12.340 expanded=16\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(9, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=13.664 expanded=15\n",
      "[Modes]  Attempt 2: Path found len=7 cost=14.059 expanded=16\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(7, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=7 cost=16.494 expanded=19\n",
      "[Modes]  Attempt 2: Path found len=7 cost=13.888 expanded=16\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=10.973, hyp_sensor=(9, 10), hyp_mode=chase_robot, path_len=7\n",
      "\n",
      "[Prior] Derived action prior from modes: U:1.000 | D:0.000 | L:0.000 | R:0.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N= 250 Q= +23.669 P=0.920\n",
      "  a=D N=   0 Q=  +0.000 P=0.020\n",
      "  a=L N=   0 Q=  +0.000 P=0.020\n",
      "  a=R N=   0 Q=  +0.000 P=0.020\n",
      "  a=S N=   0 Q=  +0.000 P=0.020\n",
      "[MCTS-FIX] Chosen action = U\n",
      "\n",
      "[ACT] Robot takes action aR=U\n",
      "[ACT] True sensor action aS=U, moves (8, 10)->(7, 10)\n",
      "[STEP] Robot moves (7, 16)->(6, 16)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=23\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "................R.\n",
      ".........#S.......\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "..................\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(6, 11) (true sensor_pos=(7, 10))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(6, 11), time t=23\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 159.06/250\n",
      "[Belief] No resampling needed.\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(6, 16), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(6, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=10.858 expanded=13\n",
      "[Modes]  Attempt 2: Path found len=6 cost=10.118 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(8, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=10.482 expanded=12\n",
      "[Modes]  Attempt 2: Path found len=6 cost=10.423 expanded=10\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(8, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=10.705 expanded=12\n",
      "[Modes]  Attempt 2: Path found len=6 cost=10.704 expanded=12\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(8, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=13.924 expanded=14\n",
      "[Modes]  Attempt 2: Path found len=6 cost=12.449 expanded=13\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(6, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=10.193 expanded=11\n",
      "[Modes]  Attempt 2: Path found len=6 cost=11.164 expanded=12\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(7, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=11.605 expanded=11\n",
      "[Modes]  Attempt 2: Path found len=6 cost=11.671 expanded=12\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(9, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=11.300 expanded=14\n",
      "[Modes]  Attempt 2: Path found len=6 cost=9.730 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(9, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=9.330 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=6 cost=9.552 expanded=10\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(7, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=13.147 expanded=12\n",
      "[Modes]  Attempt 2: Path found len=6 cost=13.515 expanded=13\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(7, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=10.908 expanded=12\n",
      "[Modes]  Attempt 2: Path found len=6 cost=11.122 expanded=10\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(7, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=12.893 expanded=12\n",
      "[Modes]  Attempt 2: Path found len=6 cost=11.460 expanded=9\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(7, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=12.998 expanded=13\n",
      "[Modes]  Attempt 2: Path found len=6 cost=13.022 expanded=13\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(7, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=12.681 expanded=11\n",
      "[Modes]  Attempt 2: Path found len=6 cost=13.218 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(7, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=11.420 expanded=13\n",
      "[Modes]  Attempt 2: Path found len=6 cost=12.014 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(8, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=10.261 expanded=10\n",
      "[Modes]  Attempt 2: Path found len=6 cost=10.220 expanded=10\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(7, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=12.454 expanded=13\n",
      "[Modes]  Attempt 2: Path found len=6 cost=12.870 expanded=14\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(9, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=11.519 expanded=13\n",
      "[Modes]  Attempt 2: Path found len=6 cost=9.968 expanded=10\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(8, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=11.237 expanded=11\n",
      "[Modes]  Attempt 2: Path found len=6 cost=10.887 expanded=12\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(9, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=10.213 expanded=10\n",
      "[Modes]  Attempt 2: Path found len=6 cost=10.041 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(9, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=11.878 expanded=13\n",
      "[Modes]  Attempt 2: Path found len=6 cost=11.282 expanded=12\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(8, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=10.636 expanded=10\n",
      "[Modes]  Attempt 2: Path found len=6 cost=10.881 expanded=13\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(9, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=9.635 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=6 cost=10.620 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(8, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=11.199 expanded=11\n",
      "[Modes]  Attempt 2: Path found len=6 cost=10.939 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(7, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=10.506 expanded=11\n",
      "[Modes]  Attempt 2: Path found len=6 cost=12.172 expanded=10\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(6, 8), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=6 cost=10.183 expanded=11\n",
      "[Modes]  Attempt 2: Path found len=6 cost=11.676 expanded=12\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=9.330, hyp_sensor=(9, 10), hyp_mode=chase_robot, path_len=6\n",
      "\n",
      "[Prior] Derived action prior from modes: U:1.000 | D:0.000 | L:0.000 | R:0.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N= 250 Q= +26.606 P=0.920\n",
      "  a=D N=   0 Q=  +0.000 P=0.020\n",
      "  a=L N=   0 Q=  +0.000 P=0.020\n",
      "  a=R N=   0 Q=  +0.000 P=0.020\n",
      "  a=S N=   0 Q=  +0.000 P=0.020\n",
      "[MCTS-FIX] Chosen action = U\n",
      "\n",
      "[ACT] Robot takes action aR=U\n",
      "[ACT] True sensor action aS=U, moves (7, 10)->(6, 10)\n",
      "[STEP] Robot moves (6, 16)->(5, 16)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=24\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######.R.\n",
      "..........S.......\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "..................\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(6, 9) (true sensor_pos=(6, 10))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(6, 9), time t=24\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 159.06/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 91.83/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:1.000\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(5, 16), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=10.020 expanded=11\n",
      "[Modes]  Attempt 2: Path found len=5 cost=8.705 expanded=8\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=8.569 expanded=8\n",
      "[Modes]  Attempt 2: Path found len=5 cost=7.894 expanded=6\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=11.250 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=5 cost=11.336 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=8.856 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=5 cost=9.419 expanded=10\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(7, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=10.391 expanded=10\n",
      "[Modes]  Attempt 2: Path found len=5 cost=9.405 expanded=9\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(8, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=8.247 expanded=7\n",
      "[Modes]  Attempt 2: Path found len=5 cost=7.505 expanded=6\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=9.141 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=5 cost=7.971 expanded=6\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=8.751 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=5 cost=7.921 expanded=6\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(8, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=9.137 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=5 cost=9.410 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=8.704 expanded=7\n",
      "[Modes]  Attempt 2: Path found len=5 cost=9.869 expanded=10\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=8.194 expanded=8\n",
      "[Modes]  Attempt 2: Path found len=5 cost=9.922 expanded=9\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=11.485 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=5 cost=12.669 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(6, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=9.067 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=5 cost=9.184 expanded=7\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=9.258 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=5 cost=8.876 expanded=7\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=9.140 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=5 cost=8.778 expanded=8\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(7, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=9.103 expanded=7\n",
      "[Modes]  Attempt 2: Path found len=5 cost=10.235 expanded=9\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=9.387 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=5 cost=7.634 expanded=5\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=7.954 expanded=6\n",
      "[Modes]  Attempt 2: Path found len=5 cost=8.743 expanded=8\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=8.860 expanded=9\n",
      "[Modes]  Attempt 2: Path found len=5 cost=9.813 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=8.424 expanded=8\n",
      "[Modes]  Attempt 2: Path found len=5 cost=8.738 expanded=8\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(7, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=9.280 expanded=10\n",
      "[Modes]  Attempt 2: Path found len=5 cost=9.058 expanded=11\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(6, 9), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=8.189 expanded=8\n",
      "[Modes]  Attempt 2: Path found len=5 cost=8.717 expanded=9\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(8, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=8.314 expanded=7\n",
      "[Modes]  Attempt 2: Path found len=5 cost=9.436 expanded=10\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(6, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=9.099 expanded=7\n",
      "[Modes]  Attempt 2: Path found len=5 cost=9.600 expanded=8\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(6, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=5 cost=11.344 expanded=11\n",
      "[Modes]  Attempt 2: Path found len=5 cost=9.971 expanded=9\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=7.505, hyp_sensor=(8, 10), hyp_mode=chase_robot, path_len=5\n",
      "\n",
      "[Prior] Derived action prior from modes: U:1.000 | D:0.000 | L:0.000 | R:0.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N= 250 Q= +31.326 P=0.920\n",
      "  a=D N=   0 Q=  +0.000 P=0.020\n",
      "  a=L N=   0 Q=  +0.000 P=0.020\n",
      "  a=R N=   0 Q=  +0.000 P=0.020\n",
      "  a=S N=   0 Q=  +0.000 P=0.020\n",
      "[MCTS-FIX] Chosen action = U\n",
      "\n",
      "[ACT] Robot takes action aR=U\n",
      "[ACT] True sensor action aS=R, moves (6, 10)->(6, 11)\n",
      "[STEP] Robot moves (5, 16)->(4, 16)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=25\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#......R.\n",
      "...####.#######...\n",
      "...........S......\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "..................\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(6, 13) (true sensor_pos=(6, 11))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(6, 13), time t=25\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 141.20/250\n",
      "[Belief] No resampling needed.\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(4, 16), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(6, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=5.964 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=4 cost=6.490 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(7, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.635 expanded=7\n",
      "[Modes]  Attempt 2: Path found len=4 cost=6.342 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(7, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=8.338 expanded=6\n",
      "[Modes]  Attempt 2: Path found len=4 cost=6.824 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(6, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=9.388 expanded=7\n",
      "[Modes]  Attempt 2: Path found len=4 cost=8.122 expanded=5\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(7, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=8.766 expanded=8\n",
      "[Modes]  Attempt 2: Path found len=4 cost=7.877 expanded=6\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(6, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=8.081 expanded=8\n",
      "[Modes]  Attempt 2: Path found len=4 cost=7.171 expanded=5\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(6, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=8.501 expanded=5\n",
      "[Modes]  Attempt 2: Path found len=4 cost=9.069 expanded=6\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(6, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=6.705 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=4 cost=6.869 expanded=5\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.299 expanded=5\n",
      "[Modes]  Attempt 2: Path found len=4 cost=7.409 expanded=5\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(7, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.181 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=4 cost=7.479 expanded=6\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(6, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.006 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=4 cost=6.617 expanded=5\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.594 expanded=5\n",
      "[Modes]  Attempt 2: Path found len=4 cost=7.945 expanded=6\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(6, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.358 expanded=5\n",
      "[Modes]  Attempt 2: Path found len=4 cost=6.873 expanded=5\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=9.158 expanded=6\n",
      "[Modes]  Attempt 2: Path found len=4 cost=11.198 expanded=8\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(6, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=6.388 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=4 cost=7.486 expanded=6\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(7, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=6.875 expanded=6\n",
      "[Modes]  Attempt 2: Path found len=4 cost=6.320 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(6, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.889 expanded=7\n",
      "[Modes]  Attempt 2: Path found len=4 cost=6.790 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.744 expanded=5\n",
      "[Modes]  Attempt 2: Path found len=4 cost=7.260 expanded=5\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(6, 10), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.133 expanded=5\n",
      "[Modes]  Attempt 2: Path found len=4 cost=6.300 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(7, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.202 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=4 cost=7.620 expanded=6\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(6, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=8.345 expanded=6\n",
      "[Modes]  Attempt 2: Path found len=4 cost=9.317 expanded=8\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.508 expanded=7\n",
      "[Modes]  Attempt 2: Path found len=4 cost=7.962 expanded=5\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.627 expanded=6\n",
      "[Modes]  Attempt 2: Path found len=4 cost=7.739 expanded=6\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=6.897 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=4 cost=6.919 expanded=5\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=4 cost=7.167 expanded=5\n",
      "[Modes]  Attempt 2: Path found len=4 cost=6.678 expanded=4\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=5.964, hyp_sensor=(6, 10), hyp_mode=chase_robot, path_len=4\n",
      "\n",
      "[Prior] Derived action prior from modes: U:1.000 | D:0.000 | L:0.000 | R:0.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N= 250 Q= +34.660 P=0.920\n",
      "  a=D N=   0 Q=  +0.000 P=0.020\n",
      "  a=L N=   0 Q=  +0.000 P=0.020\n",
      "  a=R N=   0 Q=  +0.000 P=0.020\n",
      "  a=S N=   0 Q=  +0.000 P=0.020\n",
      "[MCTS-FIX] Chosen action = U\n",
      "\n",
      "[ACT] Robot takes action aR=U\n",
      "[ACT] True sensor action aS=R, moves (6, 11)->(6, 12)\n",
      "[STEP] Robot moves (4, 16)->(3, 16)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=26\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#......R.\n",
      ".........#........\n",
      "...####.#######...\n",
      "............S.....\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "..................\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(5, 14) (true sensor_pos=(6, 12))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(5, 14), time t=26\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 141.20/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 44.25/250\n",
      "[Belief] ESS below threshold (0.55 * N). Resampling...\n",
      "[Belief] After resample mode posterior: chase_robot:1.000\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(3, 16), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=6.919 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=3 cost=5.579 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=4.895 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=4.580 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(7, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=6.086 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=3 cost=5.242 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=4.642 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=4.681 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(6, 14), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=6.836 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=6.547 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=5.414 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=3 cost=4.010 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=6.636 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=6.088 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=6.747 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=3 cost=6.411 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(6, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=5.186 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=4.990 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(6, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=5.074 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=5.003 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=4.323 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=5.269 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(6, 15), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=8.271 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=3 cost=9.118 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(6, 14), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=8.257 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=3 cost=7.840 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=5.454 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=5.687 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=5.022 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=4.786 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=7.246 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=3 cost=6.167 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=5.740 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=6.555 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=5.900 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=3 cost=6.190 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(6, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=5.668 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=6.282 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=6.848 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=6.405 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(6, 14), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=8.762 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=3 cost=7.535 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(6, 11), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=5.077 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=5.411 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(7, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=5.200 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=5.469 expanded=3\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=6.783 expanded=4\n",
      "[Modes]  Attempt 2: Path found len=3 cost=6.323 expanded=4\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=3 cost=5.929 expanded=3\n",
      "[Modes]  Attempt 2: Path found len=3 cost=6.455 expanded=3\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=4.010, hyp_sensor=(6, 11), hyp_mode=chase_robot, path_len=3\n",
      "\n",
      "[Prior] Derived action prior from modes: U:1.000 | D:0.000 | L:0.000 | R:0.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N= 250 Q= +39.063 P=0.920\n",
      "  a=D N=   0 Q=  +0.000 P=0.020\n",
      "  a=L N=   0 Q=  +0.000 P=0.020\n",
      "  a=R N=   0 Q=  +0.000 P=0.020\n",
      "  a=S N=   0 Q=  +0.000 P=0.020\n",
      "[MCTS-FIX] Chosen action = U\n",
      "\n",
      "[ACT] Robot takes action aR=U\n",
      "[ACT] True sensor action aS=R, moves (6, 12)->(6, 13)\n",
      "[STEP] Robot moves (3, 16)->(2, 16)\n",
      "[DETECT] p_det=0.240 => detected=False\n",
      "\n",
      "================================================================================\n",
      "[TIME] t=27\n",
      "================================================================================\n",
      "\n",
      "[WORLD] Current grid:\n",
      "..................\n",
      ".........#......G.\n",
      ".........#......R.\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      ".............S....\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "..................\n",
      "\n",
      "[OBS] Robot observes noisy sensor position obs=(8, 13) (true sensor_pos=(6, 13))\n",
      "\n",
      "[Belief] === Particle filter predict/update ===\n",
      "[Belief] Observation obs=(8, 13), time t=27\n",
      "[Belief] Prior mode posterior: chase_robot:1.000\n",
      "[Belief] Prior ESS: 250.00/250\n",
      "[Belief] Posterior mode posterior: chase_robot:1.000\n",
      "[Belief] Posterior ESS: 170.01/250\n",
      "[Belief] No resampling needed.\n",
      "[Belief] Mode posterior top: chase_robot:1.000\n",
      "\n",
      "[Modes] === Building multimodal path library ===\n",
      "[Modes] robot_pos=(2, 16), goal=(1, 16)\n",
      "[Modes] num_hypotheses=25, per_hypothesis_attempts=2, max_modes=6\n",
      "\n",
      "[Modes] Hypothesis #1/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.505 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=3.210 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #2/25: sensor_pos=(6, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.017 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.067 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #3/25: sensor_pos=(6, 14), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=4.027 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=3.632 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #4/25: sensor_pos=(7, 14), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.414 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.842 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #5/25: sensor_pos=(6, 14), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=3.201 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=3.442 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #6/25: sensor_pos=(6, 14), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=3.305 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.961 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #7/25: sensor_pos=(8, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.718 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.674 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #8/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.576 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.277 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #9/25: sensor_pos=(6, 14), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=4.120 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=4.150 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #10/25: sensor_pos=(6, 14), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.883 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=3.370 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #11/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.963 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.434 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #12/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.389 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.572 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #13/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.492 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=3.090 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #14/25: sensor_pos=(6, 14), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=3.310 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=3.516 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #15/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.510 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.393 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #16/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.792 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.701 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #17/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=3.422 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.571 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #18/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=3.221 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.358 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #19/25: sensor_pos=(6, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.787 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.866 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #20/25: sensor_pos=(6, 14), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=3.371 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.658 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #21/25: sensor_pos=(6, 12), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.864 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.818 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #22/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=3.313 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.450 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #23/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.871 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.362 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #24/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.938 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=2.548 expanded=2\n",
      "\n",
      "[Modes] Hypothesis #25/25: sensor_pos=(6, 13), mode=chase_robot\n",
      "[Modes]  Attempt 1: Path found len=2 cost=2.577 expanded=2\n",
      "[Modes]  Attempt 2: Path found len=2 cost=3.013 expanded=2\n",
      "\n",
      "[Modes] === Clustered modes summary ===\n",
      "[Modes] Mode 0: cost=2.017, hyp_sensor=(6, 12), hyp_mode=chase_robot, path_len=2\n",
      "\n",
      "[Prior] Derived action prior from modes: U:1.000 | D:0.000 | L:0.000 | R:0.000 | S:0.000\n",
      "\n",
      "[MCTS-FIX] === Starting fixed MCTS ===\n",
      "[MCTS-FIX][DEBUG] sim=1 root.N=1\n",
      "[MCTS-FIX][DEBUG] sim=2 root.N=2\n",
      "[MCTS-FIX][DEBUG] sim=3 root.N=3\n",
      "[MCTS-FIX][DEBUG] sim=50 root.N=50\n",
      "[MCTS-FIX][DEBUG] sim=100 root.N=100\n",
      "[MCTS-FIX][DEBUG] sim=150 root.N=150\n",
      "[MCTS-FIX][DEBUG] sim=200 root.N=200\n",
      "[MCTS-FIX][DEBUG] sim=250 root.N=250\n",
      "[MCTS-FIX] root.N=250 | sum(root.N_a)=250 | expected~250\n",
      "[MCTS-FIX] Root action stats:\n",
      "  a=U N= 250 Q= +44.551 P=0.920\n",
      "  a=D N=   0 Q=  +0.000 P=0.020\n",
      "  a=L N=   0 Q=  +0.000 P=0.020\n",
      "  a=R N=   0 Q=  +0.000 P=0.020\n",
      "  a=S N=   0 Q=  +0.000 P=0.020\n",
      "[MCTS-FIX] Chosen action = U\n",
      "\n",
      "[ACT] Robot takes action aR=U\n",
      "[ACT] True sensor action aS=R, moves (6, 13)->(6, 14)\n",
      "[STEP] Robot moves (2, 16)->(1, 16)\n",
      "[DETECT] p_det=0.240 => detected=True\n",
      "\n",
      "[TERMINAL] Robot reached the goal! \n",
      "\n",
      "[DONE] Simulation finished.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "GenBR-lite + POMDP Belief + Multimodal Trajectory Library (MultiNash-PF-lite)\n",
    "============================================================================\n",
    "\n",
    "This script implements an end-to-end pipeline for:\n",
    "1) A stealth robot planning to reach a goal in a gridworld\n",
    "2) An adversarial sensor/guard whose behavior belongs to one of K discrete \"modes\"\n",
    "3) Robot maintains a POMDP belief over the sensor state and sensor mode using a particle filter\n",
    "4) Robot chooses actions via belief-space MCTS (GenBR-lite) with PUCT\n",
    "5) A \"multimodal trajectory library\" is generated each step by sampling hypotheses + randomized-risk A*\n",
    "   (plays the role of MultiNash-PF: produce multiple plausible \"equilibrium-like\" modes)\n",
    "6) The library is used to form action priors for MCTS and for rollouts / value heuristics.\n",
    "\n",
    "The code is designed to be:\n",
    "- Fully runnable (pure Python, no external solvers)\n",
    "- Heavily commented and extremely verbose (debug prints)\n",
    "- Robust: input checks, safe defaults, bounded loops\n",
    "\n",
    "Author: ChatGPT\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import random\n",
    "import heapq\n",
    "from dataclasses import dataclass, field\n",
    "from typing import (\n",
    "    Dict, List, Tuple, Optional, Iterable, Callable, Any, Set\n",
    ")\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utility + Debug Controls\n",
    "# =========================\n",
    "\n",
    "DEBUG = True  # Turn off to reduce prints\n",
    "\n",
    "def dprint(*args, enabled=True):\n",
    "    if enabled:\n",
    "        print(*args)\n",
    "\n",
    "\n",
    "def clamp(x: float, lo: float, hi: float) -> float:\n",
    "    return max(lo, min(hi, x))\n",
    "\n",
    "\n",
    "def manhattan(a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "\n",
    "def seed_all(seed: int) -> None:\n",
    "    \"\"\"Seed Python RNG for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Gridworld Environment\n",
    "# =========================\n",
    "\n",
    "Action = str  # 'U','D','L','R','S'(stay)\n",
    "\n",
    "ACTIONS: List[Action] = [\"U\", \"D\", \"L\", \"R\", \"S\"]\n",
    "ACTION_DELTAS: Dict[Action, Tuple[int, int]] = {\n",
    "    \"U\": (-1, 0),\n",
    "    \"D\": (1, 0),\n",
    "    \"L\": (0, -1),\n",
    "    \"R\": (0, 1),\n",
    "    \"S\": (0, 0),\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GridWorld:\n",
    "    \"\"\"\n",
    "    GridWorld with obstacles.\n",
    "\n",
    "    Coordinates: (r, c) where r in [0..H-1], c in [0..W-1]\n",
    "    \"\"\"\n",
    "    H: int\n",
    "    W: int\n",
    "    obstacles: Set[Tuple[int, int]] = field(default_factory=set)\n",
    "\n",
    "    def in_bounds(self, p: Tuple[int, int]) -> bool:\n",
    "        r, c = p\n",
    "        return 0 <= r < self.H and 0 <= c < self.W\n",
    "\n",
    "    def is_free(self, p: Tuple[int, int]) -> bool:\n",
    "        return self.in_bounds(p) and (p not in self.obstacles)\n",
    "\n",
    "    def step(self, p: Tuple[int, int], a: Action) -> Tuple[int, int]:\n",
    "        \"\"\"Deterministic movement; if hits obstacle/bounds, stays.\"\"\"\n",
    "        if a not in ACTION_DELTAS:\n",
    "            raise ValueError(f\"Unknown action: {a}\")\n",
    "        dr, dc = ACTION_DELTAS[a]\n",
    "        np = (p[0] + dr, p[1] + dc)\n",
    "        if self.is_free(np):\n",
    "            return np\n",
    "        return p\n",
    "\n",
    "    def neighbors(self, p: Tuple[int, int]) -> List[Tuple[Tuple[int, int], Action]]:\n",
    "        \"\"\"Return feasible next states and actions.\"\"\"\n",
    "        out: List[Tuple[Tuple[int, int], Action]] = []\n",
    "        for a in ACTIONS:\n",
    "            np = self.step(p, a)\n",
    "            out.append((np, a))\n",
    "        return out\n",
    "\n",
    "    def render(self,\n",
    "               robot: Tuple[int, int],\n",
    "               sensor: Tuple[int, int],\n",
    "               goal: Tuple[int, int]) -> None:\n",
    "        \"\"\"ASCII render for debugging.\"\"\"\n",
    "        grid = [[\".\" for _ in range(self.W)] for _ in range(self.H)]\n",
    "        for (r, c) in self.obstacles:\n",
    "            grid[r][c] = \"#\"\n",
    "        rr, rc = robot\n",
    "        sr, sc = sensor\n",
    "        gr, gc = goal\n",
    "        grid[gr][gc] = \"G\"\n",
    "        grid[sr][sc] = \"S\"\n",
    "        grid[rr][rc] = \"R\"\n",
    "        for r in range(self.H):\n",
    "            print(\"\".join(grid[r]))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Sensor Models (Modes)\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class SensorModePolicy:\n",
    "    \"\"\"\n",
    "    Base class for sensor behavior policies (\"modes\").\n",
    "    The robot treats the mode index z as hidden.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PatrolLoopPolicy(SensorModePolicy):\n",
    "    \"\"\"\n",
    "    Patrols along a fixed loop of waypoints in order.\n",
    "    \"\"\"\n",
    "    loop: List[Tuple[int, int]] = field(default_factory=list)\n",
    "\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        if not self.loop:\n",
    "            return \"S\"\n",
    "        # Target waypoint index depends on time; simple periodic\n",
    "        idx = t % len(self.loop)\n",
    "        target = self.loop[idx]\n",
    "        return greedy_step_toward(world, sensor_pos, target)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ChasePolicy(SensorModePolicy):\n",
    "    \"\"\"\n",
    "    Greedily moves toward the robot (adversarial).\n",
    "    \"\"\"\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        return greedy_step_toward(world, sensor_pos, robot_pos)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RandomWalkPolicy(SensorModePolicy):\n",
    "    \"\"\"\n",
    "    Random feasible move.\n",
    "    \"\"\"\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        # Randomly choose among actions that actually move or stay; prefer feasible.\n",
    "        candidates = []\n",
    "        for a in ACTIONS:\n",
    "            np = world.step(sensor_pos, a)\n",
    "            candidates.append((a, np))\n",
    "        a, _ = random.choice(candidates)\n",
    "        return a\n",
    "\n",
    "\n",
    "def greedy_step_toward(world: GridWorld, src: Tuple[int, int], dst: Tuple[int, int]) -> Action:\n",
    "    \"\"\"\n",
    "    One-step greedy action to reduce Manhattan distance to dst.\n",
    "    Ties broken randomly.\n",
    "    \"\"\"\n",
    "    best_actions: List[Action] = []\n",
    "    best_dist = 10**9\n",
    "    for a in ACTIONS:\n",
    "        np = world.step(src, a)\n",
    "        d = manhattan(np, dst)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_actions = [a]\n",
    "        elif d == best_dist:\n",
    "            best_actions.append(a)\n",
    "    return random.choice(best_actions) if best_actions else \"S\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Detection / Observation Model\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class DetectionModel:\n",
    "    \"\"\"\n",
    "    Simple probabilistic detection model:\n",
    "    p_det depends on Manhattan distance between robot and sensor.\n",
    "\n",
    "    Example:\n",
    "        if dist <= d0 => high detection probability\n",
    "        else => decays\n",
    "    \"\"\"\n",
    "    d0: int = 2           # \"close range\"\n",
    "    p_close: float = 0.9  # p_det at dist <= d0\n",
    "    p_far: float = 0.05   # minimum p_det when very far\n",
    "    decay: float = 0.3    # exponential decay factor beyond d0\n",
    "\n",
    "    def p_detect(self, robot_pos: Tuple[int, int], sensor_pos: Tuple[int, int]) -> float:\n",
    "        dist = manhattan(robot_pos, sensor_pos)\n",
    "        if dist <= self.d0:\n",
    "            return self.p_close\n",
    "        # Exponential decay to p_far\n",
    "        return self.p_far + (self.p_close - self.p_far) * math.exp(-self.decay * (dist - self.d0))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ObservationModel:\n",
    "    \"\"\"\n",
    "    Robot observes a noisy measurement of sensor position.\n",
    "    We'll model:\n",
    "        o = sensor_pos + noise, where noise is discrete with a simple likelihood.\n",
    "\n",
    "    Likelihood:\n",
    "        p(o | sensor_pos)  exp(-||o - sensor_pos||_1 / sigma)\n",
    "    \"\"\"\n",
    "    sigma: float = 1.2  # larger => less informative observations\n",
    "\n",
    "    def sample_observation(self, sensor_pos: Tuple[int, int], world: GridWorld) -> Tuple[int, int]:\n",
    "        # Sample noise by random L1 perturbation (bounded)\n",
    "        # This is simple and robust; not a perfect Gaussian but fine for demo.\n",
    "        max_jump = 2\n",
    "        dr = random.randint(-max_jump, max_jump)\n",
    "        dc = random.randint(-max_jump, max_jump)\n",
    "        o = (sensor_pos[0] + dr, sensor_pos[1] + dc)\n",
    "        # Clamp to bounds\n",
    "        o = (clamp(o[0], 0, world.H - 1), clamp(o[1], 0, world.W - 1))\n",
    "        return (int(o[0]), int(o[1]))\n",
    "\n",
    "    def likelihood(self, obs: Tuple[int, int], sensor_pos: Tuple[int, int]) -> float:\n",
    "        d = manhattan(obs, sensor_pos)\n",
    "        # Avoid underflow with a floor\n",
    "        return max(1e-12, math.exp(-d / max(1e-6, self.sigma)))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Particle Filter over Sensor State + Mode\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class Particle:\n",
    "    \"\"\"\n",
    "    Represents hypothesis about sensor position and sensor mode z.\n",
    "    \"\"\"\n",
    "    sensor_pos: Tuple[int, int]\n",
    "    mode_idx: int\n",
    "    weight: float = 1.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BeliefState:\n",
    "    \"\"\"\n",
    "    Particle belief over (sensor_pos, mode).\n",
    "    \"\"\"\n",
    "    particles: List[Particle]\n",
    "    mode_names: List[str]\n",
    "\n",
    "    def normalize(self) -> None:\n",
    "        s = sum(p.weight for p in self.particles)\n",
    "        if s <= 0:\n",
    "            # Reset to uniform if degenerate\n",
    "            w = 1.0 / max(1, len(self.particles))\n",
    "            for p in self.particles:\n",
    "                p.weight = w\n",
    "            return\n",
    "        for p in self.particles:\n",
    "            p.weight /= s\n",
    "\n",
    "    def mode_posterior(self) -> Dict[int, float]:\n",
    "        post = defaultdict(float)\n",
    "        for p in self.particles:\n",
    "            post[p.mode_idx] += p.weight\n",
    "        return dict(post)\n",
    "\n",
    "    def summary(self, topk: int = 3) -> str:\n",
    "        post = self.mode_posterior()\n",
    "        items = sorted(post.items(), key=lambda kv: kv[1], reverse=True)[:topk]\n",
    "        parts = []\n",
    "        for idx, prob in items:\n",
    "            name = self.mode_names[idx] if 0 <= idx < len(self.mode_names) else f\"mode{idx}\"\n",
    "            parts.append(f\"{name}:{prob:.3f}\")\n",
    "        return \" | \".join(parts) if parts else \"(empty)\"\n",
    "\n",
    "    def effective_sample_size(self) -> float:\n",
    "        # ESS = 1 / sum w_i^2\n",
    "        s = sum(p.weight ** 2 for p in self.particles)\n",
    "        return 0.0 if s <= 0 else 1.0 / s\n",
    "\n",
    "\n",
    "def systematic_resample(particles: List[Particle]) -> List[Particle]:\n",
    "    \"\"\"\n",
    "    Systematic resampling for particle filters.\n",
    "    Assumes weights are normalized.\n",
    "    \"\"\"\n",
    "    n = len(particles)\n",
    "    if n == 0:\n",
    "        return []\n",
    "    positions = [(random.random() + i) / n for i in range(n)]\n",
    "    cumulative = []\n",
    "    csum = 0.0\n",
    "    for p in particles:\n",
    "        csum += p.weight\n",
    "        cumulative.append(csum)\n",
    "\n",
    "    out: List[Particle] = []\n",
    "    i = 0\n",
    "    for pos in positions:\n",
    "        while i < n - 1 and pos > cumulative[i]:\n",
    "            i += 1\n",
    "        chosen = particles[i]\n",
    "        out.append(Particle(sensor_pos=chosen.sensor_pos, mode_idx=chosen.mode_idx, weight=1.0 / n))\n",
    "    return out\n",
    "\n",
    "\n",
    "def initialize_belief(world: GridWorld,\n",
    "                      sensor_init_candidates: List[Tuple[int, int]],\n",
    "                      mode_pior: List[float],\n",
    "                      mode_names: List[str],\n",
    "                      num_particles: int = 200) -> BeliefState:\n",
    "    \"\"\"\n",
    "    Initialize belief by sampling positions from candidates and modes from prior.\n",
    "    \"\"\"\n",
    "    if len(mode_pior) != len(mode_names):\n",
    "        raise ValueError(\"mode_pior and mode_names must have same length.\")\n",
    "    if not sensor_init_candidates:\n",
    "        raise ValueError(\"Need at least one sensor init candidate position.\")\n",
    "    if num_particles <= 0:\n",
    "        raise ValueError(\"num_particles must be > 0\")\n",
    "\n",
    "    # Normalize prior\n",
    "    s = sum(mode_pior)\n",
    "    if s <= 0:\n",
    "        mode_pior = [1.0 / len(mode_pior)] * len(mode_pior)\n",
    "    else:\n",
    "        mode_pior = [x / s for x in mode_pior]\n",
    "\n",
    "    def sample_mode() -> int:\n",
    "        r = random.random()\n",
    "        c = 0.0\n",
    "        for i, p in enumerate(mode_pior):\n",
    "            c += p\n",
    "            if r <= c:\n",
    "                return i\n",
    "        return len(mode_pior) - 1\n",
    "\n",
    "    particles: List[Particle] = []\n",
    "    for _ in range(num_particles):\n",
    "        sp = random.choice(sensor_init_candidates)\n",
    "        z = sample_mode()\n",
    "        particles.append(Particle(sensor_pos=sp, mode_idx=z, weight=1.0 / num_particles))\n",
    "    return BeliefState(particles=particles, mode_names=mode_names)\n",
    "\n",
    "\n",
    "def belief_predict_update(\n",
    "    belief: BeliefState,\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    sensor_policies: List[SensorModePolicy],\n",
    "    obs_model: ObservationModel,\n",
    "    obs: Tuple[int, int],\n",
    "    t: int,\n",
    "    motion_noise: float = 0.10,\n",
    "    resample_threshold: float = 0.5,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Particle filter step:\n",
    "    - Predict sensor motion using policy of each particle's mode\n",
    "    - Add small random motion noise\n",
    "    - Weight update using observation likelihood p(obs | sensor_pos)\n",
    "    - Normalize and resample if ESS too small\n",
    "\n",
    "    Prints:\n",
    "    - before/after mode posterior\n",
    "    - ESS\n",
    "    \"\"\"\n",
    "    dprint(\"\\n[Belief] === Particle filter predict/update ===\")\n",
    "    dprint(f\"[Belief] Observation obs={obs}, time t={t}\")\n",
    "    dprint(f\"[Belief] Prior mode posterior: {format_mode_posterior(belief)}\")\n",
    "    dprint(f\"[Belief] Prior ESS: {belief.effective_sample_size():.2f}/{len(belief.particles)}\")\n",
    "\n",
    "    # Predict + weight update\n",
    "    for p in belief.particles:\n",
    "        # Policy-predicted action:\n",
    "        mode_idx = p.mode_idx\n",
    "        if mode_idx < 0 or mode_idx >= len(sensor_policies):\n",
    "            # Robust fallback\n",
    "            aS = \"S\"\n",
    "        else:\n",
    "            aS = sensor_policies[mode_idx].action(world, p.sensor_pos, robot_pos, t)\n",
    "\n",
    "        predicted = world.step(p.sensor_pos, aS)\n",
    "\n",
    "        # Motion noise: with small prob, take a random action\n",
    "        if random.random() < motion_noise:\n",
    "            a_noise = random.choice(ACTIONS)\n",
    "            predicted = world.step(predicted, a_noise)\n",
    "\n",
    "        p.sensor_pos = predicted\n",
    "\n",
    "        # Weight update with observation likelihood\n",
    "        p.weight *= obs_model.likelihood(obs, p.sensor_pos)\n",
    "\n",
    "    belief.normalize()\n",
    "\n",
    "    ess = belief.effective_sample_size()\n",
    "    dprint(f\"[Belief] Posterior mode posterior: {format_mode_posterior(belief)}\")\n",
    "    dprint(f\"[Belief] Posterior ESS: {ess:.2f}/{len(belief.particles)}\")\n",
    "\n",
    "    # Resample if ESS is low\n",
    "    if ess < resample_threshold * len(belief.particles):\n",
    "        dprint(f\"[Belief] ESS below threshold ({resample_threshold:.2f} * N). Resampling...\")\n",
    "        belief.particles = systematic_resample(belief.particles)\n",
    "        dprint(f\"[Belief] After resample mode posterior: {format_mode_posterior(belief)}\")\n",
    "    else:\n",
    "        dprint(\"[Belief] No resampling needed.\")\n",
    "\n",
    "\n",
    "def format_mode_posterior(belief: BeliefState, topk: int = 5) -> str:\n",
    "    post = belief.mode_posterior()\n",
    "    items = sorted(post.items(), key=lambda kv: kv[1], reverse=True)[:topk]\n",
    "    return \" | \".join(f\"{belief.mode_names[i]}:{p:.3f}\" for i, p in items)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# A* Search with Risk Costs\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class AStarResult:\n",
    "    path: List[Tuple[int, int]]  # includes start and goal\n",
    "    cost: float\n",
    "    expanded: int\n",
    "\n",
    "\n",
    "def astar_path(\n",
    "    world: GridWorld,\n",
    "    start: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    step_cost: Callable[[Tuple[int, int]], float],\n",
    "    heuristic: Callable[[Tuple[int, int]], float],\n",
    "    max_expansions: int = 50_000,\n",
    ") -> Optional[AStarResult]:\n",
    "    \"\"\"\n",
    "    A* in gridworld:\n",
    "      g(n) = cost so far\n",
    "      f(n) = g(n) + h(n)\n",
    "\n",
    "    step_cost(state) should be >= 0.\n",
    "\n",
    "    Returns None if no path found within max_expansions.\n",
    "    \"\"\"\n",
    "    if not world.is_free(start):\n",
    "        return None\n",
    "    if not world.is_free(goal):\n",
    "        return None\n",
    "\n",
    "    frontier: List[Tuple[float, float, Tuple[int, int]]] = []\n",
    "    heapq.heappush(frontier, (heuristic(start), 0.0, start))\n",
    "\n",
    "    came_from: Dict[Tuple[int, int], Tuple[int, int]] = {}\n",
    "    gscore: Dict[Tuple[int, int], float] = {start: 0.0}\n",
    "\n",
    "    expanded = 0\n",
    "    visited: Set[Tuple[int, int]] = set()\n",
    "\n",
    "    while frontier and expanded < max_expansions:\n",
    "        f, g, cur = heapq.heappop(frontier)\n",
    "        if cur in visited:\n",
    "            continue\n",
    "        visited.add(cur)\n",
    "        expanded += 1\n",
    "\n",
    "        if cur == goal:\n",
    "            # Reconstruct\n",
    "            path = [cur]\n",
    "            while cur in came_from:\n",
    "                cur = came_from[cur]\n",
    "                path.append(cur)\n",
    "            path.reverse()\n",
    "            return AStarResult(path=path, cost=gscore[goal], expanded=expanded)\n",
    "\n",
    "        for (nxt, a) in world.neighbors(cur):\n",
    "            # allow staying; but step cost still applies\n",
    "            if not world.is_free(nxt):\n",
    "                continue\n",
    "            ng = gscore[cur] + step_cost(nxt)\n",
    "            if nxt not in gscore or ng < gscore[nxt]:\n",
    "                gscore[nxt] = ng\n",
    "                came_from[nxt] = cur\n",
    "                nf = ng + heuristic(nxt)\n",
    "                heapq.heappush(frontier, (nf, ng, nxt))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MultiNash-PF-lite: Multimodal Path Library\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class PathMode:\n",
    "    \"\"\"\n",
    "    One \"mode\" = candidate robot path under a sampled belief hypothesis.\n",
    "    \"\"\"\n",
    "    path: List[Tuple[int, int]]\n",
    "    total_cost: float\n",
    "    hypothesis_sensor_pos: Tuple[int, int]\n",
    "    hypothesis_mode_idx: int\n",
    "    debug_info: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def build_cost_map_from_hypothesis(\n",
    "    world: GridWorld,\n",
    "    detection: DetectionModel,\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    base_step: float,\n",
    "    w_detect: float,\n",
    "    randomize: bool,\n",
    "    rand_scale: float,\n",
    ") -> Callable[[Tuple[int, int]], float]:\n",
    "    \"\"\"\n",
    "    Returns a state cost function c(s) = base_step + w_detect * p_det(robot=s, sensor=hyp)\n",
    "    plus optional random noise for multimodality.\n",
    "    \"\"\"\n",
    "    def cost_fn(s: Tuple[int, int]) -> float:\n",
    "        if not world.is_free(s):\n",
    "            return float(\"inf\")\n",
    "        p_det = detection.p_detect(robot_pos=s, sensor_pos=sensor_pos)\n",
    "        c = base_step + w_detect * p_det\n",
    "        if randomize:\n",
    "            # Noise to push A* into alternative corridors (\"implicit PF-like\" diversity)\n",
    "            # Keep it positive and small\n",
    "            c *= (1.0 + rand_scale * (random.random() - 0.5))\n",
    "            c = max(1e-6, c)\n",
    "        return c\n",
    "    return cost_fn\n",
    "\n",
    "\n",
    "def cluster_paths_by_signature(paths: List[List[Tuple[int, int]]], max_modes: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Robust clustering:\n",
    "    - Convert each path to a signature string of compressed directions.\n",
    "    - Map signatures to cluster IDs until max_modes is reached.\n",
    "    - Once max_modes is reached, assign new signatures to an existing cluster (hash/fallback),\n",
    "      WITHOUT trying to store them in the dict (prevents unbounded growth).\n",
    "    Returns: cluster id for each path.\n",
    "    \"\"\"\n",
    "    sig_to_cluster: Dict[str, int] = {}\n",
    "    assignments: List[int] = []\n",
    "\n",
    "    def signature(path: List[Tuple[int, int]]) -> str:\n",
    "        if len(path) < 2:\n",
    "            return \"EMPTY\"\n",
    "        dirs = []\n",
    "        for i in range(1, len(path)):\n",
    "            dr = path[i][0] - path[i-1][0]\n",
    "            dc = path[i][1] - path[i-1][1]\n",
    "            dirs.append((dr, dc))\n",
    "\n",
    "        # compress consecutive repeats\n",
    "        comp = []\n",
    "        for d in dirs:\n",
    "            if not comp or comp[-1] != d:\n",
    "                comp.append(d)\n",
    "\n",
    "        m = {(-1, 0): \"U\", (1, 0): \"D\", (0, -1): \"L\", (0, 1): \"R\", (0, 0): \"S\"}\n",
    "        return \"\".join(m.get(d, \"?\") for d in comp)[:120]\n",
    "\n",
    "    for p in paths:\n",
    "        sig = signature(p)\n",
    "\n",
    "        # Case 1: we've seen this signature before\n",
    "        if sig in sig_to_cluster:\n",
    "            cid = sig_to_cluster[sig]\n",
    "\n",
    "        # Case 2: new signature and we still have room for new clusters\n",
    "        elif len(sig_to_cluster) < max_modes:\n",
    "            cid = len(sig_to_cluster)\n",
    "            sig_to_cluster[sig] = cid\n",
    "\n",
    "        # Case 3: new signature but we're at max_modes => assign to an existing cluster\n",
    "        else:\n",
    "            # Robust fallback: if somehow empty, assign cluster 0\n",
    "            if not sig_to_cluster:\n",
    "                cid = 0\n",
    "            else:\n",
    "                # Deterministic-ish hashing to reduce randomness across runs:\n",
    "                # map signature to one of existing cluster IDs\n",
    "                cid = hash(sig) % len(sig_to_cluster)\n",
    "\n",
    "        assignments.append(cid)\n",
    "\n",
    "    return assignments\n",
    "\n",
    "\n",
    "def build_multimodal_path_library(\n",
    "    world: GridWorld,\n",
    "    belief: BeliefState,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    detection: DetectionModel,\n",
    "    num_hypotheses: int = 30,\n",
    "    per_hypothesis_attempts: int = 2,\n",
    "    base_step_cost: float = 1.0,\n",
    "    w_detect: float = 8.0,\n",
    "    rand_scale: float = 0.40,\n",
    "    max_modes: int = 6,\n",
    ") -> List[PathMode]:\n",
    "    \"\"\"\n",
    "    This is the \"MultiNash-PF-lite\" replacement:\n",
    "    - Sample several sensor hypotheses (sensor_pos, mode)\n",
    "    - For each, run randomized-risk A* multiple times to get diverse paths\n",
    "    - Cluster by path signature to get distinct modes\n",
    "    - Keep the best representative per cluster\n",
    "\n",
    "    Prints everything.\n",
    "    \"\"\"\n",
    "    dprint(\"\\n[Modes] === Building multimodal path library ===\")\n",
    "    dprint(f\"[Modes] robot_pos={robot_pos}, goal={goal}\")\n",
    "    dprint(f\"[Modes] num_hypotheses={num_hypotheses}, per_hypothesis_attempts={per_hypothesis_attempts}, max_modes={max_modes}\")\n",
    "\n",
    "    if not belief.particles:\n",
    "        dprint(\"[Modes] WARNING: belief has no particles. Returning empty library.\")\n",
    "        return []\n",
    "\n",
    "    # Sample particles proportional to weight\n",
    "    weights = [p.weight for p in belief.particles]\n",
    "    # Robust normalization\n",
    "    s = sum(weights)\n",
    "    if s <= 0:\n",
    "        weights = [1.0 / len(weights)] * len(weights)\n",
    "    else:\n",
    "        weights = [w / s for w in weights]\n",
    "\n",
    "    sampled_particles: List[Particle] = random.choices(belief.particles, weights=weights, k=num_hypotheses)\n",
    "\n",
    "    candidates: List[PathMode] = []\n",
    "\n",
    "    for hi, hp in enumerate(sampled_particles):\n",
    "        hyp_sensor = hp.sensor_pos\n",
    "        hyp_mode = hp.mode_idx\n",
    "\n",
    "        dprint(f\"\\n[Modes] Hypothesis #{hi+1}/{num_hypotheses}: sensor_pos={hyp_sensor}, mode={belief.mode_names[hyp_mode]}\")\n",
    "\n",
    "        for attempt in range(per_hypothesis_attempts):\n",
    "            # Randomized cost map encourages diverse solutions\n",
    "            cost_fn = build_cost_map_from_hypothesis(\n",
    "                world=world,\n",
    "                detection=detection,\n",
    "                sensor_pos=hyp_sensor,\n",
    "                base_step=base_step_cost,\n",
    "                w_detect=w_detect,\n",
    "                randomize=True,\n",
    "                rand_scale=rand_scale,\n",
    "            )\n",
    "            heur = lambda s: float(manhattan(s, goal))  # admissible baseline\n",
    "\n",
    "            res = astar_path(world, robot_pos, goal, step_cost=cost_fn, heuristic=heur)\n",
    "            if res is None:\n",
    "                dprint(f\"[Modes]  Attempt {attempt+1}: No path found.\")\n",
    "                continue\n",
    "\n",
    "            dprint(f\"[Modes]  Attempt {attempt+1}: Path found len={len(res.path)} cost={res.cost:.3f} expanded={res.expanded}\")\n",
    "\n",
    "            candidates.append(PathMode(\n",
    "                path=res.path,\n",
    "                total_cost=res.cost,\n",
    "                hypothesis_sensor_pos=hyp_sensor,\n",
    "                hypothesis_mode_idx=hyp_mode,\n",
    "                debug_info={\n",
    "                    \"expanded\": res.expanded,\n",
    "                    \"attempt\": attempt + 1,\n",
    "                }\n",
    "            ))\n",
    "\n",
    "    if not candidates:\n",
    "        dprint(\"[Modes] No candidates found at all. Returning empty library.\")\n",
    "        return []\n",
    "\n",
    "    # Cluster by signature and keep best per cluster\n",
    "    paths_only = [c.path for c in candidates]\n",
    "    cluster_ids = cluster_paths_by_signature(paths_only, max_modes=max_modes)\n",
    "\n",
    "    best_by_cluster: Dict[int, PathMode] = {}\n",
    "    for c, cid in zip(candidates, cluster_ids):\n",
    "        if cid not in best_by_cluster or c.total_cost < best_by_cluster[cid].total_cost:\n",
    "            best_by_cluster[cid] = c\n",
    "\n",
    "    # Sort clusters by best cost\n",
    "    library = sorted(best_by_cluster.values(), key=lambda pm: pm.total_cost)[:max_modes]\n",
    "\n",
    "    dprint(\"\\n[Modes] === Clustered modes summary ===\")\n",
    "    for i, pm in enumerate(library):\n",
    "        dprint(f\"[Modes] Mode {i}: cost={pm.total_cost:.3f}, hyp_sensor={pm.hypothesis_sensor_pos}, hyp_mode={belief.mode_names[pm.hypothesis_mode_idx]}, path_len={len(pm.path)}\")\n",
    "\n",
    "    return library\n",
    "\n",
    "\n",
    "def first_action_from_path(world: GridWorld, start: Tuple[int, int], path: List[Tuple[int, int]]) -> Action:\n",
    "    \"\"\"Compute which primitive action moves start -> path[1].\"\"\"\n",
    "    if not path or len(path) < 2:\n",
    "        return \"S\"\n",
    "    nxt = path[1]\n",
    "    dr = nxt[0] - start[0]\n",
    "    dc = nxt[1] - start[1]\n",
    "    for a, (adr, adc) in ACTION_DELTAS.items():\n",
    "        if (dr, dc) == (adr, adc):\n",
    "            return a\n",
    "    # Fallback\n",
    "    return \"S\"\n",
    "\n",
    "\n",
    "def build_action_prior_from_library(world: GridWorld,\n",
    "                                   robot_pos: Tuple[int, int],\n",
    "                                   library: List[PathMode]) -> Dict[Action, float]:\n",
    "    \"\"\"\n",
    "    Convert path library into a prior p(a) used by PUCT:\n",
    "    p(a) proportional to how many modes recommend that first step,\n",
    "    weighted by inverse cost (cheaper modes contribute more).\n",
    "    \"\"\"\n",
    "    pri = defaultdict(float)\n",
    "    if not library:\n",
    "        # Uniform fallback\n",
    "        return {a: 1.0 / len(ACTIONS) for a in ACTIONS}\n",
    "\n",
    "    for pm in library:\n",
    "        a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "        weight = 1.0 / max(1e-6, pm.total_cost)\n",
    "        pri[a0] += weight\n",
    "\n",
    "    # Normalize\n",
    "    s = sum(pri.values())\n",
    "    if s <= 0:\n",
    "        return {a: 1.0 / len(ACTIONS) for a in ACTIONS}\n",
    "    for a in ACTIONS:\n",
    "        pri[a] /= s\n",
    "\n",
    "    return dict(pri)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# GenBR-lite: Belief-space MCTS with PUCT\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class MCTSNode:\n",
    "    \"\"\"Node stores edge-stats per action (classic AlphaZero-style).\"\"\"\n",
    "    robot_pos: Tuple[int, int]\n",
    "    depth: int\n",
    "\n",
    "    # node visits\n",
    "    N: int = 0\n",
    "\n",
    "    # edge stats\n",
    "    N_a: Dict[Action, int] = field(default_factory=lambda: {a: 0 for a in ACTIONS})\n",
    "    W_a: Dict[Action, float] = field(default_factory=lambda: {a: 0.0 for a in ACTIONS})\n",
    "    Q_a: Dict[Action, float] = field(default_factory=lambda: {a: 0.0 for a in ACTIONS})\n",
    "\n",
    "    # prior over actions at this node\n",
    "    P_a: Dict[Action, float] = field(default_factory=lambda: {a: 1.0/len(ACTIONS) for a in ACTIONS})\n",
    "\n",
    "    # children\n",
    "    children: Dict[Action, \"MCTSNode\"] = field(default_factory=dict)\n",
    "\n",
    "    expanded: bool = False\n",
    "\n",
    "\n",
    "def smooth_prior(prior: Dict[Action, float], eps: float = 0.10) -> Dict[Action, float]:\n",
    "    \"\"\"Epsilon-smooth and renormalize prior to avoid degenerate priors.\"\"\"\n",
    "    p = {a: float(prior.get(a, 0.0)) for a in ACTIONS}\n",
    "    s = sum(p.values())\n",
    "    if s <= 0:\n",
    "        return {a: 1.0/len(ACTIONS) for a in ACTIONS}\n",
    "    p = {a: v/s for a, v in p.items()}\n",
    "\n",
    "    u = 1.0/len(ACTIONS)\n",
    "    p = {a: (1-eps)*p[a] + eps*u for a in ACTIONS}\n",
    "\n",
    "    s2 = sum(p.values())\n",
    "    return {a: v/s2 for a, v in p.items()}\n",
    "\n",
    "\n",
    "def select_action_puct(node: MCTSNode, c_puct: float, debug: bool = False) -> Action:\n",
    "    \"\"\"PUCT: argmax_a Q(s,a) + c*P(s,a)*sqrt(N(s)) / (1+N(s,a)).\"\"\"\n",
    "    sqrtN = math.sqrt(max(1, node.N))\n",
    "\n",
    "    best_a = None\n",
    "    best_score = -1e18\n",
    "    for a in ACTIONS:\n",
    "        q = node.Q_a[a]\n",
    "        u = c_puct * node.P_a[a] * sqrtN / (1.0 + node.N_a[a])\n",
    "        score = q + u\n",
    "\n",
    "        # tiny noise for tie-breaking stability\n",
    "        score += random.uniform(-1e-9, 1e-9)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_a = a\n",
    "\n",
    "    assert best_a is not None\n",
    "    return best_a\n",
    "\n",
    "\n",
    "def backprop_path(path: List[Tuple[MCTSNode, Action]], value: float) -> None:\n",
    "    \"\"\"Backprop value through all visited edges.\"\"\"\n",
    "    for node, a in reversed(path):\n",
    "        node.N += 1\n",
    "        node.N_a[a] += 1\n",
    "        node.W_a[a] += value\n",
    "        node.Q_a[a] = node.W_a[a] / node.N_a[a]\n",
    "\n",
    "\n",
    "def choose_final_action(root: MCTSNode) -> Action:\n",
    "    \"\"\"Pick action by max N; break ties by Q then prior then random.\"\"\"\n",
    "    # 1) max visits\n",
    "    maxN = max(root.N_a.values())\n",
    "    cand = [a for a in ACTIONS if root.N_a[a] == maxN]\n",
    "    if len(cand) == 1:\n",
    "        return cand[0]\n",
    "\n",
    "    # 2) max Q\n",
    "    maxQ = max(root.Q_a[a] for a in cand)\n",
    "    cand2 = [a for a in cand if abs(root.Q_a[a] - maxQ) < 1e-12]\n",
    "    if len(cand2) == 1:\n",
    "        return cand2[0]\n",
    "\n",
    "    # 3) max prior\n",
    "    maxP = max(root.P_a[a] for a in cand2)\n",
    "    cand3 = [a for a in cand2 if abs(root.P_a[a] - maxP) < 1e-12]\n",
    "    return random.choice(cand3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def rollout_value(\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    detection: DetectionModel,\n",
    "    max_steps: int,\n",
    "    w_step: float,\n",
    "    w_detect: float,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Simple rollout heuristic:\n",
    "    - Greedy toward goal for max_steps\n",
    "    - Value is negative cost (MCTS maximizes)\n",
    "    \"\"\"\n",
    "    total_cost = 0.0\n",
    "    cur = robot_pos\n",
    "    for _ in range(max_steps):\n",
    "        if cur == goal:\n",
    "            break\n",
    "        # Greedy move toward goal\n",
    "        a = greedy_step_toward(world, cur, goal)\n",
    "        cur = world.step(cur, a)\n",
    "        total_cost += w_step\n",
    "        total_cost += w_detect * detection.p_detect(cur, sensor_pos)\n",
    "    # Terminal bonus\n",
    "    if cur == goal:\n",
    "        total_cost -= 20.0  # reaching goal is good -> lower cost\n",
    "    return -total_cost\n",
    "\n",
    "\n",
    "def simulate_sensor_step(\n",
    "    world: GridWorld,\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    robot_pos: Tuple[int, int],\n",
    "    t: int,\n",
    "    mode_idx: int,\n",
    "    policies: List[SensorModePolicy],\n",
    ") -> Tuple[int, int]:\n",
    "    \"\"\"Apply the sensor mode policy for one step (deterministic).\"\"\"\n",
    "    if mode_idx < 0 or mode_idx >= len(policies):\n",
    "        return sensor_pos\n",
    "    aS = policies[mode_idx].action(world, sensor_pos, robot_pos, t)\n",
    "    return world.step(sensor_pos, aS)\n",
    "\n",
    "\n",
    "def mcts_search_action(\n",
    "    world: GridWorld,\n",
    "    belief: BeliefState,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    sensor_policies: List[SensorModePolicy],\n",
    "    detection: DetectionModel,\n",
    "    action_prior: Dict[Action, float],\n",
    "    t: int,\n",
    "    num_sims: int = 200,\n",
    "    max_depth: int = 10,\n",
    "    c_puct: float = 1.2,\n",
    "    w_step: float = 1.0,\n",
    "    w_detect: float = 6.0,\n",
    ") -> Action:\n",
    "    \"\"\"\n",
    "    Belief-space MCTS with root sampling:\n",
    "      For each simulation:\n",
    "        - sample (sensor_pos, mode) from belief particles\n",
    "        - traverse tree selecting actions via PUCT\n",
    "        - simulate robot + sensor forward\n",
    "        - evaluate leaf with rollout heuristic\n",
    "        - backup value\n",
    "\n",
    "    Prints:\n",
    "      - priors\n",
    "      - root visit counts + Q values\n",
    "    \"\"\"\n",
    "    dprint(\"\\n[MCTS] === Starting MCTS Search ===\")\n",
    "    dprint(f\"[MCTS] robot_pos={robot_pos}, goal={goal}, t={t}, num_sims={num_sims}, max_depth={max_depth}\")\n",
    "    dprint(f\"[MCTS] Action prior p(a): \" + \" | \".join(f\"{a}:{action_prior.get(a,0):.3f}\" for a in ACTIONS))\n",
    "\n",
    "    root = MCTSNode(robot_pos=robot_pos, depth=0)\n",
    "\n",
    "    # Prepare sampling distribution over particles\n",
    "    if not belief.particles:\n",
    "        # fallback uniform dummy belief\n",
    "        dummy = Particle(sensor_pos=robot_pos, mode_idx=0, weight=1.0)\n",
    "        particles = [dummy]\n",
    "        weights = [1.0]\n",
    "    else:\n",
    "        particles = belief.particles\n",
    "        weights = [p.weight for p in particles]\n",
    "        s = sum(weights)\n",
    "        if s <= 0:\n",
    "            weights = [1.0 / len(weights)] * len(weights)\n",
    "        else:\n",
    "            weights = [w / s for w in weights]\n",
    "\n",
    "    for sim in range(num_sims):\n",
    "        # Root sampling (belief)\n",
    "        hp = random.choices(particles, weights=weights, k=1)[0]\n",
    "        sim_sensor_pos = hp.sensor_pos\n",
    "        sim_mode = hp.mode_idx\n",
    "\n",
    "        # Copy forward simulation state\n",
    "        cur_node = root\n",
    "        cur_robot = robot_pos\n",
    "        cur_sensor = sim_sensor_pos\n",
    "\n",
    "        # Simulate a trajectory for up to max_depth\n",
    "        total_value = 0.0\n",
    "        discount = 1.0\n",
    "        gamma = 0.95\n",
    "\n",
    "        for depth in range(max_depth):\n",
    "            if cur_robot == goal:\n",
    "                # big reward for reaching goal\n",
    "                total_value += discount * 50.0\n",
    "                break\n",
    "\n",
    "            # Select action via PUCT\n",
    "            a = select_action_puct(cur_node, action_prior, c_puct)\n",
    "\n",
    "            nxt_robot = world.step(cur_robot, a)\n",
    "\n",
    "            # Sensor evolves too (under sampled mode)\n",
    "            nxt_sensor = simulate_sensor_step(world, cur_sensor, nxt_robot, t + depth, sim_mode, sensor_policies)\n",
    "\n",
    "            # Immediate reward (negative cost)\n",
    "            step_cost = w_step + w_detect * detection.p_detect(nxt_robot, nxt_sensor)\n",
    "            reward = -step_cost\n",
    "            total_value += discount * reward\n",
    "            discount *= gamma\n",
    "\n",
    "            # Expand child\n",
    "            if a not in cur_node.children:\n",
    "                cur_node.children[a] = MCTSNode(robot_pos=nxt_robot, depth=cur_node.depth + 1)\n",
    "\n",
    "                # Evaluate leaf with rollout heuristic and stop expansion\n",
    "                leaf_v = rollout_value(\n",
    "                    world=world,\n",
    "                    robot_pos=nxt_robot,\n",
    "                    sensor_pos=nxt_sensor,\n",
    "                    goal=goal,\n",
    "                    detection=detection,\n",
    "                    max_steps=max_depth - depth - 1,\n",
    "                    w_step=w_step,\n",
    "                    w_detect=w_detect,\n",
    "                )\n",
    "                total_value += discount * leaf_v\n",
    "                # Backup along the path (we need to store path nodes/actions)\n",
    "                backup_path(root, robot_pos, goal, action_prior, cur_node, a, total_value)\n",
    "                break\n",
    "\n",
    "            # Continue down the tree\n",
    "            # Backup incrementally: we do a simpler backup at end; store transitions in a list for robust backup\n",
    "            cur_robot = nxt_robot\n",
    "            cur_sensor = nxt_sensor\n",
    "            cur_node = cur_node.children[a]\n",
    "        else:\n",
    "            # Depth limit reached; backup using total_value\n",
    "            # Use last chosen action if we had one; but for robustness we do a root-only backup\n",
    "            # (We still want stable results even if loop ended without expansion.)\n",
    "            root.N += 1\n",
    "\n",
    "    # Print root statistics\n",
    "    dprint(\"\\n[MCTS] === Root statistics ===\")\n",
    "    for a in ACTIONS:\n",
    "        n = root.N_a.get(a, 0)\n",
    "        q = root.Q_a.get(a, 0.0)\n",
    "        dprint(f\"[MCTS] a={a} | N={n:4d} | Q={q: .3f} | prior={action_prior.get(a,0):.3f}\")\n",
    "\n",
    "    # Choose action by max visits\n",
    "    best_a = max(ACTIONS, key=lambda a: root.N_a.get(a, 0))\n",
    "    dprint(f\"[MCTS] Selected action = {best_a} (max visit count)\")\n",
    "    return best_a\n",
    "\n",
    "\n",
    "# def select_action_puct(node: MCTSNode, prior: Dict[Action, float], c_puct: float) -> Action:\n",
    "    \"\"\"\n",
    "    PUCT selection:\n",
    "      argmax_a [ Q(s,a) + c * p(a) * sqrt(N(s)) / (1 + N(s,a)) ]\n",
    "\n",
    "    Notation:\n",
    "      - node.N is total visits of the node\n",
    "      - node.Q_a[a] is mean value estimate for action a\n",
    "      - node.N_a[a] is action visit count\n",
    "      - prior[a] is action prior probability\n",
    "    \"\"\"\n",
    "    if node.N <= 0:\n",
    "        node.N = 1  # prevent sqrt(0) issues\n",
    "\n",
    "    best_a = \"S\"\n",
    "    best_score = -float(\"inf\")\n",
    "    sqrtN = math.sqrt(node.N)\n",
    "\n",
    "    for a in ACTIONS:\n",
    "        q = node.Q_a.get(a, 0.0)\n",
    "        na = node.N_a.get(a, 0)\n",
    "        pa = prior.get(a, 1.0 / len(ACTIONS))\n",
    "        u = c_puct * pa * sqrtN / (1.0 + na)\n",
    "        score = q + u\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_a = a\n",
    "\n",
    "    return best_a\n",
    "\n",
    "\n",
    "def backup_path(\n",
    "    root: MCTSNode,\n",
    "    root_robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    prior: Dict[Action, float],\n",
    "    leaf_parent: MCTSNode,\n",
    "    leaf_action: Action,\n",
    "    total_value: float,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    For simplicity in this demo, we back up only into leaf_parent and root\n",
    "    with a lightweight robust update.\n",
    "\n",
    "    In a production implementation you'd record the full path of (node, action)\n",
    "    and update each entry. Here we keep it stable and readable.\n",
    "    \"\"\"\n",
    "    # Update leaf_parent stats\n",
    "    leaf_parent.N += 1\n",
    "    leaf_parent.N_a[leaf_action] += 1\n",
    "    na = leaf_parent.N_a[leaf_action]\n",
    "    old_q = leaf_parent.Q_a.get(leaf_action, 0.0)\n",
    "    leaf_parent.Q_a[leaf_action] = old_q + (total_value - old_q) / na\n",
    "\n",
    "    # Update root stats as well (so action counts accumulate)\n",
    "    root.N += 1\n",
    "    # We don't know which root action led here if leaf_parent isn't root;\n",
    "    # but in this demo we expand from root quickly, so leaf_parent is often root.\n",
    "    # If leaf_parent is root, this is correct.\n",
    "    if leaf_parent is root:\n",
    "        root.N_a[leaf_action] += 1\n",
    "        na2 = root.N_a[leaf_action]\n",
    "        old_q2 = root.Q_a.get(leaf_action, 0.0)\n",
    "        root.Q_a[leaf_action] = old_q2 + (total_value - old_q2) / na2\n",
    "\n",
    "\n",
    "\n",
    "def mcts_search_action_fixed(\n",
    "    world,\n",
    "    belief,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    sensor_policies,\n",
    "    detection,\n",
    "    action_prior: Dict[Action, float],\n",
    "    t: int,\n",
    "    num_sims: int = 250,\n",
    "    max_depth: int = 10,\n",
    "    c_puct: float = 1.4,\n",
    "    w_step: float = 1.0,\n",
    "    w_detect: float = 7.0,\n",
    "    gamma: float = 0.95,\n",
    "    debug: bool = True,\n",
    ") -> Action:\n",
    "\n",
    "    dprint(\"\\n[MCTS-FIX] === Starting fixed MCTS ===\", enabled=debug)\n",
    "\n",
    "    # Smooth the prior so it is never degenerate\n",
    "    prior = smooth_prior(action_prior, eps=0.10)\n",
    "\n",
    "    root = MCTSNode(robot_pos=robot_pos, depth=0)\n",
    "    root.P_a = prior\n",
    "    root.expanded = True\n",
    "\n",
    "    # Prepare particle sampling\n",
    "    particles = belief.particles if getattr(belief, \"particles\", None) else []\n",
    "    if not particles:\n",
    "        # fallback single hypothesis\n",
    "        class Dummy:\n",
    "            sensor_pos = robot_pos\n",
    "            mode_idx = 0\n",
    "            weight = 1.0\n",
    "        particles = [Dummy()]\n",
    "\n",
    "    weights = [float(getattr(p, \"weight\", 1.0)) for p in particles]\n",
    "    s = sum(weights)\n",
    "    if s <= 0:\n",
    "        weights = [1.0/len(weights)]*len(weights)\n",
    "    else:\n",
    "        weights = [w/s for w in weights]\n",
    "\n",
    "    for sim in range(num_sims):\n",
    "        hp = random.choices(particles, weights=weights, k=1)[0]\n",
    "        sim_sensor = hp.sensor_pos\n",
    "        sim_mode = hp.mode_idx\n",
    "\n",
    "        node = root\n",
    "        cur_robot = robot_pos\n",
    "        cur_sensor = sim_sensor\n",
    "\n",
    "        path: List[Tuple[MCTSNode, Action]] = []\n",
    "\n",
    "        total_return = 0.0\n",
    "        disc = 1.0\n",
    "\n",
    "        for depth in range(max_depth):\n",
    "            if cur_robot == goal:\n",
    "                total_return += disc * 50.0\n",
    "                break\n",
    "\n",
    "            a = select_action_puct(node, c_puct=c_puct)\n",
    "            path.append((node, a))\n",
    "\n",
    "            nxt_robot = world.step(cur_robot, a)\n",
    "            nxt_sensor = simulate_sensor_step(world, cur_sensor, nxt_robot, t + depth, sim_mode, sensor_policies)\n",
    "\n",
    "            step_cost = w_step + w_detect * detection.p_detect(nxt_robot, nxt_sensor)\n",
    "            reward = -step_cost\n",
    "            total_return += disc * reward\n",
    "            disc *= gamma\n",
    "\n",
    "            # Expand child if needed\n",
    "            if a not in node.children:\n",
    "                child = MCTSNode(robot_pos=nxt_robot, depth=node.depth + 1)\n",
    "\n",
    "                # IMPORTANT: give child the SAME prior (or you can compute state-dependent priors)\n",
    "                child.P_a = prior\n",
    "                child.expanded = True\n",
    "\n",
    "                node.children[a] = child\n",
    "\n",
    "                # Leaf evaluation (rollout)\n",
    "                leaf_v = rollout_value(\n",
    "                    world=world,\n",
    "                    robot_pos=nxt_robot,\n",
    "                    sensor_pos=nxt_sensor,\n",
    "                    goal=goal,\n",
    "                    detection=detection,\n",
    "                    max_steps=max_depth - depth - 1,\n",
    "                    w_step=w_step,\n",
    "                    w_detect=w_detect,\n",
    "                )\n",
    "                total_return += disc * leaf_v\n",
    "                break\n",
    "\n",
    "            # Continue\n",
    "            node = node.children[a]\n",
    "            cur_robot, cur_sensor = nxt_robot, nxt_sensor\n",
    "\n",
    "        # Backprop along full path\n",
    "        backprop_path(path, total_return)\n",
    "\n",
    "        if debug and (sim < 3 or (sim+1) % 50 == 0):\n",
    "            dprint(f\"[MCTS-FIX][DEBUG] sim={sim+1} root.N={root.N}\")\n",
    "\n",
    "    # Sanity check: root visits should be close to num_sims\n",
    "    total_edge_visits = sum(root.N_a.values())\n",
    "    dprint(f\"[MCTS-FIX] root.N={root.N} | sum(root.N_a)={total_edge_visits} | expected~{num_sims}\", enabled=debug)\n",
    "\n",
    "    dprint(\"[MCTS-FIX] Root action stats:\", enabled=debug)\n",
    "    for a in ACTIONS:\n",
    "        dprint(f\"  a={a} N={root.N_a[a]:4d} Q={root.Q_a[a]:+8.3f} P={root.P_a[a]:.3f}\", enabled=debug)\n",
    "\n",
    "    chosen = choose_final_action(root)\n",
    "    dprint(f\"[MCTS-FIX] Chosen action = {chosen}\", enabled=debug)\n",
    "    return chosen\n",
    "\n",
    "# =========================\n",
    "# Main Simulation Loop\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    seed: int = 7\n",
    "    H: int = 12\n",
    "    W: int = 18\n",
    "    T: int = 40  # max time steps\n",
    "    num_particles: int = 250\n",
    "\n",
    "    # Belief filter\n",
    "    motion_noise: float = 0.15\n",
    "    resample_threshold: float = 0.55\n",
    "\n",
    "    # Mode library\n",
    "    num_hypotheses: int = 25\n",
    "    per_hypothesis_attempts: int = 2\n",
    "    max_modes: int = 6\n",
    "    w_detect_astar: float = 10.0\n",
    "    rand_scale: float = 0.45\n",
    "\n",
    "    # MCTS\n",
    "    num_sims: int = 250\n",
    "    max_depth: int = 10\n",
    "    c_puct: float = 1.4\n",
    "    w_step_mcts: float = 1.0\n",
    "    w_detect_mcts: float = 7.0\n",
    "\n",
    "\n",
    "def make_demo_world(cfg: Config) -> Tuple[GridWorld, Tuple[int, int], Tuple[int, int], Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Create a world with a few obstacles and default start/goal positions.\n",
    "    \"\"\"\n",
    "    obs = set()\n",
    "    # Build some walls\n",
    "    for c in range(3, 15):\n",
    "        obs.add((5, c))\n",
    "    for r in range(1, 9):\n",
    "        obs.add((r, 9))\n",
    "    # Add a gap in wall\n",
    "    obs.discard((5, 7))\n",
    "    obs.discard((6, 9))\n",
    "\n",
    "    world = GridWorld(H=cfg.H, W=cfg.W, obstacles=obs)\n",
    "    robot_start = (10, 2)\n",
    "    goal = (1, 16)\n",
    "    sensor_start = (2, 2)\n",
    "    return world, robot_start, sensor_start, goal\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = Config()\n",
    "    seed_all(cfg.seed)\n",
    "\n",
    "    world, robot_pos, sensor_pos, goal = make_demo_world(cfg)\n",
    "\n",
    "    # Define sensor modes (policies)\n",
    "    sensor_modes: List[SensorModePolicy] = [\n",
    "        PatrolLoopPolicy(name=\"patrol_left\", loop=[(2, 2), (2, 6), (4, 6), (4, 2)]),\n",
    "        PatrolLoopPolicy(name=\"patrol_mid\", loop=[(2, 10), (2, 13), (4, 13), (4, 10)]),\n",
    "        ChasePolicy(name=\"chase_robot\"),\n",
    "        RandomWalkPolicy(name=\"random_walk\"),\n",
    "    ]\n",
    "    mode_names = [m.name for m in sensor_modes]\n",
    "\n",
    "    # Choose a true sensor mode (hidden from robot)\n",
    "    true_mode_idx = random.randrange(len(sensor_modes))\n",
    "    dprint(\"\\n[INIT] True sensor mode =\", mode_names[true_mode_idx])\n",
    "    dprint(\"[INIT] Robot start =\", robot_pos, \"Sensor start =\", sensor_pos, \"Goal =\", goal)\n",
    "\n",
    "    detection = DetectionModel()\n",
    "    obs_model = ObservationModel(sigma=1.3)\n",
    "\n",
    "    # Belief initialization: assume sensor starts somewhere near top-left / top-mid\n",
    "    sensor_init_candidates = [(2, 2), (2, 10), (3, 3), (3, 9), (1, 1)]\n",
    "    mode_prior = [1.0] * len(sensor_modes)  # uniform\n",
    "    belief = initialize_belief(world, sensor_init_candidates, mode_prior, mode_names, cfg.num_particles)\n",
    "\n",
    "    dprint(\"\\n[INIT] Initial belief mode posterior:\", format_mode_posterior(belief))\n",
    "    dprint(\"[INIT] Initial ESS:\", belief.effective_sample_size())\n",
    "\n",
    "    # Simulation\n",
    "    for t in range(cfg.T):\n",
    "        dprint(\"\\n\" + \"=\" * 80)\n",
    "        dprint(f\"[TIME] t={t}\")\n",
    "        dprint(\"=\" * 80)\n",
    "\n",
    "        # Render world\n",
    "        dprint(\"\\n[WORLD] Current grid:\")\n",
    "        world.render(robot=robot_pos, sensor=sensor_pos, goal=goal)\n",
    "\n",
    "        # Generate robot's observation of sensor (noisy)\n",
    "        obs = obs_model.sample_observation(sensor_pos, world)\n",
    "        dprint(f\"\\n[OBS] Robot observes noisy sensor position obs={obs} (true sensor_pos={sensor_pos})\")\n",
    "\n",
    "        # Update belief using particle filter\n",
    "        belief_predict_update(\n",
    "            belief=belief,\n",
    "            world=world,\n",
    "            robot_pos=robot_pos,\n",
    "            sensor_policies=sensor_modes,\n",
    "            obs_model=obs_model,\n",
    "            obs=obs,\n",
    "            t=t,\n",
    "            motion_noise=cfg.motion_noise,\n",
    "            resample_threshold=cfg.resample_threshold,\n",
    "        )\n",
    "        dprint(f\"[Belief] Mode posterior top: {belief.summary()}\")\n",
    "\n",
    "        # Build multimodal path library (MultiNash-PF-lite)\n",
    "        library = build_multimodal_path_library(\n",
    "            world=world,\n",
    "            belief=belief,\n",
    "            robot_pos=robot_pos,\n",
    "            goal=goal,\n",
    "            detection=detection,\n",
    "            num_hypotheses=cfg.num_hypotheses,\n",
    "            per_hypothesis_attempts=cfg.per_hypothesis_attempts,\n",
    "            w_detect=cfg.w_detect_astar,\n",
    "            rand_scale=cfg.rand_scale,\n",
    "            max_modes=cfg.max_modes,\n",
    "        )\n",
    "\n",
    "        # Convert library into an MCTS prior\n",
    "        action_prior = build_action_prior_from_library(world, robot_pos, library)\n",
    "        dprint(\"\\n[Prior] Derived action prior from modes:\", \" | \".join(f\"{a}:{action_prior.get(a,0):.3f}\" for a in ACTIONS))\n",
    "\n",
    "        # MCTS decide robot action\n",
    "        aR = mcts_search_action_fixed(\n",
    "            world=world,\n",
    "            belief=belief,\n",
    "            robot_pos=robot_pos,\n",
    "            goal=goal,\n",
    "            sensor_policies=sensor_modes,\n",
    "            detection=detection,\n",
    "            action_prior=action_prior,\n",
    "            t=t,\n",
    "            num_sims=cfg.num_sims,\n",
    "            max_depth=cfg.max_depth,\n",
    "            c_puct=cfg.c_puct,\n",
    "            w_step=cfg.w_step_mcts,\n",
    "            w_detect=cfg.w_detect_mcts,\n",
    "        )\n",
    "        dprint(f\"\\n[ACT] Robot takes action aR={aR}\")\n",
    "\n",
    "        # Step robot\n",
    "        new_robot = world.step(robot_pos, aR)\n",
    "\n",
    "        # Step sensor using true mode\n",
    "        aS_true = sensor_modes[true_mode_idx].action(world, sensor_pos, new_robot, t)\n",
    "        new_sensor = world.step(sensor_pos, aS_true)\n",
    "\n",
    "        dprint(f\"[ACT] True sensor action aS={aS_true}, moves {sensor_pos}->{new_sensor}\")\n",
    "        dprint(f\"[STEP] Robot moves {robot_pos}->{new_robot}\")\n",
    "\n",
    "        robot_pos, sensor_pos = new_robot, new_sensor\n",
    "\n",
    "        # Detection event\n",
    "        p_det = detection.p_detect(robot_pos, sensor_pos)\n",
    "        detected = (random.random() < p_det)\n",
    "        dprint(f\"[DETECT] p_det={p_det:.3f} => detected={detected}\")\n",
    "\n",
    "        # Terminal checks\n",
    "        if robot_pos == goal:\n",
    "            dprint(\"\\n[TERMINAL] Robot reached the goal! \")\n",
    "            break\n",
    "        if detected and manhattan(robot_pos, sensor_pos) <= detection.d0:\n",
    "            dprint(\"\\n[TERMINAL] Robot was detected and caught (close-range)! \")\n",
    "            break\n",
    "\n",
    "    dprint(\"\\n[DONE] Simulation finished.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96eaa19",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "main() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n",
      "\u001b[31mTypeError\u001b[39m: main() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "928f29b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] true_mode=chase_robot robot=(10, 2) sensor=(2, 2) goal=(1, 16)\n",
      "[INIT] belief modes: patrol_left:0.268 | random_walk:0.260 | patrol_mid:0.248 | chase_robot:0.224\n",
      "================================================================================\n",
      "[TIME] t=0\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      "..S......#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..R...............\n",
      "..................\n",
      "[OBS] obs=(2, 3) (true sensor=(2, 2))\n",
      "[PF] t=0 obs=(2, 3) ESS 250.0->91.6 resample=True | modes: patrol_left:0.348 | patrol_mid:0.296 | chase_robot:0.184\n",
      "[Modes] t=0 candidates=50 clusters=6 kept=6 best_costs=[34.8, 34.9, 37.5]\n",
      "[Prior] top: R:1.000 | U:0.000 | D:0.000\n",
      "[MCTS] t=0 sims=250 depth=10 prior_top: R:0.920 | U:0.020 | D:0.020\n",
      "[MCTS] t=0 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[STEP] robot=(10, 3) sensor=(2, 3) p_det=0.191 detected=False\n",
      "================================================================================\n",
      "[TIME] t=1\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      "...S.....#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "...R..............\n",
      "..................\n",
      "[OBS] obs=(1, 5) (true sensor=(2, 3))\n",
      "[PF] t=1 obs=(1, 5) ESS 250.0->140.5 resample=False | modes: patrol_mid:0.498 | patrol_left:0.385 | random_walk:0.077\n",
      "[Modes] t=1 candidates=50 clusters=6 kept=6 best_costs=[35.2, 35.4, 36.1]\n",
      "[Prior] top: R:1.000 | U:0.000 | D:0.000\n",
      "[MCTS] t=1 sims=250 depth=10 prior_top: R:0.920 | U:0.020 | D:0.020\n",
      "[MCTS] t=1 root.N=250 sum(N_a)=250 best_by_N=D\n",
      "[ACT] robot aR=D\n",
      "[STEP] robot=(11, 3) sensor=(3, 3) p_det=0.191 detected=False\n",
      "================================================================================\n",
      "[TIME] t=2\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      "...S.....#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "...R..............\n",
      "[OBS] obs=(5, 5) (true sensor=(3, 3))\n",
      "[PF] t=2 obs=(5, 5) ESS 140.5->76.6 resample=True | modes: patrol_mid:0.612 | patrol_left:0.324 | random_walk:0.048\n",
      "[Modes] t=2 candidates=50 clusters=6 kept=6 best_costs=[36.9, 37.6, 39.5]\n",
      "[Prior] top: R:1.000 | U:0.000 | D:0.000\n",
      "[MCTS] t=2 sims=250 depth=10 prior_top: R:0.920 | U:0.020 | D:0.020\n",
      "[MCTS] t=2 root.N=250 sum(N_a)=250 best_by_N=L\n",
      "[ACT] robot aR=L\n",
      "[STEP] robot=(11, 2) sensor=(3, 2) p_det=0.191 detected=False\n",
      "[PF] t=3 obs=(4, 4) ESS 250.0->136.5 resample=True | modes: patrol_mid:0.588 | patrol_left:0.360 | random_walk:0.044\n",
      "[PF] t=4 obs=(5, 0) ESS 250.0->71.2 resample=True | modes: patrol_left:0.584 | patrol_mid:0.260 | chase_robot:0.108\n",
      "================================================================================\n",
      "[TIME] t=5\n",
      "[OBS] obs=(5, 0) (true sensor=(5, 2))\n",
      "[PF] t=5 obs=(5, 0) ESS 250.0->67.8 resample=True | modes: chase_robot:0.540 | patrol_left:0.404 | patrol_mid:0.032\n",
      "[Modes] t=5 candidates=50 clusters=6 kept=6 best_costs=[35.0, 35.3, 35.7]\n",
      "[Prior] top: R:1.000 | U:0.000 | D:0.000\n",
      "[MCTS] t=5 sims=250 depth=10 prior_top: R:0.920 | U:0.020 | D:0.020\n",
      "[MCTS] t=5 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[STEP] robot=(11, 4) sensor=(6, 2) p_det=0.240 detected=False\n",
      "[PF] t=6 obs=(4, 4) ESS 250.0->103.8 resample=True | modes: patrol_left:0.676 | chase_robot:0.240 | random_walk:0.044\n",
      "[PF] t=7 obs=(8, 0) ESS 250.0->38.6 resample=True | modes: chase_robot:0.648 | patrol_left:0.336 | random_walk:0.012\n",
      "[PF] t=9 obs=(8, 2) ESS 150.8->71.3 resample=True | modes: chase_robot:0.996 | patrol_left:0.004\n",
      "================================================================================\n",
      "[TIME] t=10\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "...S..............\n",
      "..................\n",
      "........R.........\n",
      "[OBS] obs=(8, 4) (true sensor=(9, 3))\n",
      "[PF] t=10 obs=(8, 4) ESS 250.0->145.1 resample=False | modes: chase_robot:1.000 | patrol_left:0.000\n",
      "[Modes] t=10 candidates=50 clusters=6 kept=6 best_costs=[30.4, 30.7, 30.8]\n",
      "[Prior] top: R:1.000 | U:0.000 | D:0.000\n",
      "[MCTS] t=10 sims=250 depth=10 prior_top: R:0.920 | U:0.020 | D:0.020\n",
      "[MCTS] t=10 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[STEP] robot=(11, 9) sensor=(10, 3) p_det=0.240 detected=True\n",
      "[PF] t=11 obs=(8, 2) ESS 145.1->127.2 resample=True | modes: chase_robot:1.000\n",
      "[PF] t=14 obs=(9, 3) ESS 141.9->132.4 resample=True | modes: chase_robot:1.000\n",
      "================================================================================\n",
      "[TIME] t=15\n",
      "[OBS] obs=(9, 8) (true sensor=(11, 6))\n",
      "[PF] t=15 obs=(9, 8) ESS 250.0->98.1 resample=True | modes: chase_robot:1.000\n",
      "[Modes] t=15 candidates=50 clusters=6 kept=6 best_costs=[21.6, 22.0, 22.7]\n",
      "[Prior] top: U:0.509 | R:0.491 | D:0.000\n",
      "[MCTS] t=15 sims=250 depth=10 prior_top: U:0.478 | R:0.462 | D:0.020\n",
      "[MCTS] t=15 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[STEP] robot=(11, 14) sensor=(11, 7) p_det=0.240 detected=False\n",
      "[PF] t=17 obs=(11, 7) ESS 168.8->126.7 resample=True | modes: chase_robot:1.000\n",
      "[PF] t=19 obs=(10, 8) ESS 174.2->113.1 resample=True | modes: chase_robot:1.000\n",
      "================================================================================\n",
      "[TIME] t=20\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "................R.\n",
      "..................\n",
      "...........S......\n",
      "[OBS] obs=(11, 11) (true sensor=(11, 11))\n",
      "[PF] t=20 obs=(11, 11) ESS 250.0->113.4 resample=True | modes: chase_robot:1.000\n",
      "[Modes] t=20 candidates=50 clusters=1 kept=1 best_costs=[13.6]\n",
      "[Prior] top: U:1.000 | D:0.000 | L:0.000\n",
      "[MCTS] t=20 sims=250 depth=10 prior_top: U:0.920 | D:0.020 | L:0.020\n",
      "[MCTS] t=20 root.N=250 sum(N_a)=250 best_by_N=U\n",
      "[ACT] robot aR=U\n",
      "[STEP] robot=(8, 16) sensor=(10, 11) p_det=0.240 detected=False\n",
      "[PF] t=22 obs=(10, 10) ESS 165.5->92.6 resample=True | modes: chase_robot:1.000\n",
      "[PF] t=23 obs=(11, 12) ESS 250.0->114.4 resample=True | modes: chase_robot:1.000\n",
      "================================================================================\n",
      "[TIME] t=25\n",
      "[OBS] obs=(7, 14) (true sensor=(8, 13))\n",
      "[PF] t=25 obs=(7, 14) ESS 162.7->75.5 resample=True | modes: chase_robot:1.000\n",
      "[Modes] t=25 candidates=50 clusters=1 kept=1 best_costs=[5.3]\n",
      "[Prior] top: U:1.000 | D:0.000 | L:0.000\n",
      "[MCTS] t=25 sims=250 depth=10 prior_top: U:0.920 | D:0.020 | L:0.020\n",
      "[MCTS] t=25 root.N=250 sum(N_a)=250 best_by_N=U\n",
      "[ACT] robot aR=U\n",
      "[STEP] robot=(3, 16) sensor=(7, 13) p_det=0.240 detected=False\n",
      "[PF] t=27 obs=(6, 13) ESS 152.3->87.7 resample=True | modes: chase_robot:1.000\n",
      "[TERMINAL] reached goal \n",
      "[DONE]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"GenBR-lite + PF Belief + Multimodal Path Library (debug-robust)\n",
    "\n",
    "What changed vs the earlier version:\n",
    "- Much quieter logging by default: prints only on early timesteps + periodic summaries.\n",
    "- Stronger invariants + sanity checks (probability normalization, ESS bounds, MCTS visit counts).\n",
    "- Removed broken/duplicate MCTS code paths; kept a single robust MCTS implementation.\n",
    "- Mode-library builder prints only a compact summary unless you enable detail.\n",
    "\n",
    "Run:\n",
    "  python3 this_file.py\n",
    "\n",
    "Toggle logging in Config.debug.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import random\n",
    "import heapq\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional, Iterable, Callable, Any, Set\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Debug / Logging utilities\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class DebugConfig:\n",
    "    enabled: bool = True\n",
    "    level: int = 1\n",
    "    # 0 = silent\n",
    "    # 1 = periodic summaries\n",
    "    # 2 = detailed (still gated)\n",
    "\n",
    "    # Print detail for the first few timesteps\n",
    "    detail_until_t: int = 2\n",
    "\n",
    "    # Periodic summary controls\n",
    "    summary_every_t: int = 5\n",
    "    render_every_t: int = 10\n",
    "\n",
    "    # Stage-specific periodic prints\n",
    "    pf_every_t: int = 5\n",
    "    modes_every_t: int = 5\n",
    "    mcts_every_t: int = 5\n",
    "\n",
    "    # Within MCTS\n",
    "    mcts_progress_every_sims: int = 50\n",
    "\n",
    "    # Safety: cap printing of mode hypotheses even at detail level\n",
    "    max_hyp_print: int = 3\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, cfg: DebugConfig):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def _should_print(self, t: Optional[int], every: Optional[int], lvl: int) -> bool:\n",
    "        if not self.cfg.enabled:\n",
    "            return False\n",
    "        if lvl > self.cfg.level:\n",
    "            return False\n",
    "        if t is None:\n",
    "            return True\n",
    "        if t <= self.cfg.detail_until_t:\n",
    "            return True\n",
    "        if every is None:\n",
    "            return False\n",
    "        return (every > 0) and (t % every == 0)\n",
    "\n",
    "    def log(self, msg: str, *, t: Optional[int] = None, every: Optional[int] = None, lvl: int = 1, force: bool = False) -> None:\n",
    "        if force or self._should_print(t, every, lvl):\n",
    "            print(msg)\n",
    "\n",
    "\n",
    "def soft_assert(cond: bool, msg: str, *, fatal: bool = False, log: Optional[Logger] = None, t: Optional[int] = None) -> None:\n",
    "    if cond:\n",
    "        return\n",
    "    if log is not None:\n",
    "        log.log(f\"[WARN] {msg}\", t=t, every=None, lvl=1, force=True)\n",
    "    if fatal:\n",
    "        raise AssertionError(msg)\n",
    "\n",
    "\n",
    "def clamp(x: float, lo: float, hi: float) -> float:\n",
    "    return max(lo, min(hi, x))\n",
    "\n",
    "\n",
    "def manhattan(a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "\n",
    "def seed_all(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "def stable_bucket(sig: str, m: int) -> int:\n",
    "    \"\"\"Stable mapping sig -> [0..m-1] independent of Python's randomized hash.\"\"\"\n",
    "    if m <= 0:\n",
    "        return 0\n",
    "    h = hashlib.md5(sig.encode(\"utf-8\")).hexdigest()\n",
    "    return int(h[:8], 16) % m\n",
    "\n",
    "\n",
    "def normalize_probs_dict(d: Dict[Any, float], keys: Iterable[Any], *, eps: float = 0.0) -> Dict[Any, float]:\n",
    "    \"\"\"Return a normalized distribution over `keys` from possibly-missing/negative inputs.\n",
    "\n",
    "    - Clips negatives to 0\n",
    "    - Adds optional epsilon smoothing to avoid degeneracy\n",
    "    - Falls back to uniform if total mass is 0\n",
    "    \"\"\"\n",
    "    klist = list(keys)\n",
    "    out = {k: max(0.0, float(d.get(k, 0.0))) for k in klist}\n",
    "    s = sum(out.values())\n",
    "\n",
    "    if s <= 0.0:\n",
    "        # uniform\n",
    "        u = 1.0 / max(1, len(klist))\n",
    "        return {k: u for k in klist}\n",
    "\n",
    "    out = {k: v / s for k, v in out.items()}\n",
    "\n",
    "    if eps > 0.0:\n",
    "        u = 1.0 / max(1, len(klist))\n",
    "        out = {k: (1.0 - eps) * out[k] + eps * u for k in klist}\n",
    "        s2 = sum(out.values())\n",
    "        out = {k: v / s2 for k, v in out.items()}\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def topk_str(d: Dict[Any, float], k: int = 3, fmt: str = \"{k}:{v:.3f}\") -> str:\n",
    "    items = sorted(d.items(), key=lambda kv: kv[1], reverse=True)[:k]\n",
    "    return \" | \".join(fmt.format(k=kk, v=vv) for kk, vv in items)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Gridworld Environment\n",
    "# =========================\n",
    "\n",
    "Action = str  # 'U','D','L','R','S'\n",
    "\n",
    "ACTIONS: List[Action] = [\"U\", \"D\", \"L\", \"R\", \"S\"]\n",
    "ACTION_DELTAS: Dict[Action, Tuple[int, int]] = {\n",
    "    \"U\": (-1, 0),\n",
    "    \"D\": (1, 0),\n",
    "    \"L\": (0, -1),\n",
    "    \"R\": (0, 1),\n",
    "    \"S\": (0, 0),\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GridWorld:\n",
    "    H: int\n",
    "    W: int\n",
    "    obstacles: Set[Tuple[int, int]] = field(default_factory=set)\n",
    "\n",
    "    def in_bounds(self, p: Tuple[int, int]) -> bool:\n",
    "        r, c = p\n",
    "        return 0 <= r < self.H and 0 <= c < self.W\n",
    "\n",
    "    def is_free(self, p: Tuple[int, int]) -> bool:\n",
    "        return self.in_bounds(p) and (p not in self.obstacles)\n",
    "\n",
    "    def step(self, p: Tuple[int, int], a: Action) -> Tuple[int, int]:\n",
    "        if a not in ACTION_DELTAS:\n",
    "            raise ValueError(f\"Unknown action: {a}\")\n",
    "        dr, dc = ACTION_DELTAS[a]\n",
    "        np = (p[0] + dr, p[1] + dc)\n",
    "        return np if self.is_free(np) else p\n",
    "\n",
    "    def neighbors(self, p: Tuple[int, int]) -> List[Tuple[Tuple[int, int], Action]]:\n",
    "        return [(self.step(p, a), a) for a in ACTIONS]\n",
    "\n",
    "    def render(self, robot: Tuple[int, int], sensor: Tuple[int, int], goal: Tuple[int, int]) -> None:\n",
    "        grid = [[\".\" for _ in range(self.W)] for _ in range(self.H)]\n",
    "        for (r, c) in self.obstacles:\n",
    "            grid[r][c] = \"#\"\n",
    "        rr, rc = robot\n",
    "        sr, sc = sensor\n",
    "        gr, gc = goal\n",
    "        grid[gr][gc] = \"G\"\n",
    "        grid[sr][sc] = \"S\"\n",
    "        grid[rr][rc] = \"R\"\n",
    "        for r in range(self.H):\n",
    "            print(\"\".join(grid[r]))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Sensor Models (Modes)\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class SensorModePolicy:\n",
    "    name: str\n",
    "\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def greedy_step_toward(world: GridWorld, src: Tuple[int, int], dst: Tuple[int, int]) -> Action:\n",
    "    best_actions: List[Action] = []\n",
    "    best_dist = 10**9\n",
    "    for a in ACTIONS:\n",
    "        np = world.step(src, a)\n",
    "        d = manhattan(np, dst)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_actions = [a]\n",
    "        elif d == best_dist:\n",
    "            best_actions.append(a)\n",
    "    return random.choice(best_actions) if best_actions else \"S\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PatrolLoopPolicy(SensorModePolicy):\n",
    "    loop: List[Tuple[int, int]] = field(default_factory=list)\n",
    "\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        if not self.loop:\n",
    "            return \"S\"\n",
    "        idx = t % len(self.loop)\n",
    "        return greedy_step_toward(world, sensor_pos, self.loop[idx])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ChasePolicy(SensorModePolicy):\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        return greedy_step_toward(world, sensor_pos, robot_pos)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RandomWalkPolicy(SensorModePolicy):\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        return random.choice(ACTIONS)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Detection / Observation\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class DetectionModel:\n",
    "    d0: int = 2\n",
    "    p_close: float = 0.9\n",
    "    p_far: float = 0.05\n",
    "    decay: float = 0.3\n",
    "\n",
    "    def p_detect(self, robot_pos: Tuple[int, int], sensor_pos: Tuple[int, int]) -> float:\n",
    "        dist = manhattan(robot_pos, sensor_pos)\n",
    "        if dist <= self.d0:\n",
    "            return self.p_close\n",
    "        return self.p_far + (self.p_close - self.p_far) * math.exp(-self.decay * (dist - self.d0))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ObservationModel:\n",
    "    sigma: float = 1.2\n",
    "\n",
    "    def sample_observation(self, sensor_pos: Tuple[int, int], world: GridWorld) -> Tuple[int, int]:\n",
    "        max_jump = 2\n",
    "        dr = random.randint(-max_jump, max_jump)\n",
    "        dc = random.randint(-max_jump, max_jump)\n",
    "        o = (sensor_pos[0] + dr, sensor_pos[1] + dc)\n",
    "        o = (int(clamp(o[0], 0, world.H - 1)), int(clamp(o[1], 0, world.W - 1)))\n",
    "        return o\n",
    "\n",
    "    def likelihood(self, obs: Tuple[int, int], sensor_pos: Tuple[int, int]) -> float:\n",
    "        d = manhattan(obs, sensor_pos)\n",
    "        return max(1e-12, math.exp(-d / max(1e-6, self.sigma)))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Particle Filter over (sensor_pos, mode)\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class Particle:\n",
    "    sensor_pos: Tuple[int, int]\n",
    "    mode_idx: int\n",
    "    weight: float = 1.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BeliefState:\n",
    "    particles: List[Particle]\n",
    "    mode_names: List[str]\n",
    "\n",
    "    def normalize(self) -> None:\n",
    "        s = sum(p.weight for p in self.particles)\n",
    "        if s <= 0.0:\n",
    "            w = 1.0 / max(1, len(self.particles))\n",
    "            for p in self.particles:\n",
    "                p.weight = w\n",
    "            return\n",
    "        for p in self.particles:\n",
    "            p.weight /= s\n",
    "\n",
    "    def effective_sample_size(self) -> float:\n",
    "        s = sum(p.weight * p.weight for p in self.particles)\n",
    "        return 0.0 if s <= 0.0 else 1.0 / s\n",
    "\n",
    "    def mode_posterior(self) -> Dict[int, float]:\n",
    "        post: Dict[int, float] = defaultdict(float)\n",
    "        for p in self.particles:\n",
    "            post[p.mode_idx] += p.weight\n",
    "        return dict(post)\n",
    "\n",
    "    def mode_posterior_named(self) -> Dict[str, float]:\n",
    "        post_i = self.mode_posterior()\n",
    "        out: Dict[str, float] = {}\n",
    "        for i, v in post_i.items():\n",
    "            name = self.mode_names[i] if 0 <= i < len(self.mode_names) else f\"mode{i}\"\n",
    "            out[name] = out.get(name, 0.0) + v\n",
    "        return out\n",
    "\n",
    "\n",
    "def systematic_resample(particles: List[Particle]) -> List[Particle]:\n",
    "    n = len(particles)\n",
    "    if n == 0:\n",
    "        return []\n",
    "    positions = [(random.random() + i) / n for i in range(n)]\n",
    "    cumulative = []\n",
    "    csum = 0.0\n",
    "    for p in particles:\n",
    "        csum += p.weight\n",
    "        cumulative.append(csum)\n",
    "\n",
    "    out: List[Particle] = []\n",
    "    i = 0\n",
    "    for pos in positions:\n",
    "        while i < n - 1 and pos > cumulative[i]:\n",
    "            i += 1\n",
    "        chosen = particles[i]\n",
    "        out.append(Particle(sensor_pos=chosen.sensor_pos, mode_idx=chosen.mode_idx, weight=1.0 / n))\n",
    "    return out\n",
    "\n",
    "\n",
    "def initialize_belief(\n",
    "    world: GridWorld,\n",
    "    sensor_init_candidates: List[Tuple[int, int]],\n",
    "    mode_prior: List[float],\n",
    "    mode_names: List[str],\n",
    "    num_particles: int = 200,\n",
    ") -> BeliefState:\n",
    "    if len(mode_prior) != len(mode_names):\n",
    "        raise ValueError(\"mode_prior and mode_names must have same length\")\n",
    "    if not sensor_init_candidates:\n",
    "        raise ValueError(\"Need at least one sensor init candidate\")\n",
    "    if num_particles <= 0:\n",
    "        raise ValueError(\"num_particles must be > 0\")\n",
    "\n",
    "    # normalize prior\n",
    "    s = sum(mode_prior)\n",
    "    if s <= 0.0:\n",
    "        mode_prior = [1.0 / len(mode_prior)] * len(mode_prior)\n",
    "    else:\n",
    "        mode_prior = [p / s for p in mode_prior]\n",
    "\n",
    "    def sample_mode() -> int:\n",
    "        r = random.random()\n",
    "        c = 0.0\n",
    "        for i, p in enumerate(mode_prior):\n",
    "            c += p\n",
    "            if r <= c:\n",
    "                return i\n",
    "        return len(mode_prior) - 1\n",
    "\n",
    "    particles: List[Particle] = []\n",
    "    for _ in range(num_particles):\n",
    "        sp = random.choice(sensor_init_candidates)\n",
    "        z = sample_mode()\n",
    "        particles.append(Particle(sensor_pos=sp, mode_idx=z, weight=1.0 / num_particles))\n",
    "\n",
    "    b = BeliefState(particles=particles, mode_names=mode_names)\n",
    "    b.normalize()\n",
    "    return b\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PFStepInfo:\n",
    "    ess_before: float\n",
    "    ess_after: float\n",
    "    resampled: bool\n",
    "\n",
    "\n",
    "def belief_predict_update(\n",
    "    belief: BeliefState,\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    sensor_policies: List[SensorModePolicy],\n",
    "    obs_model: ObservationModel,\n",
    "    obs: Tuple[int, int],\n",
    "    t: int,\n",
    "    *,\n",
    "    motion_noise: float = 0.10,\n",
    "    resample_threshold: float = 0.5,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> PFStepInfo:\n",
    "    if not belief.particles:\n",
    "        raise ValueError(\"belief has no particles\")\n",
    "\n",
    "    belief.normalize()\n",
    "    ess0 = belief.effective_sample_size()\n",
    "\n",
    "    # Predict + weight update\n",
    "    for p in belief.particles:\n",
    "        mi = p.mode_idx\n",
    "        if 0 <= mi < len(sensor_policies):\n",
    "            aS = sensor_policies[mi].action(world, p.sensor_pos, robot_pos, t)\n",
    "        else:\n",
    "            aS = \"S\"\n",
    "\n",
    "        predicted = world.step(p.sensor_pos, aS)\n",
    "        if random.random() < motion_noise:\n",
    "            predicted = world.step(predicted, random.choice(ACTIONS))\n",
    "\n",
    "        p.sensor_pos = predicted\n",
    "        p.weight *= obs_model.likelihood(obs, p.sensor_pos)\n",
    "\n",
    "    belief.normalize()\n",
    "    ess1 = belief.effective_sample_size()\n",
    "\n",
    "    # Sanity checks\n",
    "    N = len(belief.particles)\n",
    "    soft_assert(0.0 <= ess1 <= N + 1e-6, f\"ESS out of bounds: {ess1} (N={N})\", log=log, t=t)\n",
    "\n",
    "    resampled = False\n",
    "    if ess1 < resample_threshold * N:\n",
    "        belief.particles = systematic_resample(belief.particles)\n",
    "        belief.normalize()\n",
    "        resampled = True\n",
    "\n",
    "    # Controlled prints\n",
    "    if log is not None:\n",
    "        if log._should_print(t, log.cfg.pf_every_t, lvl=1) or resampled:\n",
    "            mp = belief.mode_posterior_named()\n",
    "            log.log(\n",
    "                f\"[PF] t={t} obs={obs} ESS {ess0:.1f}->{ess1:.1f} resample={resampled} | modes: {topk_str(mp, k=3)}\",\n",
    "                t=t,\n",
    "                every=log.cfg.pf_every_t,\n",
    "                lvl=1,\n",
    "                force=resampled,\n",
    "            )\n",
    "            if log.cfg.level >= 2 and t <= log.cfg.detail_until_t:\n",
    "                log.log(f\"[PF][detail] full mode posterior: {topk_str(mp, k=10)}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    return PFStepInfo(ess_before=ess0, ess_after=ess1, resampled=resampled)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# A* Search with Risk Costs\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class AStarResult:\n",
    "    path: List[Tuple[int, int]]\n",
    "    cost: float\n",
    "    expanded: int\n",
    "\n",
    "\n",
    "def astar_path(\n",
    "    world: GridWorld,\n",
    "    start: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    step_cost: Callable[[Tuple[int, int]], float],\n",
    "    heuristic: Callable[[Tuple[int, int]], float],\n",
    "    *,\n",
    "    max_expansions: int = 50_000,\n",
    ") -> Optional[AStarResult]:\n",
    "    if not world.is_free(start) or not world.is_free(goal):\n",
    "        return None\n",
    "\n",
    "    frontier: List[Tuple[float, float, Tuple[int, int]]] = []\n",
    "    heapq.heappush(frontier, (heuristic(start), 0.0, start))\n",
    "\n",
    "    came_from: Dict[Tuple[int, int], Tuple[int, int]] = {}\n",
    "    gscore: Dict[Tuple[int, int], float] = {start: 0.0}\n",
    "\n",
    "    expanded = 0\n",
    "\n",
    "    # A* with reopen: skip stale pops\n",
    "    while frontier and expanded < max_expansions:\n",
    "        f, g, cur = heapq.heappop(frontier)\n",
    "        if g > gscore.get(cur, float(\"inf\")) + 1e-12:\n",
    "            continue\n",
    "        expanded += 1\n",
    "\n",
    "        if cur == goal:\n",
    "            path = [cur]\n",
    "            while cur in came_from:\n",
    "                cur = came_from[cur]\n",
    "                path.append(cur)\n",
    "            path.reverse()\n",
    "            return AStarResult(path=path, cost=gscore[goal], expanded=expanded)\n",
    "\n",
    "        for (nxt, _) in world.neighbors(cur):\n",
    "            if not world.is_free(nxt):\n",
    "                continue\n",
    "            sc = step_cost(nxt)\n",
    "            if not math.isfinite(sc) or sc < 0:\n",
    "                continue\n",
    "            ng = gscore[cur] + sc\n",
    "            if ng + 1e-12 < gscore.get(nxt, float(\"inf\")):\n",
    "                gscore[nxt] = ng\n",
    "                came_from[nxt] = cur\n",
    "                heapq.heappush(frontier, (ng + heuristic(nxt), ng, nxt))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Multimodal Path Library\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class PathMode:\n",
    "    path: List[Tuple[int, int]]\n",
    "    total_cost: float\n",
    "    hypothesis_sensor_pos: Tuple[int, int]\n",
    "    hypothesis_mode_idx: int\n",
    "    debug_info: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def build_cost_map_from_hypothesis(\n",
    "    world: GridWorld,\n",
    "    detection: DetectionModel,\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    *,\n",
    "    base_step: float,\n",
    "    w_detect: float,\n",
    "    randomize: bool,\n",
    "    rand_scale: float,\n",
    ") -> Callable[[Tuple[int, int]], float]:\n",
    "    def cost_fn(s: Tuple[int, int]) -> float:\n",
    "        if not world.is_free(s):\n",
    "            return float(\"inf\")\n",
    "        p_det = detection.p_detect(robot_pos=s, sensor_pos=sensor_pos)\n",
    "        c = base_step + w_detect * p_det\n",
    "        if randomize:\n",
    "            c *= (1.0 + rand_scale * (random.random() - 0.5))\n",
    "            c = max(1e-6, c)\n",
    "        return c\n",
    "\n",
    "    return cost_fn\n",
    "\n",
    "\n",
    "def cluster_paths_by_signature(paths: List[List[Tuple[int, int]]], *, max_modes: int) -> List[int]:\n",
    "    sig_to_cluster: Dict[str, int] = {}\n",
    "    assignments: List[int] = []\n",
    "\n",
    "    def signature(path: List[Tuple[int, int]]) -> str:\n",
    "        if len(path) < 2:\n",
    "            return \"EMPTY\"\n",
    "        dirs = []\n",
    "        for i in range(1, len(path)):\n",
    "            dr = path[i][0] - path[i - 1][0]\n",
    "            dc = path[i][1] - path[i - 1][1]\n",
    "            dirs.append((dr, dc))\n",
    "\n",
    "        comp = []\n",
    "        for d in dirs:\n",
    "            if not comp or comp[-1] != d:\n",
    "                comp.append(d)\n",
    "\n",
    "        m = {(-1, 0): \"U\", (1, 0): \"D\", (0, -1): \"L\", (0, 1): \"R\", (0, 0): \"S\"}\n",
    "        return \"\".join(m.get(d, \"?\") for d in comp)[:120]\n",
    "\n",
    "    for p in paths:\n",
    "        sig = signature(p)\n",
    "\n",
    "        if sig in sig_to_cluster:\n",
    "            cid = sig_to_cluster[sig]\n",
    "        elif len(sig_to_cluster) < max_modes:\n",
    "            cid = len(sig_to_cluster)\n",
    "            sig_to_cluster[sig] = cid\n",
    "        else:\n",
    "            # stable assignment to an existing bucket\n",
    "            cid = stable_bucket(sig, len(sig_to_cluster))\n",
    "\n",
    "        assignments.append(cid)\n",
    "\n",
    "    return assignments\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModeLibraryInfo:\n",
    "    num_candidates: int\n",
    "    num_clusters: int\n",
    "\n",
    "\n",
    "def build_multimodal_path_library(\n",
    "    world: GridWorld,\n",
    "    belief: BeliefState,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    detection: DetectionModel,\n",
    "    *,\n",
    "    num_hypotheses: int = 30,\n",
    "    per_hypothesis_attempts: int = 2,\n",
    "    base_step_cost: float = 1.0,\n",
    "    w_detect: float = 8.0,\n",
    "    rand_scale: float = 0.40,\n",
    "    max_modes: int = 6,\n",
    "    t: int = 0,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> Tuple[List[PathMode], ModeLibraryInfo]:\n",
    "    if not belief.particles:\n",
    "        return [], ModeLibraryInfo(num_candidates=0, num_clusters=0)\n",
    "\n",
    "    # Sample particles proportional to weight\n",
    "    weights = [p.weight for p in belief.particles]\n",
    "    s = sum(weights)\n",
    "    if s <= 0.0:\n",
    "        weights = [1.0 / len(weights)] * len(weights)\n",
    "    else:\n",
    "        weights = [w / s for w in weights]\n",
    "\n",
    "    sampled_particles = random.choices(belief.particles, weights=weights, k=num_hypotheses)\n",
    "\n",
    "    candidates: List[PathMode] = []\n",
    "\n",
    "    # Only print a couple hypotheses in detail\n",
    "    hyp_print_budget = log.cfg.max_hyp_print if (log and log.cfg.level >= 2 and t <= log.cfg.detail_until_t) else 0\n",
    "\n",
    "    for hi, hp in enumerate(sampled_particles):\n",
    "        hyp_sensor = hp.sensor_pos\n",
    "        hyp_mode = hp.mode_idx\n",
    "\n",
    "        if log is not None and hyp_print_budget > 0:\n",
    "            log.log(\n",
    "                f\"[Modes][detail] t={t} hyp#{hi+1}/{num_hypotheses} sensor={hyp_sensor} mode={belief.mode_names[hyp_mode] if 0<=hyp_mode<len(belief.mode_names) else hyp_mode}\",\n",
    "                t=t,\n",
    "                every=None,\n",
    "                lvl=2,\n",
    "            )\n",
    "            hyp_print_budget -= 1\n",
    "\n",
    "        for attempt in range(per_hypothesis_attempts):\n",
    "            cost_fn = build_cost_map_from_hypothesis(\n",
    "                world,\n",
    "                detection,\n",
    "                hyp_sensor,\n",
    "                base_step=base_step_cost,\n",
    "                w_detect=w_detect,\n",
    "                randomize=True,\n",
    "                rand_scale=rand_scale,\n",
    "            )\n",
    "            heur = lambda s: float(manhattan(s, goal))\n",
    "\n",
    "            res = astar_path(world, robot_pos, goal, step_cost=cost_fn, heuristic=heur)\n",
    "            if res is None:\n",
    "                continue\n",
    "\n",
    "            candidates.append(\n",
    "                PathMode(\n",
    "                    path=res.path,\n",
    "                    total_cost=res.cost,\n",
    "                    hypothesis_sensor_pos=hyp_sensor,\n",
    "                    hypothesis_mode_idx=hyp_mode,\n",
    "                    debug_info={\"expanded\": res.expanded, \"attempt\": attempt + 1},\n",
    "                )\n",
    "            )\n",
    "\n",
    "    if not candidates:\n",
    "        if log is not None and log._should_print(t, log.cfg.modes_every_t, lvl=1):\n",
    "            log.log(f\"[Modes] t={t} candidates=0 (no paths found)\", t=t, every=log.cfg.modes_every_t, lvl=1)\n",
    "        return [], ModeLibraryInfo(num_candidates=0, num_clusters=0)\n",
    "\n",
    "    # Cluster and keep best per cluster\n",
    "    cluster_ids = cluster_paths_by_signature([c.path for c in candidates], max_modes=max_modes)\n",
    "\n",
    "    best_by_cluster: Dict[int, PathMode] = {}\n",
    "    for c, cid in zip(candidates, cluster_ids):\n",
    "        if cid not in best_by_cluster or c.total_cost < best_by_cluster[cid].total_cost:\n",
    "            best_by_cluster[cid] = c\n",
    "\n",
    "    library = sorted(best_by_cluster.values(), key=lambda pm: pm.total_cost)[:max_modes]\n",
    "\n",
    "    if log is not None and log._should_print(t, log.cfg.modes_every_t, lvl=1):\n",
    "        costs = [pm.total_cost for pm in library]\n",
    "        cost_str = \", \".join(f\"{c:.1f}\" for c in costs[:min(3, len(costs))])\n",
    "        log.log(\n",
    "            f\"[Modes] t={t} candidates={len(candidates)} clusters={len(best_by_cluster)} kept={len(library)} best_costs=[{cost_str}]\",\n",
    "            t=t,\n",
    "            every=log.cfg.modes_every_t,\n",
    "            lvl=1,\n",
    "        )\n",
    "\n",
    "    return library, ModeLibraryInfo(num_candidates=len(candidates), num_clusters=len(best_by_cluster))\n",
    "\n",
    "\n",
    "def first_action_from_path(world: GridWorld, start: Tuple[int, int], path: List[Tuple[int, int]]) -> Action:\n",
    "    if len(path) < 2:\n",
    "        return \"S\"\n",
    "    nxt = path[1]\n",
    "    dr = nxt[0] - start[0]\n",
    "    dc = nxt[1] - start[1]\n",
    "    for a, (adr, adc) in ACTION_DELTAS.items():\n",
    "        if (dr, dc) == (adr, adc):\n",
    "            return a\n",
    "    return \"S\"\n",
    "\n",
    "\n",
    "def build_action_prior_from_library(world: GridWorld, robot_pos: Tuple[int, int], library: List[PathMode]) -> Dict[Action, float]:\n",
    "    if not library:\n",
    "        return {a: 1.0 / len(ACTIONS) for a in ACTIONS}\n",
    "\n",
    "    pri_raw: Dict[Action, float] = defaultdict(float)\n",
    "    for pm in library:\n",
    "        a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "        pri_raw[a0] += 1.0 / max(1e-6, pm.total_cost)\n",
    "\n",
    "    return normalize_probs_dict(pri_raw, ACTIONS)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# GenBR-lite: Belief-space MCTS with PUCT\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class MCTSNode:\n",
    "    robot_pos: Tuple[int, int]\n",
    "    depth: int\n",
    "\n",
    "    N: int = 0\n",
    "    N_a: Dict[Action, int] = field(default_factory=lambda: {a: 0 for a in ACTIONS})\n",
    "    W_a: Dict[Action, float] = field(default_factory=lambda: {a: 0.0 for a in ACTIONS})\n",
    "    Q_a: Dict[Action, float] = field(default_factory=lambda: {a: 0.0 for a in ACTIONS})\n",
    "\n",
    "    P_a: Dict[Action, float] = field(default_factory=lambda: {a: 1.0 / len(ACTIONS) for a in ACTIONS})\n",
    "\n",
    "    children: Dict[Action, \"MCTSNode\"] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def select_action_puct(node: MCTSNode, *, c_puct: float) -> Action:\n",
    "    \"\"\"PUCT: argmax_a Q + c*P*sqrt(N)/(1+N_a). Uses node.P_a.\"\"\"\n",
    "    sqrtN = math.sqrt(max(1, node.N))\n",
    "\n",
    "    best_a: Optional[Action] = None\n",
    "    best_score = -1e18\n",
    "\n",
    "    for a in ACTIONS:\n",
    "        q = node.Q_a[a]\n",
    "        u = c_puct * node.P_a[a] * sqrtN / (1.0 + node.N_a[a])\n",
    "        score = q + u + random.uniform(-1e-9, 1e-9)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_a = a\n",
    "\n",
    "    assert best_a is not None\n",
    "    return best_a\n",
    "\n",
    "\n",
    "def backprop_path(path: List[Tuple[MCTSNode, Action]], value: float) -> None:\n",
    "    for node, a in reversed(path):\n",
    "        node.N += 1\n",
    "        node.N_a[a] += 1\n",
    "        node.W_a[a] += value\n",
    "        node.Q_a[a] = node.W_a[a] / node.N_a[a]\n",
    "\n",
    "\n",
    "def choose_final_action(root: MCTSNode) -> Action:\n",
    "    maxN = max(root.N_a.values())\n",
    "    cand = [a for a in ACTIONS if root.N_a[a] == maxN]\n",
    "    if len(cand) == 1:\n",
    "        return cand[0]\n",
    "\n",
    "    maxQ = max(root.Q_a[a] for a in cand)\n",
    "    cand2 = [a for a in cand if abs(root.Q_a[a] - maxQ) < 1e-12]\n",
    "    if len(cand2) == 1:\n",
    "        return cand2[0]\n",
    "\n",
    "    maxP = max(root.P_a[a] for a in cand2)\n",
    "    cand3 = [a for a in cand2 if abs(root.P_a[a] - maxP) < 1e-12]\n",
    "    return random.choice(cand3)\n",
    "\n",
    "\n",
    "def rollout_value(\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    detection: DetectionModel,\n",
    "    *,\n",
    "    max_steps: int,\n",
    "    w_step: float,\n",
    "    w_detect: float,\n",
    ") -> float:\n",
    "    total_cost = 0.0\n",
    "    cur = robot_pos\n",
    "    for _ in range(max_steps):\n",
    "        if cur == goal:\n",
    "            break\n",
    "        a = greedy_step_toward(world, cur, goal)\n",
    "        cur = world.step(cur, a)\n",
    "        total_cost += w_step\n",
    "        total_cost += w_detect * detection.p_detect(cur, sensor_pos)\n",
    "    if cur == goal:\n",
    "        total_cost -= 20.0\n",
    "    return -total_cost\n",
    "\n",
    "\n",
    "def simulate_sensor_step(\n",
    "    world: GridWorld,\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    robot_pos: Tuple[int, int],\n",
    "    t: int,\n",
    "    mode_idx: int,\n",
    "    policies: List[SensorModePolicy],\n",
    ") -> Tuple[int, int]:\n",
    "    if 0 <= mode_idx < len(policies):\n",
    "        aS = policies[mode_idx].action(world, sensor_pos, robot_pos, t)\n",
    "        return world.step(sensor_pos, aS)\n",
    "    return sensor_pos\n",
    "\n",
    "\n",
    "def mcts_search_action(\n",
    "    world: GridWorld,\n",
    "    belief: BeliefState,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    sensor_policies: List[SensorModePolicy],\n",
    "    detection: DetectionModel,\n",
    "    action_prior: Dict[Action, float],\n",
    "    *,\n",
    "    t: int,\n",
    "    num_sims: int = 250,\n",
    "    max_depth: int = 10,\n",
    "    c_puct: float = 1.4,\n",
    "    w_step: float = 1.0,\n",
    "    w_detect: float = 7.0,\n",
    "    gamma: float = 0.95,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> Action:\n",
    "    # Smooth and validate prior\n",
    "    prior = normalize_probs_dict(action_prior, ACTIONS, eps=0.10)\n",
    "\n",
    "    root = MCTSNode(robot_pos=robot_pos, depth=0)\n",
    "    root.P_a = prior\n",
    "\n",
    "    # Prepare particle sampling distribution\n",
    "    particles = belief.particles if belief.particles else [Particle(sensor_pos=robot_pos, mode_idx=0, weight=1.0)]\n",
    "    weights = [float(getattr(p, \"weight\", 1.0)) for p in particles]\n",
    "    s = sum(weights)\n",
    "    if s <= 0.0:\n",
    "        weights = [1.0 / len(weights)] * len(weights)\n",
    "    else:\n",
    "        weights = [w / s for w in weights]\n",
    "\n",
    "    # Optional header\n",
    "    if log is not None and (log._should_print(t, log.cfg.mcts_every_t, lvl=1)):\n",
    "        log.log(f\"[MCTS] t={t} sims={num_sims} depth={max_depth} prior_top: {topk_str(prior, k=3)}\", t=t, every=log.cfg.mcts_every_t, lvl=1)\n",
    "\n",
    "    for sim in range(num_sims):\n",
    "        hp = random.choices(particles, weights=weights, k=1)[0]\n",
    "        sim_sensor = hp.sensor_pos\n",
    "        sim_mode = hp.mode_idx\n",
    "\n",
    "        node = root\n",
    "        cur_robot = robot_pos\n",
    "        cur_sensor = sim_sensor\n",
    "\n",
    "        path: List[Tuple[MCTSNode, Action]] = []\n",
    "        total_return = 0.0\n",
    "        disc = 1.0\n",
    "\n",
    "        # Corner case: already at goal\n",
    "        if cur_robot == goal:\n",
    "            root.N += 1\n",
    "            continue\n",
    "\n",
    "        for depth in range(max_depth):\n",
    "            if cur_robot == goal:\n",
    "                total_return += disc * 50.0\n",
    "                break\n",
    "\n",
    "            a = select_action_puct(node, c_puct=c_puct)\n",
    "            path.append((node, a))\n",
    "\n",
    "            nxt_robot = world.step(cur_robot, a)\n",
    "            nxt_sensor = simulate_sensor_step(world, cur_sensor, nxt_robot, t + depth, sim_mode, sensor_policies)\n",
    "\n",
    "            step_cost = w_step + w_detect * detection.p_detect(nxt_robot, nxt_sensor)\n",
    "            total_return += disc * (-step_cost)\n",
    "            disc *= gamma\n",
    "\n",
    "            if a not in node.children:\n",
    "                child = MCTSNode(robot_pos=nxt_robot, depth=node.depth + 1)\n",
    "                child.P_a = prior\n",
    "                node.children[a] = child\n",
    "\n",
    "                leaf_v = rollout_value(\n",
    "                    world,\n",
    "                    nxt_robot,\n",
    "                    nxt_sensor,\n",
    "                    goal,\n",
    "                    detection,\n",
    "                    max_steps=max_depth - depth - 1,\n",
    "                    w_step=w_step,\n",
    "                    w_detect=w_detect,\n",
    "                )\n",
    "                total_return += disc * leaf_v\n",
    "                break\n",
    "\n",
    "            node = node.children[a]\n",
    "            cur_robot, cur_sensor = nxt_robot, nxt_sensor\n",
    "\n",
    "        if path:\n",
    "            backprop_path(path, total_return)\n",
    "        else:\n",
    "            # If something went weird and we didn't select an action, still count a visit\n",
    "            root.N += 1\n",
    "\n",
    "        if log is not None and log.cfg.level >= 2 and (sim < 2 or ((sim + 1) % log.cfg.mcts_progress_every_sims == 0 and t <= log.cfg.detail_until_t)):\n",
    "            log.log(f\"[MCTS][detail] t={t} sim={sim+1}/{num_sims} root.N={root.N}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    # Post-checks\n",
    "    total_edge_visits = sum(root.N_a.values())\n",
    "    # In this implementation root.N should be close to num_sims (exact if every sim selects at least 1 action)\n",
    "    if log is not None:\n",
    "        if log._should_print(t, log.cfg.mcts_every_t, lvl=1):\n",
    "            log.log(\n",
    "                f\"[MCTS] t={t} root.N={root.N} sum(N_a)={total_edge_visits} best_by_N={max(root.N_a, key=lambda a: root.N_a[a])}\",\n",
    "                t=t,\n",
    "                every=log.cfg.mcts_every_t,\n",
    "                lvl=1,\n",
    "            )\n",
    "\n",
    "            if log.cfg.level >= 2 and t <= log.cfg.detail_until_t:\n",
    "                for a in ACTIONS:\n",
    "                    log.log(f\"[MCTS][detail] a={a} N={root.N_a[a]:4d} Q={root.Q_a[a]:+8.3f} P={root.P_a[a]:.3f}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    chosen = choose_final_action(root)\n",
    "    return chosen\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Main Simulation\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    seed: int = 7\n",
    "\n",
    "    H: int = 12\n",
    "    W: int = 18\n",
    "    T: int = 40\n",
    "\n",
    "    num_particles: int = 250\n",
    "\n",
    "    # PF\n",
    "    motion_noise: float = 0.15\n",
    "    resample_threshold: float = 0.55\n",
    "\n",
    "    # Mode library\n",
    "    num_hypotheses: int = 25\n",
    "    per_hypothesis_attempts: int = 2\n",
    "    max_modes: int = 6\n",
    "    w_detect_astar: float = 10.0\n",
    "    rand_scale: float = 0.45\n",
    "\n",
    "    # MCTS\n",
    "    num_sims: int = 250\n",
    "    max_depth: int = 10\n",
    "    c_puct: float = 1.4\n",
    "    w_step_mcts: float = 1.0\n",
    "    w_detect_mcts: float = 7.0\n",
    "\n",
    "    # Debug\n",
    "    debug: DebugConfig = field(default_factory=DebugConfig)\n",
    "\n",
    "\n",
    "def make_demo_world(cfg: Config) -> Tuple[GridWorld, Tuple[int, int], Tuple[int, int], Tuple[int, int]]:\n",
    "    obs = set()\n",
    "    for c in range(3, 15):\n",
    "        obs.add((5, c))\n",
    "    for r in range(1, 9):\n",
    "        obs.add((r, 9))\n",
    "    obs.discard((5, 7))\n",
    "    obs.discard((6, 9))\n",
    "\n",
    "    world = GridWorld(H=cfg.H, W=cfg.W, obstacles=obs)\n",
    "    robot_start = (10, 2)\n",
    "    goal = (1, 16)\n",
    "    sensor_start = (2, 2)\n",
    "    return world, robot_start, sensor_start, goal\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = Config()\n",
    "    seed_all(cfg.seed)\n",
    "\n",
    "    log = Logger(cfg.debug)\n",
    "\n",
    "    world, robot_pos, sensor_pos, goal = make_demo_world(cfg)\n",
    "\n",
    "    sensor_modes: List[SensorModePolicy] = [\n",
    "        PatrolLoopPolicy(name=\"patrol_left\", loop=[(2, 2), (2, 6), (4, 6), (4, 2)]),\n",
    "        PatrolLoopPolicy(name=\"patrol_mid\", loop=[(2, 10), (2, 13), (4, 13), (4, 10)]),\n",
    "        ChasePolicy(name=\"chase_robot\"),\n",
    "        RandomWalkPolicy(name=\"random_walk\"),\n",
    "    ]\n",
    "    mode_names = [m.name for m in sensor_modes]\n",
    "\n",
    "    true_mode_idx = random.randrange(len(sensor_modes))\n",
    "\n",
    "    detection = DetectionModel()\n",
    "    obs_model = ObservationModel(sigma=1.3)\n",
    "\n",
    "    sensor_init_candidates = [(2, 2), (2, 10), (3, 3), (3, 9), (1, 1)]\n",
    "    mode_prior = [1.0] * len(sensor_modes)\n",
    "    belief = initialize_belief(world, sensor_init_candidates, mode_prior, mode_names, cfg.num_particles)\n",
    "\n",
    "    log.log(f\"[INIT] true_mode={mode_names[true_mode_idx]} robot={robot_pos} sensor={sensor_pos} goal={goal}\", force=True)\n",
    "    log.log(f\"[INIT] belief modes: {topk_str(belief.mode_posterior_named(), k=4)}\", force=True)\n",
    "\n",
    "    for t in range(cfg.T):\n",
    "        # Minimal header\n",
    "        show_header = (t <= cfg.debug.detail_until_t) or (cfg.debug.enabled and cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)\n",
    "        if show_header:\n",
    "            log.log(\"=\" * 80, force=True)\n",
    "            log.log(f\"[TIME] t={t}\", force=True)\n",
    "\n",
    "        # Optional render\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.render_every_t > 0 and t % cfg.debug.render_every_t == 0)):\n",
    "            log.log(\"[WORLD]\", t=t, every=cfg.debug.render_every_t, lvl=1, force=(t <= cfg.debug.detail_until_t))\n",
    "            world.render(robot=robot_pos, sensor=sensor_pos, goal=goal)\n",
    "\n",
    "        obs = obs_model.sample_observation(sensor_pos, world)\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[OBS] obs={obs} (true sensor={sensor_pos})\", force=True)\n",
    "\n",
    "        # PF update\n",
    "        pf_info = belief_predict_update(\n",
    "            belief,\n",
    "            world,\n",
    "            robot_pos,\n",
    "            sensor_modes,\n",
    "            obs_model,\n",
    "            obs,\n",
    "            t,\n",
    "            motion_noise=cfg.motion_noise,\n",
    "            resample_threshold=cfg.resample_threshold,\n",
    "            log=log,\n",
    "        )\n",
    "\n",
    "        # Mode library -> prior\n",
    "        library, lib_info = build_multimodal_path_library(\n",
    "            world,\n",
    "            belief,\n",
    "            robot_pos,\n",
    "            goal,\n",
    "            detection,\n",
    "            num_hypotheses=cfg.num_hypotheses,\n",
    "            per_hypothesis_attempts=cfg.per_hypothesis_attempts,\n",
    "            w_detect=cfg.w_detect_astar,\n",
    "            rand_scale=cfg.rand_scale,\n",
    "            max_modes=cfg.max_modes,\n",
    "            t=t,\n",
    "            log=log,\n",
    "        )\n",
    "        action_prior = build_action_prior_from_library(world, robot_pos, library)\n",
    "\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[Prior] top: {topk_str(action_prior, k=3)}\", force=True)\n",
    "\n",
    "        # MCTS choose action\n",
    "        aR = mcts_search_action(\n",
    "            world,\n",
    "            belief,\n",
    "            robot_pos,\n",
    "            goal,\n",
    "            sensor_modes,\n",
    "            detection,\n",
    "            action_prior,\n",
    "            t=t,\n",
    "            num_sims=cfg.num_sims,\n",
    "            max_depth=cfg.max_depth,\n",
    "            c_puct=cfg.c_puct,\n",
    "            w_step=cfg.w_step_mcts,\n",
    "            w_detect=cfg.w_detect_mcts,\n",
    "            log=log,\n",
    "        )\n",
    "\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[ACT] robot aR={aR}\", force=True)\n",
    "\n",
    "        # Step robot and true sensor\n",
    "        new_robot = world.step(robot_pos, aR)\n",
    "        aS_true = sensor_modes[true_mode_idx].action(world, sensor_pos, new_robot, t)\n",
    "        new_sensor = world.step(sensor_pos, aS_true)\n",
    "\n",
    "        robot_pos, sensor_pos = new_robot, new_sensor\n",
    "\n",
    "        # Detection\n",
    "        p_det = detection.p_detect(robot_pos, sensor_pos)\n",
    "        detected = (random.random() < p_det)\n",
    "\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[STEP] robot={robot_pos} sensor={sensor_pos} p_det={p_det:.3f} detected={detected}\", force=True)\n",
    "\n",
    "        # Terminate\n",
    "        if robot_pos == goal:\n",
    "            log.log(\"[TERMINAL] reached goal \", force=True)\n",
    "            break\n",
    "        if detected and manhattan(robot_pos, sensor_pos) <= detection.d0:\n",
    "            log.log(\"[TERMINAL] caught \", force=True)\n",
    "            break\n",
    "\n",
    "    log.log(\"[DONE]\", force=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff5a7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] true_mode=chase_robot robot=(10, 2) sensor=(2, 2) goal=(1, 16)\n",
      "[INIT] belief modes: random_walk:0.272 | patrol_left:0.260 | patrol_mid:0.240 | chase_robot:0.228\n",
      "================================================================================\n",
      "[TIME] t=0\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      "..S......#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..R...............\n",
      "..................\n",
      "[OBS] obs=(4, 3) (true sensor=(2, 2))\n",
      "[PF] t=0 obs=(4, 3) ESS 250.0->61.1 resample=True | modes: chase_robot:0.508 | random_walk:0.192 | patrol_left:0.152\n",
      "[Modes] t=0 candidates=50 clusters=6 kept=6 | top3: random_walk:w=0.004,cost=37.1,score=53.7, random_walk:w=0.004,cost=37.2,score=53.8, random_walk:w=0.004,cost=37.7,score=54.3\n",
      "[PriorDiag] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[MCTS] t=0 sims=250 depth=10 prior: H=0.390 top=R:0.920 | U:0.020 | D:0.020\n",
      "[MCTS] t=0 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[CHASE] true t=0 src=(2, 2) dst=(10, 3) a=D nxt=(3, 2) d:9->8 best_d=8 best=['D', 'R']\n",
      "[STEP] robot=(10, 3) sensor=(3, 2) aS=D p_det=0.191 detected=False\n",
      "================================================================================\n",
      "[TIME] t=1\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      "..S......#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "...R..............\n",
      "..................\n",
      "[OBS] obs=(1, 3) (true sensor=(3, 2))\n",
      "[PF] t=1 obs=(1, 3) ESS 250.0->131.3 resample=True | modes: chase_robot:0.328 | patrol_left:0.284 | random_walk:0.224\n",
      "[Modes] t=1 candidates=50 clusters=6 kept=6 | top3: random_walk:w=0.004,cost=32.0,score=48.6, random_walk:w=0.004,cost=33.0,score=49.6, random_walk:w=0.004,cost=34.1,score=50.7\n",
      "[PriorDiag] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[MCTS] t=1 sims=250 depth=10 prior: H=0.390 top=R:0.920 | U:0.020 | D:0.020\n",
      "[MCTS] t=1 root.N=250 sum(N_a)=250 best_by_N=S\n",
      "[ACT] robot aR=S\n",
      "[CHASE] true t=1 src=(3, 2) dst=(10, 3) a=D nxt=(4, 2) d:8->7 best_d=7 best=['D', 'R']\n",
      "[STEP] robot=(10, 3) sensor=(4, 2) aS=D p_det=0.240 detected=False\n",
      "================================================================================\n",
      "[TIME] t=2\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      "..S......#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "...R..............\n",
      "..................\n",
      "[OBS] obs=(5, 4) (true sensor=(4, 2))\n",
      "[PF] t=2 obs=(5, 4) ESS 250.0->172.6 resample=False | modes: chase_robot:0.546 | patrol_left:0.272 | random_walk:0.118\n",
      "[Modes] t=2 candidates=50 clusters=6 kept=6 | top3: chase_robot:w=0.007,cost=38.4,score=53.4, random_walk:w=0.007,cost=38.6,score=53.6, chase_robot:w=0.007,cost=40.2,score=55.2\n",
      "[PriorDiag] H=0.424 top=R:0.849 | D:0.151 | U:0.000\n",
      "[MCTS] t=2 sims=250 depth=10 prior: H=0.715 top=R:0.784 | D:0.156 | U:0.020\n",
      "[MCTS] t=2 root.N=250 sum(N_a)=250 best_by_N=D\n",
      "[ACT] robot aR=D\n",
      "[CHASE] true t=2 src=(4, 2) dst=(11, 3) a=D nxt=(5, 2) d:8->7 best_d=7 best=['D', 'R']\n",
      "[STEP] robot=(11, 3) sensor=(5, 2) aS=D p_det=0.240 detected=False\n",
      "[PF] t=3 obs=(5, 1) ESS 172.6->96.6 resample=True | modes: chase_robot:0.744 | patrol_left:0.140 | random_walk:0.116\n",
      "================================================================================\n",
      "[TIME] t=5\n",
      "[OBS] obs=(5, 2) (true sensor=(7, 2))\n",
      "[PF] t=5 obs=(5, 2) ESS 163.3->66.1 resample=True | modes: chase_robot:0.692 | random_walk:0.300 | patrol_left:0.008\n",
      "[Modes] t=5 candidates=50 clusters=6 kept=6 | top3: random_walk:w=0.004,cost=34.3,score=50.8, random_walk:w=0.004,cost=35.4,score=52.0, random_walk:w=0.004,cost=35.6,score=52.1\n",
      "[PriorDiag] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[MCTS] t=5 sims=250 depth=10 prior: H=0.390 top=R:0.920 | U:0.020 | D:0.020\n",
      "[MCTS] t=5 root.N=250 sum(N_a)=250 best_by_N=D\n",
      "[ACT] robot aR=D\n",
      "[CHASE] true t=5 src=(7, 2) dst=(11, 3) a=D nxt=(8, 2) d:5->4 best_d=4 best=['D', 'R']\n",
      "[STEP] robot=(11, 3) sensor=(8, 2) aS=D p_det=0.516 detected=True\n",
      "[PF] t=6 obs=(9, 4) ESS 250.0->101.3 resample=True | modes: chase_robot:0.836 | random_walk:0.164\n",
      "[PF] t=7 obs=(7, 0) ESS 250.0->130.2 resample=True | modes: chase_robot:0.812 | random_walk:0.188\n",
      "[PF] t=9 obs=(11, 5) ESS 187.7->117.1 resample=True | modes: chase_robot:0.968 | random_walk:0.032\n",
      "================================================================================\n",
      "[TIME] t=10\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      ".....S............\n",
      "..................\n",
      ".......R..........\n",
      "[OBS] obs=(11, 5) (true sensor=(9, 5))\n",
      "[PF] t=10 obs=(11, 5) ESS 250.0->139.2 resample=False | modes: chase_robot:0.998 | random_walk:0.002\n",
      "[Modes] t=10 candidates=50 clusters=5 kept=5 | top3: chase_robot:w=0.003,cost=37.6,score=54.9, chase_robot:w=0.003,cost=38.2,score=55.6, chase_robot:w=0.001,cost=36.3,score=56.0\n",
      "[PriorDiag] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[MCTS] t=10 sims=250 depth=10 prior: H=0.390 top=R:0.920 | U:0.020 | D:0.020\n",
      "[MCTS] t=10 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[CHASE] true t=10 src=(9, 5) dst=(11, 8) a=R nxt=(9, 6) d:5->4 best_d=4 best=['D', 'R']\n",
      "[STEP] robot=(11, 8) sensor=(9, 6) aS=R p_det=0.516 detected=False\n",
      "[PF] t=11 obs=(7, 7) ESS 139.2->131.8 resample=True | modes: chase_robot:1.000\n",
      "[PF] t=14 obs=(7, 8) ESS 221.2->120.8 resample=True | modes: chase_robot:1.000\n",
      "================================================================================\n",
      "[TIME] t=15\n",
      "[OBS] obs=(9, 10) (true sensor=(9, 10))\n",
      "[PF] t=15 obs=(9, 10) ESS 250.0->177.4 resample=False | modes: chase_robot:1.000\n",
      "[Modes] t=15 candidates=50 clusters=6 kept=6 | top3: chase_robot:w=0.002,cost=30.6,score=49.7, chase_robot:w=0.001,cost=28.8,score=50.2, chase_robot:w=0.002,cost=33.3,score=52.4\n",
      "[PriorDiag] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[MCTS] t=15 sims=250 depth=10 prior: H=0.390 top=R:0.920 | U:0.020 | D:0.020\n",
      "[MCTS] t=15 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[CHASE] true t=15 src=(9, 10) dst=(11, 13) a=R nxt=(9, 11) d:5->4 best_d=4 best=['D', 'R']\n",
      "[STEP] robot=(11, 13) sensor=(9, 11) aS=R p_det=0.516 detected=True\n",
      "[PF] t=18 obs=(9, 12) ESS 181.5->126.7 resample=True | modes: chase_robot:1.000\n",
      "================================================================================\n",
      "[TIME] t=20\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "...............S..\n",
      "..................\n",
      ".................R\n",
      "[OBS] obs=(9, 15) (true sensor=(9, 15))\n",
      "[PF] t=20 obs=(9, 15) ESS 182.8->118.8 resample=True | modes: chase_robot:1.000\n",
      "[Modes] t=20 candidates=50 clusters=2 kept=2 | top3: chase_robot:w=0.004,cost=36.9,score=53.5, chase_robot:w=0.004,cost=37.0,score=53.6\n",
      "[PriorDiag] H=0.000 top=U:1.000 | D:0.000 | L:0.000\n",
      "[MCTS] t=20 sims=250 depth=10 prior: H=0.390 top=U:0.920 | D:0.020 | L:0.020\n",
      "[MCTS] t=20 root.N=250 sum(N_a)=250 best_by_N=D\n",
      "[ACT] robot aR=D\n",
      "[CHASE] true t=20 src=(9, 15) dst=(11, 17) a=D nxt=(10, 15) d:4->3 best_d=3 best=['D', 'R']\n",
      "[STEP] robot=(11, 17) sensor=(10, 15) aS=D p_det=0.680 detected=True\n",
      "[TERMINAL] caught \n",
      "[DONE]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"GenBR-lite + PF Belief + Multimodal Path Library (debug-robust)\n",
    "\n",
    "This version includes the specific fixes suggested from your logs:\n",
    "1) **Chase policy sanity + determinism**:\n",
    "   - Chase now uses a deterministic tie-break (no random sideways moves on ties).\n",
    "   - We print (and warn on) any chase step that *increases* Manhattan distance when a decreasing move exists.\n",
    "\n",
    "2) **Mode-library selection uses plausibility + cost** (not cost-only optimism):\n",
    "   - Each candidate path is scored as:  score = cost + lambda_plaus * (-log(hyp_weight)).\n",
    "   - Best-per-cluster and final sorting use this score.\n",
    "\n",
    "3) **Action prior is a mixture over modes** (not single-best-path):\n",
    "   - Prior weights each kept mode by: hyp_weight * exp(-cost/temp).\n",
    "\n",
    "4) **Detection is actually terminal**:\n",
    "   - If detected and within d0, episode terminates as \"caught\".\n",
    "\n",
    "What to send me to verify correctness:\n",
    "- Run with DebugConfig(level=2, detail_until_t=6, summary_every_t=1, render_every_t=1) for ~10 steps.\n",
    "- Paste the log lines that start with: [CHASE], [CHASE][WARN], [ModesKept], [PriorDiag], [MCTS]\n",
    "\n",
    "Run:\n",
    "  python3 this_file.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import random\n",
    "import heapq\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional, Iterable, Callable, Any, Set\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Debug / Logging utilities\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class DebugConfig:\n",
    "    enabled: bool = True\n",
    "    level: int = 1\n",
    "    # 0 = silent\n",
    "    # 1 = periodic summaries\n",
    "    # 2 = detailed (still gated)\n",
    "\n",
    "    # Print detail for the first few timesteps\n",
    "    detail_until_t: int = 2\n",
    "\n",
    "    # Periodic summary controls\n",
    "    summary_every_t: int = 5\n",
    "    render_every_t: int = 10\n",
    "\n",
    "    # Stage-specific periodic prints\n",
    "    pf_every_t: int = 5\n",
    "    modes_every_t: int = 5\n",
    "    mcts_every_t: int = 5\n",
    "\n",
    "    # Within MCTS\n",
    "    mcts_progress_every_sims: int = 50\n",
    "\n",
    "    # Safety: cap printing of mode hypotheses even at detail level\n",
    "    max_hyp_print: int = 3\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, cfg: DebugConfig):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def _should_print(self, t: Optional[int], every: Optional[int], lvl: int) -> bool:\n",
    "        if not self.cfg.enabled:\n",
    "            return False\n",
    "        if lvl > self.cfg.level:\n",
    "            return False\n",
    "        if t is None:\n",
    "            return True\n",
    "        if t <= self.cfg.detail_until_t:\n",
    "            return True\n",
    "        if every is None:\n",
    "            return False\n",
    "        return (every > 0) and (t % every == 0)\n",
    "\n",
    "    def log(self, msg: str, *, t: Optional[int] = None, every: Optional[int] = None, lvl: int = 1, force: bool = False) -> None:\n",
    "        if force or self._should_print(t, every, lvl):\n",
    "            print(msg)\n",
    "\n",
    "\n",
    "def soft_assert(cond: bool, msg: str, *, fatal: bool = False, log: Optional[Logger] = None, t: Optional[int] = None) -> None:\n",
    "    if cond:\n",
    "        return\n",
    "    if log is not None:\n",
    "        log.log(f\"[WARN] {msg}\", t=t, every=None, lvl=1, force=True)\n",
    "    if fatal:\n",
    "        raise AssertionError(msg)\n",
    "\n",
    "\n",
    "def clamp(x: float, lo: float, hi: float) -> float:\n",
    "    return max(lo, min(hi, x))\n",
    "\n",
    "\n",
    "def manhattan(a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "\n",
    "def seed_all(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "def stable_bucket(sig: str, m: int) -> int:\n",
    "    \"\"\"Stable mapping sig -> [0..m-1] independent of Python's randomized hash.\"\"\"\n",
    "    if m <= 0:\n",
    "        return 0\n",
    "    h = hashlib.md5(sig.encode(\"utf-8\")).hexdigest()\n",
    "    return int(h[:8], 16) % m\n",
    "\n",
    "\n",
    "def normalize_probs_dict(d: Dict[Any, float], keys: Iterable[Any], *, eps: float = 0.0) -> Dict[Any, float]:\n",
    "    \"\"\"Return a normalized distribution over `keys` from possibly-missing/negative inputs.\n",
    "\n",
    "    - Clips negatives to 0\n",
    "    - Adds optional epsilon smoothing to avoid degeneracy\n",
    "    - Falls back to uniform if total mass is 0\n",
    "    \"\"\"\n",
    "    klist = list(keys)\n",
    "    out = {k: max(0.0, float(d.get(k, 0.0))) for k in klist}\n",
    "    s = sum(out.values())\n",
    "\n",
    "    if s <= 0.0:\n",
    "        u = 1.0 / max(1, len(klist))\n",
    "        return {k: u for k in klist}\n",
    "\n",
    "    out = {k: v / s for k, v in out.items()}\n",
    "\n",
    "    if eps > 0.0:\n",
    "        u = 1.0 / max(1, len(klist))\n",
    "        out = {k: (1.0 - eps) * out[k] + eps * u for k in klist}\n",
    "        s2 = sum(out.values())\n",
    "        out = {k: v / s2 for k, v in out.items()}\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def topk_str(d: Dict[Any, float], k: int = 3, fmt: str = \"{k}:{v:.3f}\") -> str:\n",
    "    items = sorted(d.items(), key=lambda kv: kv[1], reverse=True)[:k]\n",
    "    return \" | \".join(fmt.format(k=kk, v=vv) for kk, vv in items)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Gridworld Environment\n",
    "# =========================\n",
    "\n",
    "Action = str  # 'U','D','L','R','S'\n",
    "\n",
    "ACTIONS: List[Action] = [\"U\", \"D\", \"L\", \"R\", \"S\"]\n",
    "ACTION_DELTAS: Dict[Action, Tuple[int, int]] = {\n",
    "    \"U\": (-1, 0),\n",
    "    \"D\": (1, 0),\n",
    "    \"L\": (0, -1),\n",
    "    \"R\": (0, 1),\n",
    "    \"S\": (0, 0),\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GridWorld:\n",
    "    H: int\n",
    "    W: int\n",
    "    obstacles: Set[Tuple[int, int]] = field(default_factory=set)\n",
    "\n",
    "    def in_bounds(self, p: Tuple[int, int]) -> bool:\n",
    "        r, c = p\n",
    "        return 0 <= r < self.H and 0 <= c < self.W\n",
    "\n",
    "    def is_free(self, p: Tuple[int, int]) -> bool:\n",
    "        return self.in_bounds(p) and (p not in self.obstacles)\n",
    "\n",
    "    def step(self, p: Tuple[int, int], a: Action) -> Tuple[int, int]:\n",
    "        if a not in ACTION_DELTAS:\n",
    "            raise ValueError(f\"Unknown action: {a}\")\n",
    "        dr, dc = ACTION_DELTAS[a]\n",
    "        np = (p[0] + dr, p[1] + dc)\n",
    "        return np if self.is_free(np) else p\n",
    "\n",
    "    def neighbors(self, p: Tuple[int, int]) -> List[Tuple[Tuple[int, int], Action]]:\n",
    "        return [(self.step(p, a), a) for a in ACTIONS]\n",
    "\n",
    "    def render(self, robot: Tuple[int, int], sensor: Tuple[int, int], goal: Tuple[int, int]) -> None:\n",
    "        grid = [[\".\" for _ in range(self.W)] for _ in range(self.H)]\n",
    "        for (r, c) in self.obstacles:\n",
    "            grid[r][c] = \"#\"\n",
    "        rr, rc = robot\n",
    "        sr, sc = sensor\n",
    "        gr, gc = goal\n",
    "        grid[gr][gc] = \"G\"\n",
    "        grid[sr][sc] = \"S\"\n",
    "        grid[rr][rc] = \"R\"\n",
    "        for r in range(self.H):\n",
    "            print(\"\".join(grid[r]))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Sensor Models (Modes)\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class SensorModePolicy:\n",
    "    name: str\n",
    "\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def best_actions_toward(world: GridWorld, src: Tuple[int, int], dst: Tuple[int, int]) -> Tuple[List[Action], int]:\n",
    "    \"\"\"Return (best_actions, best_dist) minimizing manhattan(next(src,a), dst).\"\"\"\n",
    "    best_actions: List[Action] = []\n",
    "    best_dist = 10**9\n",
    "    for a in ACTIONS:\n",
    "        np = world.step(src, a)\n",
    "        d = manhattan(np, dst)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_actions = [a]\n",
    "        elif d == best_dist:\n",
    "            best_actions.append(a)\n",
    "    return best_actions, best_dist\n",
    "\n",
    "\n",
    "def deterministic_greedy_step_toward(world: GridWorld, src: Tuple[int, int], dst: Tuple[int, int]) -> Action:\n",
    "    \"\"\"Greedy toward dst with deterministic tie-break (easier to debug than random ties).\"\"\"\n",
    "    best_as, _ = best_actions_toward(world, src, dst)\n",
    "    if not best_as:\n",
    "        return \"S\"\n",
    "\n",
    "    # Preferred axis: move along the larger |delta| if possible\n",
    "    dr = dst[0] - src[0]\n",
    "    dc = dst[1] - src[1]\n",
    "\n",
    "    preferred: List[Action] = []\n",
    "    if abs(dr) >= abs(dc):\n",
    "        if dr > 0:\n",
    "            preferred.append(\"D\")\n",
    "        elif dr < 0:\n",
    "            preferred.append(\"U\")\n",
    "    if abs(dc) > abs(dr):\n",
    "        if dc > 0:\n",
    "            preferred.append(\"R\")\n",
    "        elif dc < 0:\n",
    "            preferred.append(\"L\")\n",
    "\n",
    "    # If the preferred move is among best actions, take it\n",
    "    for a in preferred:\n",
    "        if a in best_as:\n",
    "            return a\n",
    "\n",
    "    # Otherwise deterministic order\n",
    "    for a in [\"U\", \"D\", \"L\", \"R\", \"S\"]:\n",
    "        if a in best_as:\n",
    "            return a\n",
    "\n",
    "    return best_as[0]\n",
    "\n",
    "\n",
    "def chase_sanity_check(\n",
    "    world: GridWorld,\n",
    "    src: Tuple[int, int],\n",
    "    dst: Tuple[int, int],\n",
    "    chosen: Action,\n",
    "    *,\n",
    "    log: Optional[Logger],\n",
    "    t: int,\n",
    "    tag: str,\n",
    ") -> None:\n",
    "    \"\"\"Warn if chosen action increases distance when a non-increasing action exists.\"\"\"\n",
    "    d0 = manhattan(src, dst)\n",
    "    nxt = world.step(src, chosen)\n",
    "    d1 = manhattan(nxt, dst)\n",
    "\n",
    "    best_as, best_d = best_actions_toward(world, src, dst)\n",
    "\n",
    "    if log is not None and log.cfg.enabled and (t <= log.cfg.detail_until_t or (log.cfg.summary_every_t > 0 and t % log.cfg.summary_every_t == 0)):\n",
    "        log.log(\n",
    "            f\"[CHASE] {tag} t={t} src={src} dst={dst} a={chosen} nxt={nxt} d:{d0}->{d1} best_d={best_d} best={best_as}\",\n",
    "            t=t,\n",
    "            every=log.cfg.summary_every_t,\n",
    "            lvl=1,\n",
    "        )\n",
    "\n",
    "    # If chosen isn't among best actions, it's suspicious\n",
    "    if chosen not in best_as:\n",
    "        if log is not None:\n",
    "            log.log(\n",
    "                f\"[CHASE][WARN] {tag} t={t} chose {chosen} but best={best_as} (d:{d0}->{d1}, best_d={best_d})\",\n",
    "                t=t,\n",
    "                every=None,\n",
    "                lvl=1,\n",
    "                force=True,\n",
    "            )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PatrolLoopPolicy(SensorModePolicy):\n",
    "    loop: List[Tuple[int, int]] = field(default_factory=list)\n",
    "\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        if not self.loop:\n",
    "            return \"S\"\n",
    "        idx = t % len(self.loop)\n",
    "        return deterministic_greedy_step_toward(world, sensor_pos, self.loop[idx])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ChasePolicy(SensorModePolicy):\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        return deterministic_greedy_step_toward(world, sensor_pos, robot_pos)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RandomWalkPolicy(SensorModePolicy):\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        return random.choice(ACTIONS)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Detection / Observation\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class DetectionModel:\n",
    "    d0: int = 2\n",
    "    p_close: float = 0.9\n",
    "    p_far: float = 0.05\n",
    "    decay: float = 0.3\n",
    "\n",
    "    def p_detect(self, robot_pos: Tuple[int, int], sensor_pos: Tuple[int, int]) -> float:\n",
    "        dist = manhattan(robot_pos, sensor_pos)\n",
    "        if dist <= self.d0:\n",
    "            return self.p_close\n",
    "        return self.p_far + (self.p_close - self.p_far) * math.exp(-self.decay * (dist - self.d0))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ObservationModel:\n",
    "    sigma: float = 1.2\n",
    "\n",
    "    def sample_observation(self, sensor_pos: Tuple[int, int], world: GridWorld) -> Tuple[int, int]:\n",
    "        max_jump = 2\n",
    "        dr = random.randint(-max_jump, max_jump)\n",
    "        dc = random.randint(-max_jump, max_jump)\n",
    "        o = (sensor_pos[0] + dr, sensor_pos[1] + dc)\n",
    "        o = (int(clamp(o[0], 0, world.H - 1)), int(clamp(o[1], 0, world.W - 1)))\n",
    "        return o\n",
    "\n",
    "    def likelihood(self, obs: Tuple[int, int], sensor_pos: Tuple[int, int]) -> float:\n",
    "        d = manhattan(obs, sensor_pos)\n",
    "        return max(1e-12, math.exp(-d / max(1e-6, self.sigma)))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Particle Filter over (sensor_pos, mode)\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class Particle:\n",
    "    sensor_pos: Tuple[int, int]\n",
    "    mode_idx: int\n",
    "    weight: float = 1.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BeliefState:\n",
    "    particles: List[Particle]\n",
    "    mode_names: List[str]\n",
    "\n",
    "    def normalize(self) -> None:\n",
    "        s = sum(p.weight for p in self.particles)\n",
    "        if s <= 0.0:\n",
    "            w = 1.0 / max(1, len(self.particles))\n",
    "            for p in self.particles:\n",
    "                p.weight = w\n",
    "            return\n",
    "        for p in self.particles:\n",
    "            p.weight /= s\n",
    "\n",
    "    def effective_sample_size(self) -> float:\n",
    "        s = sum(p.weight * p.weight for p in self.particles)\n",
    "        return 0.0 if s <= 0.0 else 1.0 / s\n",
    "\n",
    "    def mode_posterior(self) -> Dict[int, float]:\n",
    "        post: Dict[int, float] = defaultdict(float)\n",
    "        for p in self.particles:\n",
    "            post[p.mode_idx] += p.weight\n",
    "        return dict(post)\n",
    "\n",
    "    def mode_posterior_named(self) -> Dict[str, float]:\n",
    "        post_i = self.mode_posterior()\n",
    "        out: Dict[str, float] = {}\n",
    "        for i, v in post_i.items():\n",
    "            name = self.mode_names[i] if 0 <= i < len(self.mode_names) else f\"mode{i}\"\n",
    "            out[name] = out.get(name, 0.0) + v\n",
    "        return out\n",
    "\n",
    "\n",
    "def systematic_resample(particles: List[Particle]) -> List[Particle]:\n",
    "    n = len(particles)\n",
    "    if n == 0:\n",
    "        return []\n",
    "    positions = [(random.random() + i) / n for i in range(n)]\n",
    "    cumulative = []\n",
    "    csum = 0.0\n",
    "    for p in particles:\n",
    "        csum += p.weight\n",
    "        cumulative.append(csum)\n",
    "\n",
    "    out: List[Particle] = []\n",
    "    i = 0\n",
    "    for pos in positions:\n",
    "        while i < n - 1 and pos > cumulative[i]:\n",
    "            i += 1\n",
    "        chosen = particles[i]\n",
    "        out.append(Particle(sensor_pos=chosen.sensor_pos, mode_idx=chosen.mode_idx, weight=1.0 / n))\n",
    "    return out\n",
    "\n",
    "\n",
    "def initialize_belief(\n",
    "    world: GridWorld,\n",
    "    sensor_init_candidates: List[Tuple[int, int]],\n",
    "    mode_prior: List[float],\n",
    "    mode_names: List[str],\n",
    "    num_particles: int = 200,\n",
    ") -> BeliefState:\n",
    "    if len(mode_prior) != len(mode_names):\n",
    "        raise ValueError(\"mode_prior and mode_names must have same length\")\n",
    "    if not sensor_init_candidates:\n",
    "        raise ValueError(\"Need at least one sensor init candidate\")\n",
    "    if num_particles <= 0:\n",
    "        raise ValueError(\"num_particles must be > 0\")\n",
    "\n",
    "    # normalize prior\n",
    "    s = sum(mode_prior)\n",
    "    if s <= 0.0:\n",
    "        mode_prior = [1.0 / len(mode_prior)] * len(mode_prior)\n",
    "    else:\n",
    "        mode_prior = [p / s for p in mode_prior]\n",
    "\n",
    "    def sample_mode() -> int:\n",
    "        r = random.random()\n",
    "        c = 0.0\n",
    "        for i, p in enumerate(mode_prior):\n",
    "            c += p\n",
    "            if r <= c:\n",
    "                return i\n",
    "        return len(mode_prior) - 1\n",
    "\n",
    "    particles: List[Particle] = []\n",
    "    for _ in range(num_particles):\n",
    "        sp = random.choice(sensor_init_candidates)\n",
    "        z = sample_mode()\n",
    "        particles.append(Particle(sensor_pos=sp, mode_idx=z, weight=1.0 / num_particles))\n",
    "\n",
    "    b = BeliefState(particles=particles, mode_names=mode_names)\n",
    "    b.normalize()\n",
    "    return b\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PFStepInfo:\n",
    "    ess_before: float\n",
    "    ess_after: float\n",
    "    resampled: bool\n",
    "\n",
    "\n",
    "def belief_predict_update(\n",
    "    belief: BeliefState,\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    sensor_policies: List[SensorModePolicy],\n",
    "    obs_model: ObservationModel,\n",
    "    obs: Tuple[int, int],\n",
    "    t: int,\n",
    "    *,\n",
    "    motion_noise: float = 0.10,\n",
    "    resample_threshold: float = 0.5,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> PFStepInfo:\n",
    "    if not belief.particles:\n",
    "        raise ValueError(\"belief has no particles\")\n",
    "\n",
    "    belief.normalize()\n",
    "    ess0 = belief.effective_sample_size()\n",
    "\n",
    "    # Predict + weight update\n",
    "    for p in belief.particles:\n",
    "        mi = p.mode_idx\n",
    "        if 0 <= mi < len(sensor_policies):\n",
    "            aS = sensor_policies[mi].action(world, p.sensor_pos, robot_pos, t)\n",
    "        else:\n",
    "            aS = \"S\"\n",
    "\n",
    "        predicted = world.step(p.sensor_pos, aS)\n",
    "        if random.random() < motion_noise:\n",
    "            predicted = world.step(predicted, random.choice(ACTIONS))\n",
    "\n",
    "        p.sensor_pos = predicted\n",
    "        p.weight *= obs_model.likelihood(obs, p.sensor_pos)\n",
    "\n",
    "    belief.normalize()\n",
    "    ess1 = belief.effective_sample_size()\n",
    "\n",
    "    # Sanity checks\n",
    "    N = len(belief.particles)\n",
    "    soft_assert(0.0 <= ess1 <= N + 1e-6, f\"ESS out of bounds: {ess1} (N={N})\", log=log, t=t)\n",
    "\n",
    "    resampled = False\n",
    "    if ess1 < resample_threshold * N:\n",
    "        belief.particles = systematic_resample(belief.particles)\n",
    "        belief.normalize()\n",
    "        resampled = True\n",
    "\n",
    "    # Controlled prints\n",
    "    if log is not None:\n",
    "        if log._should_print(t, log.cfg.pf_every_t, lvl=1) or resampled:\n",
    "            mp = belief.mode_posterior_named()\n",
    "            log.log(\n",
    "                f\"[PF] t={t} obs={obs} ESS {ess0:.1f}->{ess1:.1f} resample={resampled} | modes: {topk_str(mp, k=3)}\",\n",
    "                t=t,\n",
    "                every=log.cfg.pf_every_t,\n",
    "                lvl=1,\n",
    "                force=resampled,\n",
    "            )\n",
    "            if log.cfg.level >= 2 and t <= log.cfg.detail_until_t:\n",
    "                log.log(f\"[PF][detail] full mode posterior: {topk_str(mp, k=10)}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    return PFStepInfo(ess_before=ess0, ess_after=ess1, resampled=resampled)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# A* Search with Risk Costs\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class AStarResult:\n",
    "    path: List[Tuple[int, int]]\n",
    "    cost: float\n",
    "    expanded: int\n",
    "\n",
    "\n",
    "def astar_path(\n",
    "    world: GridWorld,\n",
    "    start: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    step_cost: Callable[[Tuple[int, int]], float],\n",
    "    heuristic: Callable[[Tuple[int, int]], float],\n",
    "    *,\n",
    "    max_expansions: int = 50_000,\n",
    ") -> Optional[AStarResult]:\n",
    "    if not world.is_free(start) or not world.is_free(goal):\n",
    "        return None\n",
    "\n",
    "    frontier: List[Tuple[float, float, Tuple[int, int]]] = []\n",
    "    heapq.heappush(frontier, (heuristic(start), 0.0, start))\n",
    "\n",
    "    came_from: Dict[Tuple[int, int], Tuple[int, int]] = {}\n",
    "    gscore: Dict[Tuple[int, int], float] = {start: 0.0}\n",
    "\n",
    "    expanded = 0\n",
    "\n",
    "    # A* with reopen: skip stale pops\n",
    "    while frontier and expanded < max_expansions:\n",
    "        f, g, cur = heapq.heappop(frontier)\n",
    "        if g > gscore.get(cur, float(\"inf\")) + 1e-12:\n",
    "            continue\n",
    "        expanded += 1\n",
    "\n",
    "        if cur == goal:\n",
    "            path = [cur]\n",
    "            while cur in came_from:\n",
    "                cur = came_from[cur]\n",
    "                path.append(cur)\n",
    "            path.reverse()\n",
    "            return AStarResult(path=path, cost=gscore[goal], expanded=expanded)\n",
    "\n",
    "        for (nxt, _) in world.neighbors(cur):\n",
    "            if not world.is_free(nxt):\n",
    "                continue\n",
    "            sc = step_cost(nxt)\n",
    "            if not math.isfinite(sc) or sc < 0:\n",
    "                continue\n",
    "            ng = gscore[cur] + sc\n",
    "            if ng + 1e-12 < gscore.get(nxt, float(\"inf\")):\n",
    "                gscore[nxt] = ng\n",
    "                came_from[nxt] = cur\n",
    "                heapq.heappush(frontier, (ng + heuristic(nxt), ng, nxt))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Multimodal Path Library\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class PathMode:\n",
    "    path: List[Tuple[int, int]]\n",
    "    total_cost: float\n",
    "    score: float\n",
    "    hypothesis_sensor_pos: Tuple[int, int]\n",
    "    hypothesis_mode_idx: int\n",
    "    hypothesis_weight: float\n",
    "    debug_info: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def build_cost_map_from_hypothesis(\n",
    "    world: GridWorld,\n",
    "    detection: \"DetectionModel\",\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    *,\n",
    "    base_step: float,\n",
    "    w_detect: float,\n",
    "    randomize: bool,\n",
    "    rand_scale: float,\n",
    ") -> Callable[[Tuple[int, int]], float]:\n",
    "    def cost_fn(s: Tuple[int, int]) -> float:\n",
    "        if not world.is_free(s):\n",
    "            return float(\"inf\")\n",
    "        p_det = detection.p_detect(robot_pos=s, sensor_pos=sensor_pos)\n",
    "        c = base_step + w_detect * p_det\n",
    "        if randomize:\n",
    "            c *= (1.0 + rand_scale * (random.random() - 0.5))\n",
    "            c = max(1e-6, c)\n",
    "        return c\n",
    "\n",
    "    return cost_fn\n",
    "\n",
    "\n",
    "def cluster_paths_by_signature(paths: List[List[Tuple[int, int]]], *, max_modes: int) -> List[int]:\n",
    "    sig_to_cluster: Dict[str, int] = {}\n",
    "    assignments: List[int] = []\n",
    "\n",
    "    def signature(path: List[Tuple[int, int]]) -> str:\n",
    "        if len(path) < 2:\n",
    "            return \"EMPTY\"\n",
    "        dirs = []\n",
    "        for i in range(1, len(path)):\n",
    "            dr = path[i][0] - path[i - 1][0]\n",
    "            dc = path[i][1] - path[i - 1][1]\n",
    "            dirs.append((dr, dc))\n",
    "\n",
    "        comp = []\n",
    "        for d in dirs:\n",
    "            if not comp or comp[-1] != d:\n",
    "                comp.append(d)\n",
    "\n",
    "        m = {(-1, 0): \"U\", (1, 0): \"D\", (0, -1): \"L\", (0, 1): \"R\", (0, 0): \"S\"}\n",
    "        return \"\".join(m.get(d, \"?\") for d in comp)[:120]\n",
    "\n",
    "    for p in paths:\n",
    "        sig = signature(p)\n",
    "\n",
    "        if sig in sig_to_cluster:\n",
    "            cid = sig_to_cluster[sig]\n",
    "        elif len(sig_to_cluster) < max_modes:\n",
    "            cid = len(sig_to_cluster)\n",
    "            sig_to_cluster[sig] = cid\n",
    "        else:\n",
    "            cid = stable_bucket(sig, len(sig_to_cluster))\n",
    "\n",
    "        assignments.append(cid)\n",
    "\n",
    "    return assignments\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModeLibraryInfo:\n",
    "    num_candidates: int\n",
    "    num_clusters: int\n",
    "\n",
    "\n",
    "def unique_weighted_sample(particles: List[Particle], weights: List[float], k: int) -> List[Particle]:\n",
    "    \"\"\"Approximate weighted sampling without replacement by oversampling then uniquing.\"\"\"\n",
    "    if not particles:\n",
    "        return []\n",
    "    if k <= 0:\n",
    "        return []\n",
    "    oversample = max(k, 3 * k)\n",
    "    picks = random.choices(particles, weights=weights, k=oversample)\n",
    "    seen = set()\n",
    "    out: List[Particle] = []\n",
    "    for p in picks:\n",
    "        key = (p.sensor_pos, p.mode_idx)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append(p)\n",
    "        if len(out) >= k:\n",
    "            break\n",
    "    # If we still don't have k, allow duplicates as a fallback\n",
    "    while len(out) < k:\n",
    "        out.append(random.choices(particles, weights=weights, k=1)[0])\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_multimodal_path_library(\n",
    "    world: GridWorld,\n",
    "    belief: BeliefState,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    detection: DetectionModel,\n",
    "    *,\n",
    "    num_hypotheses: int = 30,\n",
    "    per_hypothesis_attempts: int = 2,\n",
    "    base_step_cost: float = 1.0,\n",
    "    w_detect: float = 8.0,\n",
    "    rand_scale: float = 0.40,\n",
    "    max_modes: int = 6,\n",
    "    plausibility_lambda: float = 3.0,\n",
    "    t: int = 0,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> Tuple[List[PathMode], ModeLibraryInfo]:\n",
    "    if not belief.particles:\n",
    "        return [], ModeLibraryInfo(num_candidates=0, num_clusters=0)\n",
    "\n",
    "    # Sample particles proportional to weight\n",
    "    weights = [p.weight for p in belief.particles]\n",
    "    s = sum(weights)\n",
    "    if s <= 0.0:\n",
    "        weights = [1.0 / len(weights)] * len(weights)\n",
    "    else:\n",
    "        weights = [w / s for w in weights]\n",
    "\n",
    "    # NEW: more diverse sampling\n",
    "    sampled_particles = unique_weighted_sample(belief.particles, weights, k=num_hypotheses)\n",
    "\n",
    "    candidates: List[PathMode] = []\n",
    "\n",
    "    hyp_print_budget = log.cfg.max_hyp_print if (log and log.cfg.level >= 2 and t <= log.cfg.detail_until_t) else 0\n",
    "\n",
    "    for hi, hp in enumerate(sampled_particles):\n",
    "        hyp_sensor = hp.sensor_pos\n",
    "        hyp_mode = hp.mode_idx\n",
    "        hyp_w = float(getattr(hp, \"weight\", 0.0))\n",
    "\n",
    "        if log is not None and hyp_print_budget > 0:\n",
    "            log.log(\n",
    "                f\"[Modes][detail] t={t} hyp#{hi+1}/{num_hypotheses} sensor={hyp_sensor} mode={belief.mode_names[hyp_mode] if 0<=hyp_mode<len(belief.mode_names) else hyp_mode} w={hyp_w:.4f}\",\n",
    "                t=t,\n",
    "                every=None,\n",
    "                lvl=2,\n",
    "            )\n",
    "            hyp_print_budget -= 1\n",
    "\n",
    "        for attempt in range(per_hypothesis_attempts):\n",
    "            cost_fn = build_cost_map_from_hypothesis(\n",
    "                world,\n",
    "                detection,\n",
    "                hyp_sensor,\n",
    "                base_step=base_step_cost,\n",
    "                w_detect=w_detect,\n",
    "                randomize=True,\n",
    "                rand_scale=rand_scale,\n",
    "            )\n",
    "            heur = lambda s: float(manhattan(s, goal))\n",
    "\n",
    "            res = astar_path(world, robot_pos, goal, step_cost=cost_fn, heuristic=heur)\n",
    "            if res is None:\n",
    "                continue\n",
    "\n",
    "            # NEW: plausibility-regularized score\n",
    "            score = float(res.cost) + plausibility_lambda * (-math.log(max(1e-12, hyp_w)))\n",
    "\n",
    "            candidates.append(\n",
    "                PathMode(\n",
    "                    path=res.path,\n",
    "                    total_cost=float(res.cost),\n",
    "                    score=score,\n",
    "                    hypothesis_sensor_pos=hyp_sensor,\n",
    "                    hypothesis_mode_idx=hyp_mode,\n",
    "                    hypothesis_weight=hyp_w,\n",
    "                    debug_info={\"expanded\": res.expanded, \"attempt\": attempt + 1},\n",
    "                )\n",
    "            )\n",
    "\n",
    "    if not candidates:\n",
    "        if log is not None and log._should_print(t, log.cfg.modes_every_t, lvl=1):\n",
    "            log.log(f\"[Modes] t={t} candidates=0 (no paths found)\", t=t, every=log.cfg.modes_every_t, lvl=1)\n",
    "        return [], ModeLibraryInfo(num_candidates=0, num_clusters=0)\n",
    "\n",
    "    cluster_ids = cluster_paths_by_signature([c.path for c in candidates], max_modes=max_modes)\n",
    "\n",
    "    # NEW: pick best by *score* per cluster\n",
    "    best_by_cluster: Dict[int, PathMode] = {}\n",
    "    for c, cid in zip(candidates, cluster_ids):\n",
    "        if cid not in best_by_cluster or c.score < best_by_cluster[cid].score:\n",
    "            best_by_cluster[cid] = c\n",
    "\n",
    "    # NEW: sort by score, not raw cost\n",
    "    library = sorted(best_by_cluster.values(), key=lambda pm: pm.score)[:max_modes]\n",
    "\n",
    "    if log is not None and log._should_print(t, log.cfg.modes_every_t, lvl=1):\n",
    "        best = \", \".join(\n",
    "            f\"{belief.mode_names[pm.hypothesis_mode_idx] if 0<=pm.hypothesis_mode_idx<len(belief.mode_names) else pm.hypothesis_mode_idx}:\"\n",
    "            f\"w={pm.hypothesis_weight:.3f},cost={pm.total_cost:.1f},score={pm.score:.1f}\"\n",
    "            for pm in library[:min(3, len(library))]\n",
    "        )\n",
    "        log.log(\n",
    "            f\"[Modes] t={t} candidates={len(candidates)} clusters={len(best_by_cluster)} kept={len(library)} | top3: {best}\",\n",
    "            t=t,\n",
    "            every=log.cfg.modes_every_t,\n",
    "            lvl=1,\n",
    "        )\n",
    "\n",
    "        if log.cfg.level >= 2 and t <= log.cfg.detail_until_t:\n",
    "            for i, pm in enumerate(library):\n",
    "                a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "                mname = belief.mode_names[pm.hypothesis_mode_idx] if 0 <= pm.hypothesis_mode_idx < len(belief.mode_names) else str(pm.hypothesis_mode_idx)\n",
    "                log.log(\n",
    "                    f\"[ModesKept] t={t} #{i+1} mode={mname} hypS={pm.hypothesis_sensor_pos} a0={a0} w={pm.hypothesis_weight:.4f} cost={pm.total_cost:.2f} score={pm.score:.2f}\",\n",
    "                    t=t,\n",
    "                    every=None,\n",
    "                    lvl=2,\n",
    "                )\n",
    "\n",
    "    return library, ModeLibraryInfo(num_candidates=len(candidates), num_clusters=len(best_by_cluster))\n",
    "\n",
    "\n",
    "def first_action_from_path(world: GridWorld, start: Tuple[int, int], path: List[Tuple[int, int]]) -> Action:\n",
    "    if len(path) < 2:\n",
    "        return \"S\"\n",
    "    nxt = path[1]\n",
    "    dr = nxt[0] - start[0]\n",
    "    dc = nxt[1] - start[1]\n",
    "    for a, (adr, adc) in ACTION_DELTAS.items():\n",
    "        if (dr, dc) == (adr, adc):\n",
    "            return a\n",
    "    return \"S\"\n",
    "\n",
    "\n",
    "def build_action_prior_from_library(\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    library: List[PathMode],\n",
    "    *,\n",
    "    temp: float = 25.0,\n",
    ") -> Dict[Action, float]:\n",
    "    \"\"\"Mixture prior over kept modes: weight = hyp_weight * exp(-cost/temp).\"\"\"\n",
    "    if not library:\n",
    "        return {a: 1.0 / len(ACTIONS) for a in ACTIONS}\n",
    "\n",
    "    pri_raw: Dict[Action, float] = defaultdict(float)\n",
    "    for pm in library:\n",
    "        a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "        w = max(1e-12, pm.hypothesis_weight)\n",
    "        w *= math.exp(-pm.total_cost / max(1e-6, temp))\n",
    "        pri_raw[a0] += w\n",
    "\n",
    "    return normalize_probs_dict(pri_raw, ACTIONS)\n",
    "\n",
    "\n",
    "def prior_diagnostics(prior: Dict[Action, float]) -> str:\n",
    "    ent = 0.0\n",
    "    for a in ACTIONS:\n",
    "        p = float(prior.get(a, 0.0))\n",
    "        if p > 1e-12:\n",
    "            ent -= p * math.log(p)\n",
    "    return f\"H={ent:.3f} top={topk_str(prior, k=3)}\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# GenBR-lite: Belief-space MCTS with PUCT\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class MCTSNode:\n",
    "    robot_pos: Tuple[int, int]\n",
    "    depth: int\n",
    "\n",
    "    N: int = 0\n",
    "    N_a: Dict[Action, int] = field(default_factory=lambda: {a: 0 for a in ACTIONS})\n",
    "    W_a: Dict[Action, float] = field(default_factory=lambda: {a: 0.0 for a in ACTIONS})\n",
    "    Q_a: Dict[Action, float] = field(default_factory=lambda: {a: 0.0 for a in ACTIONS})\n",
    "\n",
    "    P_a: Dict[Action, float] = field(default_factory=lambda: {a: 1.0 / len(ACTIONS) for a in ACTIONS})\n",
    "\n",
    "    children: Dict[Action, \"MCTSNode\"] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def select_action_puct(node: MCTSNode, *, c_puct: float) -> Action:\n",
    "    \"\"\"PUCT: argmax_a Q + c*P*sqrt(N)/(1+N_a). Uses node.P_a.\"\"\"\n",
    "    sqrtN = math.sqrt(max(1, node.N))\n",
    "\n",
    "    best_a: Optional[Action] = None\n",
    "    best_score = -1e18\n",
    "\n",
    "    for a in ACTIONS:\n",
    "        q = node.Q_a[a]\n",
    "        u = c_puct * node.P_a[a] * sqrtN / (1.0 + node.N_a[a])\n",
    "        score = q + u + random.uniform(-1e-9, 1e-9)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_a = a\n",
    "\n",
    "    assert best_a is not None\n",
    "    return best_a\n",
    "\n",
    "\n",
    "def backprop_path(path: List[Tuple[MCTSNode, Action]], value: float) -> None:\n",
    "    for node, a in reversed(path):\n",
    "        node.N += 1\n",
    "        node.N_a[a] += 1\n",
    "        node.W_a[a] += value\n",
    "        node.Q_a[a] = node.W_a[a] / node.N_a[a]\n",
    "\n",
    "\n",
    "def choose_final_action(root: MCTSNode) -> Action:\n",
    "    maxN = max(root.N_a.values())\n",
    "    cand = [a for a in ACTIONS if root.N_a[a] == maxN]\n",
    "    if len(cand) == 1:\n",
    "        return cand[0]\n",
    "\n",
    "    maxQ = max(root.Q_a[a] for a in cand)\n",
    "    cand2 = [a for a in cand if abs(root.Q_a[a] - maxQ) < 1e-12]\n",
    "    if len(cand2) == 1:\n",
    "        return cand2[0]\n",
    "\n",
    "    maxP = max(root.P_a[a] for a in cand2)\n",
    "    cand3 = [a for a in cand2 if abs(root.P_a[a] - maxP) < 1e-12]\n",
    "    return random.choice(cand3)\n",
    "\n",
    "\n",
    "def rollout_value(\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    detection: DetectionModel,\n",
    "    *,\n",
    "    max_steps: int,\n",
    "    w_step: float,\n",
    "    w_detect: float,\n",
    ") -> float:\n",
    "    total_cost = 0.0\n",
    "    cur = robot_pos\n",
    "    for _ in range(max_steps):\n",
    "        if cur == goal:\n",
    "            break\n",
    "        a = deterministic_greedy_step_toward(world, cur, goal)\n",
    "        cur = world.step(cur, a)\n",
    "        total_cost += w_step\n",
    "        total_cost += w_detect * detection.p_detect(cur, sensor_pos)\n",
    "    if cur == goal:\n",
    "        total_cost -= 20.0\n",
    "    return -total_cost\n",
    "\n",
    "\n",
    "def simulate_sensor_step(\n",
    "    world: GridWorld,\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    robot_pos: Tuple[int, int],\n",
    "    t: int,\n",
    "    mode_idx: int,\n",
    "    policies: List[SensorModePolicy],\n",
    ") -> Tuple[int, int]:\n",
    "    if 0 <= mode_idx < len(policies):\n",
    "        aS = policies[mode_idx].action(world, sensor_pos, robot_pos, t)\n",
    "        return world.step(sensor_pos, aS)\n",
    "    return sensor_pos\n",
    "\n",
    "\n",
    "def mcts_search_action(\n",
    "    world: GridWorld,\n",
    "    belief: BeliefState,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    sensor_policies: List[SensorModePolicy],\n",
    "    detection: DetectionModel,\n",
    "    action_prior: Dict[Action, float],\n",
    "    *,\n",
    "    t: int,\n",
    "    num_sims: int = 250,\n",
    "    max_depth: int = 10,\n",
    "    c_puct: float = 1.4,\n",
    "    w_step: float = 1.0,\n",
    "    w_detect: float = 7.0,\n",
    "    gamma: float = 0.95,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> Action:\n",
    "    prior = normalize_probs_dict(action_prior, ACTIONS, eps=0.10)\n",
    "\n",
    "    root = MCTSNode(robot_pos=robot_pos, depth=0)\n",
    "    root.P_a = prior\n",
    "\n",
    "    # Prepare particle sampling distribution\n",
    "    particles = belief.particles if belief.particles else [Particle(sensor_pos=robot_pos, mode_idx=0, weight=1.0)]\n",
    "    weights = [float(getattr(p, \"weight\", 1.0)) for p in particles]\n",
    "    s = sum(weights)\n",
    "    if s <= 0.0:\n",
    "        weights = [1.0 / len(weights)] * len(weights)\n",
    "    else:\n",
    "        weights = [w / s for w in weights]\n",
    "\n",
    "    if log is not None and (log._should_print(t, log.cfg.mcts_every_t, lvl=1)):\n",
    "        log.log(f\"[MCTS] t={t} sims={num_sims} depth={max_depth} prior: {prior_diagnostics(prior)}\", t=t, every=log.cfg.mcts_every_t, lvl=1)\n",
    "\n",
    "    for sim in range(num_sims):\n",
    "        hp = random.choices(particles, weights=weights, k=1)[0]\n",
    "        sim_sensor = hp.sensor_pos\n",
    "        sim_mode = hp.mode_idx\n",
    "\n",
    "        node = root\n",
    "        cur_robot = robot_pos\n",
    "        cur_sensor = sim_sensor\n",
    "\n",
    "        path: List[Tuple[MCTSNode, Action]] = []\n",
    "        total_return = 0.0\n",
    "        disc = 1.0\n",
    "\n",
    "        if cur_robot == goal:\n",
    "            root.N += 1\n",
    "            continue\n",
    "\n",
    "        for depth in range(max_depth):\n",
    "            if cur_robot == goal:\n",
    "                total_return += disc * 50.0\n",
    "                break\n",
    "\n",
    "            a = select_action_puct(node, c_puct=c_puct)\n",
    "            path.append((node, a))\n",
    "\n",
    "            nxt_robot = world.step(cur_robot, a)\n",
    "            nxt_sensor = simulate_sensor_step(world, cur_sensor, nxt_robot, t + depth, sim_mode, sensor_policies)\n",
    "\n",
    "            step_cost = w_step + w_detect * detection.p_detect(nxt_robot, nxt_sensor)\n",
    "            total_return += disc * (-step_cost)\n",
    "            disc *= gamma\n",
    "\n",
    "            if a not in node.children:\n",
    "                child = MCTSNode(robot_pos=nxt_robot, depth=node.depth + 1)\n",
    "                child.P_a = prior\n",
    "                node.children[a] = child\n",
    "\n",
    "                leaf_v = rollout_value(\n",
    "                    world,\n",
    "                    nxt_robot,\n",
    "                    nxt_sensor,\n",
    "                    goal,\n",
    "                    detection,\n",
    "                    max_steps=max_depth - depth - 1,\n",
    "                    w_step=w_step,\n",
    "                    w_detect=w_detect,\n",
    "                )\n",
    "                total_return += disc * leaf_v\n",
    "                break\n",
    "\n",
    "            node = node.children[a]\n",
    "            cur_robot, cur_sensor = nxt_robot, nxt_sensor\n",
    "\n",
    "        if path:\n",
    "            backprop_path(path, total_return)\n",
    "        else:\n",
    "            root.N += 1\n",
    "\n",
    "        if log is not None and log.cfg.level >= 2 and (sim < 2 or ((sim + 1) % log.cfg.mcts_progress_every_sims == 0 and t <= log.cfg.detail_until_t)):\n",
    "            log.log(f\"[MCTS][detail] t={t} sim={sim+1}/{num_sims} root.N={root.N}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    total_edge_visits = sum(root.N_a.values())\n",
    "    if log is not None and log._should_print(t, log.cfg.mcts_every_t, lvl=1):\n",
    "        bestN = max(root.N_a, key=lambda a: root.N_a[a])\n",
    "        log.log(\n",
    "            f\"[MCTS] t={t} root.N={root.N} sum(N_a)={total_edge_visits} best_by_N={bestN}\",\n",
    "            t=t,\n",
    "            every=log.cfg.mcts_every_t,\n",
    "            lvl=1,\n",
    "        )\n",
    "        if log.cfg.level >= 2 and t <= log.cfg.detail_until_t:\n",
    "            for a in ACTIONS:\n",
    "                log.log(f\"[MCTS][detail] a={a} N={root.N_a[a]:4d} Q={root.Q_a[a]:+8.3f} P={root.P_a[a]:.3f}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    return choose_final_action(root)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Main Simulation\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    seed: int = 7\n",
    "\n",
    "    H: int = 12\n",
    "    W: int = 18\n",
    "    T: int = 40\n",
    "\n",
    "    num_particles: int = 250\n",
    "\n",
    "    # PF\n",
    "    motion_noise: float = 0.15\n",
    "    resample_threshold: float = 0.55\n",
    "\n",
    "    # Mode library\n",
    "    num_hypotheses: int = 25\n",
    "    per_hypothesis_attempts: int = 2\n",
    "    max_modes: int = 6\n",
    "    w_detect_astar: float = 10.0\n",
    "    rand_scale: float = 0.45\n",
    "\n",
    "    # NEW: plausibility-vs-cost tradeoff\n",
    "    plausibility_lambda: float = 3.0\n",
    "\n",
    "    # NEW: prior temperature\n",
    "    prior_temp: float = 25.0\n",
    "\n",
    "    # MCTS\n",
    "    num_sims: int = 250\n",
    "    max_depth: int = 10\n",
    "    c_puct: float = 1.4\n",
    "    w_step_mcts: float = 1.0\n",
    "    w_detect_mcts: float = 7.0\n",
    "\n",
    "    # NEW: force a specific true mode for reproducibility\n",
    "    true_mode_name: Optional[str] = \"chase_robot\"  # set None for random\n",
    "\n",
    "    # Debug\n",
    "    debug: DebugConfig = field(default_factory=DebugConfig)\n",
    "\n",
    "\n",
    "def make_demo_world(cfg: Config) -> Tuple[GridWorld, Tuple[int, int], Tuple[int, int], Tuple[int, int]]:\n",
    "    obs = set()\n",
    "    for c in range(3, 15):\n",
    "        obs.add((5, c))\n",
    "    for r in range(1, 9):\n",
    "        obs.add((r, 9))\n",
    "    obs.discard((5, 7))\n",
    "    obs.discard((6, 9))\n",
    "\n",
    "    world = GridWorld(H=cfg.H, W=cfg.W, obstacles=obs)\n",
    "    robot_start = (10, 2)\n",
    "    goal = (1, 16)\n",
    "    sensor_start = (2, 2)\n",
    "    return world, robot_start, sensor_start, goal\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = Config()\n",
    "    seed_all(cfg.seed)\n",
    "\n",
    "    log = Logger(cfg.debug)\n",
    "\n",
    "    world, robot_pos, sensor_pos, goal = make_demo_world(cfg)\n",
    "\n",
    "    sensor_modes: List[SensorModePolicy] = [\n",
    "        PatrolLoopPolicy(name=\"patrol_left\", loop=[(2, 2), (2, 6), (4, 6), (4, 2)]),\n",
    "        PatrolLoopPolicy(name=\"patrol_mid\", loop=[(2, 10), (2, 13), (4, 13), (4, 10)]),\n",
    "        ChasePolicy(name=\"chase_robot\"),\n",
    "        RandomWalkPolicy(name=\"random_walk\"),\n",
    "    ]\n",
    "    mode_names = [m.name for m in sensor_modes]\n",
    "\n",
    "    # NEW: deterministic true mode option\n",
    "    if cfg.true_mode_name is None:\n",
    "        true_mode_idx = random.randrange(len(sensor_modes))\n",
    "    else:\n",
    "        try:\n",
    "            true_mode_idx = mode_names.index(cfg.true_mode_name)\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"true_mode_name={cfg.true_mode_name!r} not in modes {mode_names}\")\n",
    "\n",
    "    detection = DetectionModel()\n",
    "    obs_model = ObservationModel(sigma=1.3)\n",
    "\n",
    "    sensor_init_candidates = [(2, 2), (2, 10), (3, 3), (3, 9), (1, 1)]\n",
    "    mode_prior = [1.0] * len(sensor_modes)\n",
    "    belief = initialize_belief(world, sensor_init_candidates, mode_prior, mode_names, cfg.num_particles)\n",
    "\n",
    "    log.log(f\"[INIT] true_mode={mode_names[true_mode_idx]} robot={robot_pos} sensor={sensor_pos} goal={goal}\", force=True)\n",
    "    log.log(f\"[INIT] belief modes: {topk_str(belief.mode_posterior_named(), k=4)}\", force=True)\n",
    "\n",
    "    for t in range(cfg.T):\n",
    "        show_header = (t <= cfg.debug.detail_until_t) or (cfg.debug.enabled and cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)\n",
    "        if show_header:\n",
    "            log.log(\"=\" * 80, force=True)\n",
    "            log.log(f\"[TIME] t={t}\", force=True)\n",
    "\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.render_every_t > 0 and t % cfg.debug.render_every_t == 0)):\n",
    "            log.log(\"[WORLD]\", t=t, every=cfg.debug.render_every_t, lvl=1, force=(t <= cfg.debug.detail_until_t))\n",
    "            world.render(robot=robot_pos, sensor=sensor_pos, goal=goal)\n",
    "\n",
    "        obs = obs_model.sample_observation(sensor_pos, world)\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[OBS] obs={obs} (true sensor={sensor_pos})\", force=True)\n",
    "\n",
    "        # PF update\n",
    "        _ = belief_predict_update(\n",
    "            belief,\n",
    "            world,\n",
    "            robot_pos,\n",
    "            sensor_modes,\n",
    "            obs_model,\n",
    "            obs,\n",
    "            t,\n",
    "            motion_noise=cfg.motion_noise,\n",
    "            resample_threshold=cfg.resample_threshold,\n",
    "            log=log,\n",
    "        )\n",
    "\n",
    "        # Mode library -> prior\n",
    "        library, _ = build_multimodal_path_library(\n",
    "            world,\n",
    "            belief,\n",
    "            robot_pos,\n",
    "            goal,\n",
    "            detection,\n",
    "            num_hypotheses=cfg.num_hypotheses,\n",
    "            per_hypothesis_attempts=cfg.per_hypothesis_attempts,\n",
    "            w_detect=cfg.w_detect_astar,\n",
    "            rand_scale=cfg.rand_scale,\n",
    "            max_modes=cfg.max_modes,\n",
    "            plausibility_lambda=cfg.plausibility_lambda,\n",
    "            t=t,\n",
    "            log=log,\n",
    "        )\n",
    "\n",
    "        action_prior = build_action_prior_from_library(world, robot_pos, library, temp=cfg.prior_temp)\n",
    "\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[PriorDiag] {prior_diagnostics(action_prior)}\", force=True)\n",
    "\n",
    "        # MCTS choose action\n",
    "        aR = mcts_search_action(\n",
    "            world,\n",
    "            belief,\n",
    "            robot_pos,\n",
    "            goal,\n",
    "            sensor_modes,\n",
    "            detection,\n",
    "            action_prior,\n",
    "            t=t,\n",
    "            num_sims=cfg.num_sims,\n",
    "            max_depth=cfg.max_depth,\n",
    "            c_puct=cfg.c_puct,\n",
    "            w_step=cfg.w_step_mcts,\n",
    "            w_detect=cfg.w_detect_mcts,\n",
    "            log=log,\n",
    "        )\n",
    "\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[ACT] robot aR={aR}\", force=True)\n",
    "\n",
    "        # Step robot and true sensor\n",
    "        new_robot = world.step(robot_pos, aR)\n",
    "        aS_true = sensor_modes[true_mode_idx].action(world, sensor_pos, new_robot, t)\n",
    "\n",
    "        # NEW: chase sanity check on TRUE sensor if chase mode\n",
    "        if mode_names[true_mode_idx] == \"chase_robot\":\n",
    "            chase_sanity_check(world, sensor_pos, new_robot, aS_true, log=log, t=t, tag=\"true\")\n",
    "\n",
    "        new_sensor = world.step(sensor_pos, aS_true)\n",
    "\n",
    "        robot_pos, sensor_pos = new_robot, new_sensor\n",
    "\n",
    "        # Detection\n",
    "        p_det = detection.p_detect(robot_pos, sensor_pos)\n",
    "        detected = (random.random() < p_det)\n",
    "\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[STEP] robot={robot_pos} sensor={sensor_pos} aS={aS_true} p_det={p_det:.3f} detected={detected}\", force=True)\n",
    "\n",
    "        # Terminate\n",
    "        if robot_pos == goal:\n",
    "            log.log(\"[TERMINAL] reached goal \", force=True)\n",
    "            break\n",
    "        if detected and manhattan(robot_pos, sensor_pos) <= detection.d0:\n",
    "            log.log(\"[TERMINAL] caught \", force=True)\n",
    "            break\n",
    "\n",
    "    log.log(\"[DONE]\", force=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a4d7985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] true_mode=chase_robot robot=(10, 2) sensor=(2, 2) goal=(1, 16)\n",
      "[INIT] belief modes: random_walk:0.272 | patrol_left:0.260 | patrol_mid:0.240 | chase_robot:0.228\n",
      "================================================================================\n",
      "[TIME] t=0\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      "..S......#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..R...............\n",
      "..................\n",
      "[OBS] obs=(4, 3) (true sensor=(2, 2))\n",
      "[PF] t=0 obs=(4, 3) ESS 250.0->61.1 resample=True | modes: chase_robot:0.508 | random_walk:0.192 | patrol_left:0.152\n",
      "[Modes] t=0 candidates=50 clusters=6 kept=6 | top3: random_walk:w=0.004,cost=37.1,score=53.7, random_walk:w=0.004,cost=37.2,score=53.8, random_walk:w=0.004,cost=37.7,score=54.3\n",
      "[PriorCheck][WARN] t=0 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.0052\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=0 #1 a0=R mix_w=0.000907 mode=random_walk hypS=(3, 1) hyp_w=0.0040 cost=37.09 score=53.66\n",
      "[PriorCheck][Kept] t=0 #2 a0=R mix_w=0.000903 mode=random_walk hypS=(2, 1) hyp_w=0.0040 cost=37.22 score=53.78\n",
      "[PriorCheck][Kept] t=0 #3 a0=R mix_w=0.000884 mode=random_walk hypS=(3, 1) hyp_w=0.0040 cost=37.74 score=54.30\n",
      "[PriorCheck][Kept] t=0 #4 a0=R mix_w=0.00086 mode=patrol_left hypS=(2, 2) hyp_w=0.0040 cost=38.41 score=54.98\n",
      "[PriorCheck][Kept] t=0 #5 a0=R mix_w=0.000854 mode=patrol_left hypS=(2, 3) hyp_w=0.0040 cost=38.61 score=55.17\n",
      "[PriorCheck][Kept] t=0 #6 a0=R mix_w=0.000793 mode=patrol_mid hypS=(2, 3) hyp_w=0.0040 cost=40.46 score=57.02\n",
      "[PriorDiag] eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=0 sims=250 depth=10 prior: H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=0 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[CHASE] true t=0 src=(2, 2) dst=(10, 3) a=D nxt=(3, 2) d:9->8 best_d=8 best=['D', 'R']\n",
      "[STEP] robot=(10, 3) sensor=(3, 2) aS=D p_det=0.191 detected=True\n",
      "================================================================================\n",
      "[TIME] t=1\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      "..S......#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "...R..............\n",
      "..................\n",
      "[OBS] obs=(3, 0) (true sensor=(3, 2))\n",
      "[PF] t=1 obs=(3, 0) ESS 250.0->85.6 resample=True | modes: chase_robot:0.476 | random_walk:0.372 | patrol_left:0.096\n",
      "[Modes] t=1 candidates=50 clusters=6 kept=6 | top3: random_walk:w=0.004,cost=33.2,score=49.7, random_walk:w=0.004,cost=33.2,score=49.8, random_walk:w=0.004,cost=33.2,score=49.8\n",
      "[PriorCheck][WARN] t=1 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.00605\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=1 #1 a0=R mix_w=0.00106 mode=random_walk hypS=(1, 0) hyp_w=0.0040 cost=33.18 score=49.74\n",
      "[PriorCheck][Kept] t=1 #2 a0=R mix_w=0.00106 mode=random_walk hypS=(3, 0) hyp_w=0.0040 cost=33.20 score=49.76\n",
      "[PriorCheck][Kept] t=1 #3 a0=R mix_w=0.00106 mode=random_walk hypS=(1, 0) hyp_w=0.0040 cost=33.21 score=49.77\n",
      "[PriorCheck][Kept] t=1 #4 a0=R mix_w=0.00103 mode=chase_robot hypS=(3, 1) hyp_w=0.0040 cost=33.86 score=50.42\n",
      "[PriorCheck][Kept] t=1 #5 a0=R mix_w=0.00102 mode=random_walk hypS=(1, 1) hyp_w=0.0040 cost=34.10 score=50.66\n",
      "[PriorCheck][Kept] t=1 #6 a0=R mix_w=0.000811 mode=patrol_left hypS=(2, 4) hyp_w=0.0040 cost=39.90 score=56.46\n",
      "[PriorDiag] eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=1 sims=250 depth=10 prior: H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=1 root.N=250 sum(N_a)=250 best_by_N=D\n",
      "[ACT] robot aR=D\n",
      "[CHASE] true t=1 src=(3, 2) dst=(11, 3) a=D nxt=(4, 2) d:9->8 best_d=8 best=['D', 'R']\n",
      "[STEP] robot=(11, 3) sensor=(4, 2) aS=D p_det=0.191 detected=False\n",
      "================================================================================\n",
      "[TIME] t=2\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      "..S......#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "...R..............\n",
      "[OBS] obs=(4, 2) (true sensor=(4, 2))\n",
      "[PF] t=2 obs=(4, 2) ESS 250.0->175.9 resample=False | modes: chase_robot:0.677 | random_walk:0.293 | patrol_left:0.026\n",
      "[Modes] t=2 candidates=50 clusters=6 kept=6 | top3: random_walk:w=0.013,cost=36.6,score=49.6, random_walk:w=0.013,cost=37.3,score=50.4, chase_robot:w=0.006,cost=36.0,score=51.3\n",
      "[PriorCheck][WARN] t=2 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.0105\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=2 #1 a0=R mix_w=0.00302 mode=random_walk hypS=(4, 2) hyp_w=0.0130 cost=36.60 score=49.62\n",
      "[PriorCheck][Kept] t=2 #2 a0=R mix_w=0.00293 mode=random_walk hypS=(4, 2) hyp_w=0.0130 cost=37.34 score=50.36\n",
      "[PriorCheck][Kept] t=2 #3 a0=R mix_w=0.00143 mode=chase_robot hypS=(4, 1) hyp_w=0.0060 cost=35.99 score=51.32\n",
      "[PriorCheck][Kept] t=2 #4 a0=R mix_w=0.00142 mode=random_walk hypS=(3, 2) hyp_w=0.0060 cost=36.21 score=51.53\n",
      "[PriorCheck][Kept] t=2 #5 a0=R mix_w=0.00137 mode=random_walk hypS=(3, 2) hyp_w=0.0060 cost=37.11 score=52.44\n",
      "[PriorCheck][Kept] t=2 #6 a0=R mix_w=0.000315 mode=random_walk hypS=(1, 2) hyp_w=0.0013 cost=35.41 score=55.35\n",
      "[PriorDiag] eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=2 sims=250 depth=10 prior: H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=2 root.N=250 sum(N_a)=250 best_by_N=D\n",
      "[ACT] robot aR=D\n",
      "[CHASE] true t=2 src=(4, 2) dst=(11, 3) a=D nxt=(5, 2) d:8->7 best_d=7 best=['D', 'R']\n",
      "[STEP] robot=(11, 3) sensor=(5, 2) aS=D p_det=0.240 detected=False\n",
      "[PF] t=3 obs=(7, 1) ESS 175.9->65.8 resample=True | modes: chase_robot:0.852 | random_walk:0.148\n",
      "[PriorCheck][WARN] t=3 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.00558\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=3 #1 a0=R mix_w=0.00101 mode=random_walk hypS=(3, 0) hyp_w=0.0040 cost=34.39 score=50.95\n",
      "[PriorCheck][Kept] t=3 #2 a0=R mix_w=0.000982 mode=random_walk hypS=(3, 0) hyp_w=0.0040 cost=35.12 score=51.68\n",
      "[PriorCheck][Kept] t=3 #3 a0=R mix_w=0.000959 mode=chase_robot hypS=(5, 0) hyp_w=0.0040 cost=35.71 score=52.27\n",
      "[PriorCheck][Kept] t=3 #4 a0=R mix_w=0.000899 mode=random_walk hypS=(5, 0) hyp_w=0.0040 cost=37.31 score=53.87\n",
      "[PriorCheck][Kept] t=3 #5 a0=R mix_w=0.000894 mode=random_walk hypS=(3, 2) hyp_w=0.0040 cost=37.46 score=54.03\n",
      "[PriorCheck][Kept] t=3 #6 a0=R mix_w=0.000838 mode=random_walk hypS=(5, 2) hyp_w=0.0040 cost=39.09 score=55.65\n",
      "[PF] t=4 obs=(4, 1) ESS 250.0->104.9 resample=True | modes: chase_robot:0.568 | random_walk:0.432\n",
      "[PriorCheck][WARN] t=4 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.00591\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=4 #1 a0=R mix_w=0.00108 mode=random_walk hypS=(3, 0) hyp_w=0.0040 cost=32.78 score=49.34\n",
      "[PriorCheck][Kept] t=4 #2 a0=R mix_w=0.00107 mode=random_walk hypS=(2, 1) hyp_w=0.0040 cost=32.88 score=49.44\n",
      "[PriorCheck][Kept] t=4 #3 a0=R mix_w=0.00101 mode=random_walk hypS=(4, 0) hyp_w=0.0040 cost=34.33 score=50.90\n",
      "[PriorCheck][Kept] t=4 #4 a0=R mix_w=0.00101 mode=random_walk hypS=(5, 0) hyp_w=0.0040 cost=34.38 score=50.94\n",
      "[PriorCheck][Kept] t=4 #5 a0=R mix_w=0.000942 mode=chase_robot hypS=(6, 1) hyp_w=0.0040 cost=36.14 score=52.71\n",
      "[PriorCheck][Kept] t=4 #6 a0=R mix_w=0.000787 mode=chase_robot hypS=(7, 1) hyp_w=0.0040 cost=40.64 score=57.21\n",
      "================================================================================\n",
      "[TIME] t=5\n",
      "[OBS] obs=(6, 4) (true sensor=(7, 2))\n",
      "[PF] t=5 obs=(6, 4) ESS 250.0->139.7 resample=False | modes: chase_robot:0.615 | random_walk:0.385\n",
      "[Modes] t=5 candidates=50 clusters=6 kept=6 | top3: random_walk:w=0.020,cost=35.1,score=46.9, random_walk:w=0.009,cost=33.1,score=47.2, random_walk:w=0.009,cost=33.4,score=47.5\n",
      "[PriorCheck][WARN] t=5 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.0139\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=5 #1 a0=R mix_w=0.00488 mode=random_walk hypS=(6, 2) hyp_w=0.0199 cost=35.15 score=46.90\n",
      "[PriorCheck][Kept] t=5 #2 a0=R mix_w=0.00245 mode=random_walk hypS=(6, 1) hyp_w=0.0092 cost=33.13 score=47.19\n",
      "[PriorCheck][Kept] t=5 #3 a0=R mix_w=0.00242 mode=random_walk hypS=(6, 1) hyp_w=0.0092 cost=33.40 score=47.46\n",
      "[PriorCheck][Kept] t=5 #4 a0=R mix_w=0.00236 mode=random_walk hypS=(6, 1) hyp_w=0.0092 cost=34.02 score=48.08\n",
      "[PriorCheck][Kept] t=5 #5 a0=R mix_w=0.00116 mode=random_walk hypS=(6, 0) hyp_w=0.0043 cost=32.51 score=48.88\n",
      "[PriorCheck][Kept] t=5 #6 a0=R mix_w=0.000571 mode=random_walk hypS=(5, 0) hyp_w=0.0020 cost=31.07 score=49.74\n",
      "[PriorDiag] eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=5 sims=250 depth=10 prior: H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=5 root.N=250 sum(N_a)=250 best_by_N=S\n",
      "[ACT] robot aR=S\n",
      "[CHASE] true t=5 src=(7, 2) dst=(11, 5) a=D nxt=(8, 2) d:7->6 best_d=6 best=['D', 'R']\n",
      "[STEP] robot=(11, 5) sensor=(8, 2) aS=D p_det=0.306 detected=False\n",
      "[PF] t=6 obs=(6, 0) ESS 139.7->37.0 resample=True | modes: random_walk:0.712 | chase_robot:0.288\n",
      "[PF] t=7 obs=(8, 3) ESS 250.0->81.3 resample=True | modes: chase_robot:0.776 | random_walk:0.224\n",
      "[PriorCheck][WARN] t=7 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.00609\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=7 #1 a0=R mix_w=0.00114 mode=random_walk hypS=(5, 2) hyp_w=0.0040 cost=31.29 score=47.85\n",
      "[PriorCheck][Kept] t=7 #2 a0=R mix_w=0.00113 mode=random_walk hypS=(7, 1) hyp_w=0.0040 cost=31.60 score=48.16\n",
      "[PriorCheck][Kept] t=7 #3 a0=R mix_w=0.0011 mode=random_walk hypS=(8, 0) hyp_w=0.0040 cost=32.20 score=48.77\n",
      "[PriorCheck][Kept] t=7 #4 a0=R mix_w=0.00107 mode=chase_robot hypS=(7, 2) hyp_w=0.0040 cost=32.94 score=49.51\n",
      "[PriorCheck][Kept] t=7 #5 a0=R mix_w=0.000925 mode=chase_robot hypS=(8, 2) hyp_w=0.0040 cost=36.61 score=53.18\n",
      "[PriorCheck][Kept] t=7 #6 a0=R mix_w=0.000718 mode=chase_robot hypS=(10, 3) hyp_w=0.0040 cost=42.93 score=59.50\n",
      "[PriorCheck][WARN] t=8 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.00887\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=8 #1 a0=R mix_w=0.00333 mode=chase_robot hypS=(9, 4) hyp_w=0.0143 cost=36.45 score=49.19\n",
      "[PriorCheck][Kept] t=8 #2 a0=R mix_w=0.00169 mode=chase_robot hypS=(9, 3) hyp_w=0.0066 cost=34.18 score=49.23\n",
      "[PriorCheck][Kept] t=8 #3 a0=R mix_w=0.00168 mode=chase_robot hypS=(8, 4) hyp_w=0.0066 cost=34.26 score=49.31\n",
      "[PriorCheck][Kept] t=8 #4 a0=R mix_w=0.000417 mode=chase_robot hypS=(8, 2) hyp_w=0.0014 cost=30.72 score=50.38\n",
      "[PriorCheck][Kept] t=8 #5 a0=R mix_w=0.00156 mode=chase_robot hypS=(8, 4) hyp_w=0.0066 cost=36.26 score=51.30\n",
      "[PriorCheck][Kept] t=8 #6 a0=R mix_w=0.000193 mode=random_walk hypS=(6, 3) hyp_w=0.0007 cost=30.78 score=52.75\n",
      "[PriorCheck][WARN] t=9 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.0111\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=9 #1 a0=R mix_w=0.00334 mode=chase_robot hypS=(9, 4) hyp_w=0.0127 cost=33.34 score=46.44\n",
      "[PriorCheck][Kept] t=9 #2 a0=R mix_w=0.00164 mode=random_walk hypS=(8, 4) hyp_w=0.0059 cost=31.87 score=47.28\n",
      "[PriorCheck][Kept] t=9 #3 a0=R mix_w=0.00161 mode=chase_robot hypS=(8, 4) hyp_w=0.0059 cost=32.30 score=47.71\n",
      "[PriorCheck][Kept] t=9 #4 a0=R mix_w=0.00156 mode=chase_robot hypS=(8, 4) hyp_w=0.0059 cost=33.10 score=48.51\n",
      "[PriorCheck][Kept] t=9 #5 a0=R mix_w=0.00151 mode=chase_robot hypS=(8, 4) hyp_w=0.0059 cost=33.90 score=49.31\n",
      "[PriorCheck][Kept] t=9 #6 a0=R mix_w=0.00146 mode=chase_robot hypS=(8, 4) hyp_w=0.0059 cost=34.72 score=50.13\n",
      "================================================================================\n",
      "[TIME] t=10\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      "......S..#........\n",
      "..................\n",
      "..................\n",
      ".........R........\n",
      "[OBS] obs=(6, 4) (true sensor=(8, 6))\n",
      "[PF] t=10 obs=(6, 4) ESS 174.8->156.1 resample=False | modes: chase_robot:0.963 | random_walk:0.037\n",
      "[Modes] t=10 candidates=50 clusters=6 kept=6 | top3: chase_robot:w=0.016,cost=29.1,score=41.4, random_walk:w=0.008,cost=31.0,score=45.6, random_walk:w=0.002,cost=26.5,score=45.8\n",
      "[PriorCheck][WARN] t=10 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.012\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=10 #1 a0=R mix_w=0.0051 mode=chase_robot hypS=(7, 4) hyp_w=0.0163 cost=29.08 score=41.43\n",
      "[PriorCheck][Kept] t=10 #2 a0=R mix_w=0.00219 mode=random_walk hypS=(7, 4) hyp_w=0.0076 cost=30.98 score=45.64\n",
      "[PriorCheck][Kept] t=10 #3 a0=R mix_w=0.000562 mode=random_walk hypS=(7, 2) hyp_w=0.0016 cost=26.50 score=45.77\n",
      "[PriorCheck][Kept] t=10 #4 a0=R mix_w=0.00212 mode=chase_robot hypS=(8, 5) hyp_w=0.0076 cost=31.75 score=46.40\n",
      "[PriorCheck][Kept] t=10 #5 a0=R mix_w=0.00102 mode=chase_robot hypS=(8, 4) hyp_w=0.0035 cost=30.84 score=47.80\n",
      "[PriorCheck][Kept] t=10 #6 a0=R mix_w=0.00101 mode=chase_robot hypS=(8, 4) hyp_w=0.0035 cost=31.04 score=48.00\n",
      "[PriorDiag] eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=10 sims=250 depth=10 prior: H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=10 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[CHASE] true t=10 src=(8, 6) dst=(11, 10) a=R nxt=(8, 7) d:7->6 best_d=6 best=['D', 'R']\n",
      "[STEP] robot=(11, 10) sensor=(8, 7) aS=R p_det=0.306 detected=False\n",
      "[PriorCheck][WARN] t=11 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.0123\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=11 #1 a0=R mix_w=0.00222 mode=chase_robot hypS=(8, 5) hyp_w=0.0070 cost=28.51 score=43.42\n",
      "[PriorCheck][Kept] t=11 #2 a0=R mix_w=0.00209 mode=chase_robot hypS=(8, 5) hyp_w=0.0070 cost=29.98 score=44.89\n",
      "[PriorCheck][Kept] t=11 #3 a0=R mix_w=0.00204 mode=chase_robot hypS=(8, 6) hyp_w=0.0070 cost=30.62 score=45.52\n",
      "[PriorCheck][Kept] t=11 #4 a0=R mix_w=0.00204 mode=chase_robot hypS=(8, 5) hyp_w=0.0070 cost=30.63 score=45.54\n",
      "[PriorCheck][Kept] t=11 #5 a0=R mix_w=0.00196 mode=chase_robot hypS=(8, 5) hyp_w=0.0070 cost=31.66 score=46.57\n",
      "[PriorCheck][Kept] t=11 #6 a0=R mix_w=0.00191 mode=chase_robot hypS=(8, 6) hyp_w=0.0070 cost=32.26 score=47.16\n",
      "[PF] t=12 obs=(7, 10) ESS 149.0->114.3 resample=True | modes: chase_robot:1.000\n",
      "[PriorCheck][WARN] t=12 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.00693\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=12 #1 a0=R mix_w=0.00126 mode=chase_robot hypS=(7, 7) hyp_w=0.0040 cost=28.97 score=45.53\n",
      "[PriorCheck][Kept] t=12 #2 a0=R mix_w=0.00119 mode=chase_robot hypS=(8, 7) hyp_w=0.0040 cost=30.34 score=46.90\n",
      "[PriorCheck][Kept] t=12 #3 a0=R mix_w=0.00119 mode=chase_robot hypS=(8, 7) hyp_w=0.0040 cost=30.40 score=46.97\n",
      "[PriorCheck][Kept] t=12 #4 a0=R mix_w=0.00118 mode=chase_robot hypS=(8, 7) hyp_w=0.0040 cost=30.47 score=47.03\n",
      "[PriorCheck][Kept] t=12 #5 a0=R mix_w=0.00113 mode=chase_robot hypS=(8, 7) hyp_w=0.0040 cost=31.63 score=48.19\n",
      "[PriorCheck][Kept] t=12 #6 a0=R mix_w=0.000989 mode=chase_robot hypS=(7, 8) hyp_w=0.0040 cost=34.93 score=51.49\n",
      "[PriorCheck][WARN] t=13 kept=6 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.00983\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=13 #1 a0=R mix_w=0.0032 mode=chase_robot hypS=(10, 8) hyp_w=0.0107 cost=30.14 score=43.76\n",
      "[PriorCheck][Kept] t=13 #2 a0=R mix_w=0.00145 mode=chase_robot hypS=(9, 8) hyp_w=0.0049 cost=30.69 score=46.61\n",
      "[PriorCheck][Kept] t=13 #3 a0=R mix_w=0.0014 mode=chase_robot hypS=(9, 8) hyp_w=0.0049 cost=31.65 score=47.58\n",
      "[PriorCheck][Kept] t=13 #4 a0=R mix_w=0.00067 mode=chase_robot hypS=(9, 7) hyp_w=0.0023 cost=30.75 score=48.98\n",
      "[PriorCheck][Kept] t=13 #5 a0=R mix_w=0.000654 mode=chase_robot hypS=(8, 8) hyp_w=0.0023 cost=31.38 score=49.61\n",
      "[PriorCheck][Kept] t=13 #6 a0=R mix_w=0.00246 mode=chase_robot hypS=(9, 9) hyp_w=0.0107 cost=36.68 score=50.30\n",
      "[PriorCheck][WARN] t=14 kept=5 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.00746\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=14 #1 a0=R mix_w=0.000959 mode=chase_robot hypS=(7, 8) hyp_w=0.0029 cost=27.36 score=44.92\n",
      "[PriorCheck][Kept] t=14 #2 a0=R mix_w=0.0018 mode=chase_robot hypS=(9, 9) hyp_w=0.0062 cost=30.90 score=46.16\n",
      "[PriorCheck][Kept] t=14 #3 a0=R mix_w=0.00171 mode=chase_robot hypS=(9, 9) hyp_w=0.0062 cost=32.10 score=47.36\n",
      "[PriorCheck][Kept] t=14 #4 a0=R mix_w=0.00164 mode=chase_robot hypS=(9, 9) hyp_w=0.0062 cost=33.19 score=48.45\n",
      "[PriorCheck][Kept] t=14 #5 a0=R mix_w=0.00136 mode=chase_robot hypS=(9, 10) hyp_w=0.0062 cost=37.91 score=53.17\n",
      "================================================================================\n",
      "[TIME] t=15\n",
      "[OBS] obs=(9, 8) (true sensor=(9, 10))\n",
      "[PF] t=15 obs=(9, 8) ESS 184.8->208.3 resample=False | modes: chase_robot:1.000\n",
      "[Modes] t=15 candidates=50 clusters=5 kept=5 | top3: chase_robot:w=0.005,cost=24.7,score=40.4, chase_robot:w=0.005,cost=25.0,score=40.8, chase_robot:w=0.005,cost=25.2,score=41.0\n",
      "[PriorCheck][WARN] t=15 kept=5 distinct_a0=1(R) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=R:1.000 | U:0.000 | D:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[PriorCheck] mix_mass(raw): R:0.00865\n",
      "[PriorCheck] mix_mass(nrm): R:1.000 | U:0.000 | D:0.000 | L:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=15 #1 a0=R mix_w=0.00194 mode=chase_robot hypS=(9, 8) hyp_w=0.0052 cost=24.67 score=40.44\n",
      "[PriorCheck][Kept] t=15 #2 a0=R mix_w=0.00191 mode=chase_robot hypS=(9, 8) hyp_w=0.0052 cost=25.00 score=40.78\n",
      "[PriorCheck][Kept] t=15 #3 a0=R mix_w=0.00189 mode=chase_robot hypS=(9, 8) hyp_w=0.0052 cost=25.24 score=41.02\n",
      "[PriorCheck][Kept] t=15 #4 a0=R mix_w=0.00145 mode=chase_robot hypS=(9, 10) hyp_w=0.0052 cost=31.86 score=47.64\n",
      "[PriorCheck][Kept] t=15 #5 a0=R mix_w=0.00145 mode=chase_robot hypS=(9, 10) hyp_w=0.0052 cost=31.90 score=47.68\n",
      "[PriorDiag] eps=0.15 H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=15 sims=250 depth=10 prior: H=0.533 top=R:0.880 | U:0.030 | D:0.030\n",
      "[MCTS] t=15 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[CHASE] true t=15 src=(9, 10) dst=(11, 15) a=R nxt=(9, 11) d:7->6 best_d=6 best=['D', 'R']\n",
      "[STEP] robot=(11, 15) sensor=(9, 11) aS=R p_det=0.306 detected=False\n",
      "[PF] t=18 obs=(7, 13) ESS 168.9->104.9 resample=True | modes: chase_robot:1.000\n",
      "[PriorCheck][WARN] t=18 kept=2 distinct_a0=1(U) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=U:1.000 | D:0.000 | L:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=U:0.880 | D:0.030 | L:0.030\n",
      "[PriorCheck] mix_mass(raw): U:0.00277\n",
      "[PriorCheck] mix_mass(nrm): U:1.000 | D:0.000 | L:0.000 | R:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=18 #1 a0=U mix_w=0.00143 mode=chase_robot hypS=(9, 11) hyp_w=0.0040 cost=25.77 score=42.34\n",
      "[PriorCheck][Kept] t=18 #2 a0=U mix_w=0.00135 mode=chase_robot hypS=(9, 11) hyp_w=0.0040 cost=27.21 score=43.78\n",
      "[PriorCheck][WARN] t=19 kept=2 distinct_a0=1(U) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=U:1.000 | D:0.000 | L:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=U:0.880 | D:0.030 | L:0.030\n",
      "[PriorCheck] mix_mass(raw): U:0.00152\n",
      "[PriorCheck] mix_mass(nrm): U:1.000 | D:0.000 | L:0.000 | R:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=19 #1 a0=U mix_w=0.000589 mode=chase_robot hypS=(9, 13) hyp_w=0.0023 cost=34.53 score=52.70\n",
      "[PriorCheck][Kept] t=19 #2 a0=U mix_w=0.000932 mode=chase_robot hypS=(9, 14) hyp_w=0.0051 cost=42.27 score=58.13\n",
      "================================================================================\n",
      "[TIME] t=20\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "...............S..\n",
      "..................\n",
      ".................R\n",
      "[OBS] obs=(11, 17) (true sensor=(9, 15))\n",
      "[PF] t=20 obs=(11, 17) ESS 203.7->109.3 resample=True | modes: chase_robot:1.000\n",
      "[Modes] t=20 candidates=50 clusters=2 kept=2 | top3: chase_robot:w=0.004,cost=38.1,score=54.7, chase_robot:w=0.004,cost=40.2,score=56.8\n",
      "[PriorCheck][WARN] t=20 kept=2 distinct_a0=1(U) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=U:1.000 | D:0.000 | L:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=U:0.880 | D:0.030 | L:0.030\n",
      "[PriorCheck] mix_mass(raw): U:0.00167\n",
      "[PriorCheck] mix_mass(nrm): U:1.000 | D:0.000 | L:0.000 | R:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=20 #1 a0=U mix_w=0.000871 mode=chase_robot hypS=(11, 15) hyp_w=0.0040 cost=38.12 score=54.69\n",
      "[PriorCheck][Kept] t=20 #2 a0=U mix_w=0.000801 mode=chase_robot hypS=(11, 15) hyp_w=0.0040 cost=40.19 score=56.75\n",
      "[PriorDiag] eps=0.15 H=0.533 top=U:0.880 | D:0.030 | L:0.030\n",
      "[MCTS] t=20 sims=250 depth=10 prior: H=0.533 top=U:0.880 | D:0.030 | L:0.030\n",
      "[MCTS] t=20 root.N=250 sum(N_a)=250 best_by_N=S\n",
      "[ACT] robot aR=S\n",
      "[CHASE] true t=20 src=(9, 15) dst=(11, 17) a=D nxt=(10, 15) d:4->3 best_d=3 best=['D', 'R']\n",
      "[STEP] robot=(11, 17) sensor=(10, 15) aS=D p_det=0.680 detected=True\n",
      "[PriorCheck][WARN] t=21 kept=2 distinct_a0=1(U) rawH=0.000 rawMax=1.000 | eps=0.15 smH=0.533 smMax=0.880\n",
      "[PriorDiagRaw] H=0.000 top=U:1.000 | D:0.000 | L:0.000\n",
      "[PriorDiagSm]  eps=0.15 H=0.533 top=U:0.880 | D:0.030 | L:0.030\n",
      "[PriorCheck] mix_mass(raw): U:0.00248\n",
      "[PriorCheck] mix_mass(nrm): U:1.000 | D:0.000 | L:0.000 | R:0.000 | S:0.000\n",
      "[PriorCheck][Kept] t=21 #1 a0=U mix_w=0.0013 mode=chase_robot hypS=(11, 15) hyp_w=0.0059 cost=37.68 score=53.08\n",
      "[PriorCheck][Kept] t=21 #2 a0=U mix_w=0.00117 mode=chase_robot hypS=(11, 15) hyp_w=0.0059 cost=40.33 score=55.73\n",
      "[TERMINAL] caught \n",
      "[DONE]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"GenBR-lite + PF Belief + Multimodal Path Library (debug-robust)\n",
    "\n",
    "This version includes the specific fixes suggested from your logs:\n",
    "1) **Chase policy sanity + determinism**:\n",
    "   - Chase now uses a deterministic tie-break (no random sideways moves on ties).\n",
    "   - We print (and warn on) any chase step that *increases* Manhattan distance when a decreasing move exists.\n",
    "\n",
    "2) **Mode-library selection uses plausibility + cost** (not cost-only optimism):\n",
    "   - Each candidate path is scored as:  score = cost + lambda_plaus * (-log(hyp_weight)).\n",
    "   - Best-per-cluster and final sorting use this score.\n",
    "\n",
    "3) **Action prior is a mixture over modes** (not single-best-path):\n",
    "   - Prior weights each kept mode by: hyp_weight * exp(-cost/temp).\n",
    "\n",
    "4) **Detection is actually terminal**:\n",
    "   - If detected and within d0, episode terminates as \"caught\".\n",
    "\n",
    "What to send me to verify correctness:\n",
    "- Run with DebugConfig(level=2, detail_until_t=6, summary_every_t=1, render_every_t=1) for ~10 steps.\n",
    "- Paste the log lines that start with: [CHASE], [CHASE][WARN], [ModesKept], [PriorDiag], [MCTS]\n",
    "\n",
    "Run:\n",
    "  python3 this_file.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import random\n",
    "import heapq\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional, Iterable, Callable, Any, Set\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Debug / Logging utilities\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class DebugConfig:\n",
    "    enabled: bool = True\n",
    "    level: int = 1\n",
    "    # 0 = silent\n",
    "    # 1 = periodic summaries\n",
    "    # 2 = detailed (still gated)\n",
    "\n",
    "    # Print detail for the first few timesteps\n",
    "    detail_until_t: int = 2\n",
    "\n",
    "    # Periodic summary controls\n",
    "    summary_every_t: int = 5\n",
    "    render_every_t: int = 10\n",
    "\n",
    "    # Stage-specific periodic prints\n",
    "    pf_every_t: int = 5\n",
    "    modes_every_t: int = 5\n",
    "    mcts_every_t: int = 5\n",
    "\n",
    "    # Within MCTS\n",
    "    mcts_progress_every_sims: int = 50\n",
    "\n",
    "    # Safety: cap printing of mode hypotheses even at detail level\n",
    "    max_hyp_print: int = 3\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, cfg: DebugConfig):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def _should_print(self, t: Optional[int], every: Optional[int], lvl: int) -> bool:\n",
    "        if not self.cfg.enabled:\n",
    "            return False\n",
    "        if lvl > self.cfg.level:\n",
    "            return False\n",
    "        if t is None:\n",
    "            return True\n",
    "        if t <= self.cfg.detail_until_t:\n",
    "            return True\n",
    "        if every is None:\n",
    "            return False\n",
    "        return (every > 0) and (t % every == 0)\n",
    "\n",
    "    def log(self, msg: str, *, t: Optional[int] = None, every: Optional[int] = None, lvl: int = 1, force: bool = False) -> None:\n",
    "        if force or self._should_print(t, every, lvl):\n",
    "            print(msg)\n",
    "\n",
    "\n",
    "def soft_assert(cond: bool, msg: str, *, fatal: bool = False, log: Optional[Logger] = None, t: Optional[int] = None) -> None:\n",
    "    if cond:\n",
    "        return\n",
    "    if log is not None:\n",
    "        log.log(f\"[WARN] {msg}\", t=t, every=None, lvl=1, force=True)\n",
    "    if fatal:\n",
    "        raise AssertionError(msg)\n",
    "\n",
    "\n",
    "def clamp(x: float, lo: float, hi: float) -> float:\n",
    "    return max(lo, min(hi, x))\n",
    "\n",
    "\n",
    "def manhattan(a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "\n",
    "def seed_all(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "def stable_bucket(sig: str, m: int) -> int:\n",
    "    \"\"\"Stable mapping sig -> [0..m-1] independent of Python's randomized hash.\"\"\"\n",
    "    if m <= 0:\n",
    "        return 0\n",
    "    h = hashlib.md5(sig.encode(\"utf-8\")).hexdigest()\n",
    "    return int(h[:8], 16) % m\n",
    "\n",
    "\n",
    "def normalize_probs_dict(d: Dict[Any, float], keys: Iterable[Any], *, eps: float = 0.0) -> Dict[Any, float]:\n",
    "    \"\"\"Return a normalized distribution over `keys` from possibly-missing/negative inputs.\n",
    "\n",
    "    - Clips negatives to 0\n",
    "    - Adds optional epsilon smoothing to avoid degeneracy\n",
    "    - Falls back to uniform if total mass is 0\n",
    "    \"\"\"\n",
    "    klist = list(keys)\n",
    "    out = {k: max(0.0, float(d.get(k, 0.0))) for k in klist}\n",
    "    s = sum(out.values())\n",
    "\n",
    "    if s <= 0.0:\n",
    "        u = 1.0 / max(1, len(klist))\n",
    "        return {k: u for k in klist}\n",
    "\n",
    "    out = {k: v / s for k, v in out.items()}\n",
    "\n",
    "    if eps > 0.0:\n",
    "        u = 1.0 / max(1, len(klist))\n",
    "        out = {k: (1.0 - eps) * out[k] + eps * u for k in klist}\n",
    "        s2 = sum(out.values())\n",
    "        out = {k: v / s2 for k, v in out.items()}\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def topk_str(d: Dict[Any, float], k: int = 3, fmt: str = \"{k}:{v:.3f}\") -> str:\n",
    "    items = sorted(d.items(), key=lambda kv: kv[1], reverse=True)[:k]\n",
    "    return \" | \".join(fmt.format(k=kk, v=vv) for kk, vv in items)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Gridworld Environment\n",
    "# =========================\n",
    "\n",
    "Action = str  # 'U','D','L','R','S'\n",
    "\n",
    "ACTIONS: List[Action] = [\"U\", \"D\", \"L\", \"R\", \"S\"]\n",
    "ACTION_DELTAS: Dict[Action, Tuple[int, int]] = {\n",
    "    \"U\": (-1, 0),\n",
    "    \"D\": (1, 0),\n",
    "    \"L\": (0, -1),\n",
    "    \"R\": (0, 1),\n",
    "    \"S\": (0, 0),\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GridWorld:\n",
    "    H: int\n",
    "    W: int\n",
    "    obstacles: Set[Tuple[int, int]] = field(default_factory=set)\n",
    "\n",
    "    def in_bounds(self, p: Tuple[int, int]) -> bool:\n",
    "        r, c = p\n",
    "        return 0 <= r < self.H and 0 <= c < self.W\n",
    "\n",
    "    def is_free(self, p: Tuple[int, int]) -> bool:\n",
    "        return self.in_bounds(p) and (p not in self.obstacles)\n",
    "\n",
    "    def step(self, p: Tuple[int, int], a: Action) -> Tuple[int, int]:\n",
    "        if a not in ACTION_DELTAS:\n",
    "            raise ValueError(f\"Unknown action: {a}\")\n",
    "        dr, dc = ACTION_DELTAS[a]\n",
    "        np = (p[0] + dr, p[1] + dc)\n",
    "        return np if self.is_free(np) else p\n",
    "\n",
    "    def neighbors(self, p: Tuple[int, int]) -> List[Tuple[Tuple[int, int], Action]]:\n",
    "        return [(self.step(p, a), a) for a in ACTIONS]\n",
    "\n",
    "    def render(self, robot: Tuple[int, int], sensor: Tuple[int, int], goal: Tuple[int, int]) -> None:\n",
    "        grid = [[\".\" for _ in range(self.W)] for _ in range(self.H)]\n",
    "        for (r, c) in self.obstacles:\n",
    "            grid[r][c] = \"#\"\n",
    "        rr, rc = robot\n",
    "        sr, sc = sensor\n",
    "        gr, gc = goal\n",
    "        grid[gr][gc] = \"G\"\n",
    "        grid[sr][sc] = \"S\"\n",
    "        grid[rr][rc] = \"R\"\n",
    "        for r in range(self.H):\n",
    "            print(\"\".join(grid[r]))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Sensor Models (Modes)\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class SensorModePolicy:\n",
    "    name: str\n",
    "\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def best_actions_toward(world: GridWorld, src: Tuple[int, int], dst: Tuple[int, int]) -> Tuple[List[Action], int]:\n",
    "    \"\"\"Return (best_actions, best_dist) minimizing manhattan(next(src,a), dst).\"\"\"\n",
    "    best_actions: List[Action] = []\n",
    "    best_dist = 10**9\n",
    "    for a in ACTIONS:\n",
    "        np = world.step(src, a)\n",
    "        d = manhattan(np, dst)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_actions = [a]\n",
    "        elif d == best_dist:\n",
    "            best_actions.append(a)\n",
    "    return best_actions, best_dist\n",
    "\n",
    "\n",
    "def deterministic_greedy_step_toward(world: GridWorld, src: Tuple[int, int], dst: Tuple[int, int]) -> Action:\n",
    "    \"\"\"Greedy toward dst with deterministic tie-break (easier to debug than random ties).\"\"\"\n",
    "    best_as, _ = best_actions_toward(world, src, dst)\n",
    "    if not best_as:\n",
    "        return \"S\"\n",
    "\n",
    "    # Preferred axis: move along the larger |delta| if possible\n",
    "    dr = dst[0] - src[0]\n",
    "    dc = dst[1] - src[1]\n",
    "\n",
    "    preferred: List[Action] = []\n",
    "    if abs(dr) >= abs(dc):\n",
    "        if dr > 0:\n",
    "            preferred.append(\"D\")\n",
    "        elif dr < 0:\n",
    "            preferred.append(\"U\")\n",
    "    if abs(dc) > abs(dr):\n",
    "        if dc > 0:\n",
    "            preferred.append(\"R\")\n",
    "        elif dc < 0:\n",
    "            preferred.append(\"L\")\n",
    "\n",
    "    # If the preferred move is among best actions, take it\n",
    "    for a in preferred:\n",
    "        if a in best_as:\n",
    "            return a\n",
    "\n",
    "    # Otherwise deterministic order\n",
    "    for a in [\"U\", \"D\", \"L\", \"R\", \"S\"]:\n",
    "        if a in best_as:\n",
    "            return a\n",
    "\n",
    "    return best_as[0]\n",
    "\n",
    "\n",
    "def chase_sanity_check(\n",
    "    world: GridWorld,\n",
    "    src: Tuple[int, int],\n",
    "    dst: Tuple[int, int],\n",
    "    chosen: Action,\n",
    "    *,\n",
    "    log: Optional[Logger],\n",
    "    t: int,\n",
    "    tag: str,\n",
    ") -> None:\n",
    "    \"\"\"Warn if chosen action increases distance when a non-increasing action exists.\"\"\"\n",
    "    d0 = manhattan(src, dst)\n",
    "    nxt = world.step(src, chosen)\n",
    "    d1 = manhattan(nxt, dst)\n",
    "\n",
    "    best_as, best_d = best_actions_toward(world, src, dst)\n",
    "\n",
    "    if log is not None and log.cfg.enabled and (t <= log.cfg.detail_until_t or (log.cfg.summary_every_t > 0 and t % log.cfg.summary_every_t == 0)):\n",
    "        log.log(\n",
    "            f\"[CHASE] {tag} t={t} src={src} dst={dst} a={chosen} nxt={nxt} d:{d0}->{d1} best_d={best_d} best={best_as}\",\n",
    "            t=t,\n",
    "            every=log.cfg.summary_every_t,\n",
    "            lvl=1,\n",
    "        )\n",
    "\n",
    "    # If chosen isn't among best actions, it's suspicious\n",
    "    if chosen not in best_as:\n",
    "        if log is not None:\n",
    "            log.log(\n",
    "                f\"[CHASE][WARN] {tag} t={t} chose {chosen} but best={best_as} (d:{d0}->{d1}, best_d={best_d})\",\n",
    "                t=t,\n",
    "                every=None,\n",
    "                lvl=1,\n",
    "                force=True,\n",
    "            )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PatrolLoopPolicy(SensorModePolicy):\n",
    "    loop: List[Tuple[int, int]] = field(default_factory=list)\n",
    "\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        if not self.loop:\n",
    "            return \"S\"\n",
    "        idx = t % len(self.loop)\n",
    "        return deterministic_greedy_step_toward(world, sensor_pos, self.loop[idx])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ChasePolicy(SensorModePolicy):\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        return deterministic_greedy_step_toward(world, sensor_pos, robot_pos)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RandomWalkPolicy(SensorModePolicy):\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        return random.choice(ACTIONS)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Detection / Observation\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class DetectionModel:\n",
    "    d0: int = 2\n",
    "    p_close: float = 0.9\n",
    "    p_far: float = 0.05\n",
    "    decay: float = 0.3\n",
    "\n",
    "    def p_detect(self, robot_pos: Tuple[int, int], sensor_pos: Tuple[int, int]) -> float:\n",
    "        dist = manhattan(robot_pos, sensor_pos)\n",
    "        if dist <= self.d0:\n",
    "            return self.p_close\n",
    "        return self.p_far + (self.p_close - self.p_far) * math.exp(-self.decay * (dist - self.d0))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ObservationModel:\n",
    "    sigma: float = 1.2\n",
    "\n",
    "    def sample_observation(self, sensor_pos: Tuple[int, int], world: GridWorld) -> Tuple[int, int]:\n",
    "        max_jump = 2\n",
    "        dr = random.randint(-max_jump, max_jump)\n",
    "        dc = random.randint(-max_jump, max_jump)\n",
    "        o = (sensor_pos[0] + dr, sensor_pos[1] + dc)\n",
    "        o = (int(clamp(o[0], 0, world.H - 1)), int(clamp(o[1], 0, world.W - 1)))\n",
    "        return o\n",
    "\n",
    "    def likelihood(self, obs: Tuple[int, int], sensor_pos: Tuple[int, int]) -> float:\n",
    "        d = manhattan(obs, sensor_pos)\n",
    "        return max(1e-12, math.exp(-d / max(1e-6, self.sigma)))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Particle Filter over (sensor_pos, mode)\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class Particle:\n",
    "    sensor_pos: Tuple[int, int]\n",
    "    mode_idx: int\n",
    "    weight: float = 1.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BeliefState:\n",
    "    particles: List[Particle]\n",
    "    mode_names: List[str]\n",
    "\n",
    "    def normalize(self) -> None:\n",
    "        s = sum(p.weight for p in self.particles)\n",
    "        if s <= 0.0:\n",
    "            w = 1.0 / max(1, len(self.particles))\n",
    "            for p in self.particles:\n",
    "                p.weight = w\n",
    "            return\n",
    "        for p in self.particles:\n",
    "            p.weight /= s\n",
    "\n",
    "    def effective_sample_size(self) -> float:\n",
    "        s = sum(p.weight * p.weight for p in self.particles)\n",
    "        return 0.0 if s <= 0.0 else 1.0 / s\n",
    "\n",
    "    def mode_posterior(self) -> Dict[int, float]:\n",
    "        post: Dict[int, float] = defaultdict(float)\n",
    "        for p in self.particles:\n",
    "            post[p.mode_idx] += p.weight\n",
    "        return dict(post)\n",
    "\n",
    "    def mode_posterior_named(self) -> Dict[str, float]:\n",
    "        post_i = self.mode_posterior()\n",
    "        out: Dict[str, float] = {}\n",
    "        for i, v in post_i.items():\n",
    "            name = self.mode_names[i] if 0 <= i < len(self.mode_names) else f\"mode{i}\"\n",
    "            out[name] = out.get(name, 0.0) + v\n",
    "        return out\n",
    "\n",
    "\n",
    "def systematic_resample(particles: List[Particle]) -> List[Particle]:\n",
    "    n = len(particles)\n",
    "    if n == 0:\n",
    "        return []\n",
    "    positions = [(random.random() + i) / n for i in range(n)]\n",
    "    cumulative = []\n",
    "    csum = 0.0\n",
    "    for p in particles:\n",
    "        csum += p.weight\n",
    "        cumulative.append(csum)\n",
    "\n",
    "    out: List[Particle] = []\n",
    "    i = 0\n",
    "    for pos in positions:\n",
    "        while i < n - 1 and pos > cumulative[i]:\n",
    "            i += 1\n",
    "        chosen = particles[i]\n",
    "        out.append(Particle(sensor_pos=chosen.sensor_pos, mode_idx=chosen.mode_idx, weight=1.0 / n))\n",
    "    return out\n",
    "\n",
    "\n",
    "def initialize_belief(\n",
    "    world: GridWorld,\n",
    "    sensor_init_candidates: List[Tuple[int, int]],\n",
    "    mode_prior: List[float],\n",
    "    mode_names: List[str],\n",
    "    num_particles: int = 200,\n",
    ") -> BeliefState:\n",
    "    if len(mode_prior) != len(mode_names):\n",
    "        raise ValueError(\"mode_prior and mode_names must have same length\")\n",
    "    if not sensor_init_candidates:\n",
    "        raise ValueError(\"Need at least one sensor init candidate\")\n",
    "    if num_particles <= 0:\n",
    "        raise ValueError(\"num_particles must be > 0\")\n",
    "\n",
    "    # normalize prior\n",
    "    s = sum(mode_prior)\n",
    "    if s <= 0.0:\n",
    "        mode_prior = [1.0 / len(mode_prior)] * len(mode_prior)\n",
    "    else:\n",
    "        mode_prior = [p / s for p in mode_prior]\n",
    "\n",
    "    def sample_mode() -> int:\n",
    "        r = random.random()\n",
    "        c = 0.0\n",
    "        for i, p in enumerate(mode_prior):\n",
    "            c += p\n",
    "            if r <= c:\n",
    "                return i\n",
    "        return len(mode_prior) - 1\n",
    "\n",
    "    particles: List[Particle] = []\n",
    "    for _ in range(num_particles):\n",
    "        sp = random.choice(sensor_init_candidates)\n",
    "        z = sample_mode()\n",
    "        particles.append(Particle(sensor_pos=sp, mode_idx=z, weight=1.0 / num_particles))\n",
    "\n",
    "    b = BeliefState(particles=particles, mode_names=mode_names)\n",
    "    b.normalize()\n",
    "    return b\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PFStepInfo:\n",
    "    ess_before: float\n",
    "    ess_after: float\n",
    "    resampled: bool\n",
    "\n",
    "\n",
    "def belief_predict_update(\n",
    "    belief: BeliefState,\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    sensor_policies: List[SensorModePolicy],\n",
    "    obs_model: ObservationModel,\n",
    "    obs: Tuple[int, int],\n",
    "    t: int,\n",
    "    *,\n",
    "    motion_noise: float = 0.10,\n",
    "    resample_threshold: float = 0.5,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> PFStepInfo:\n",
    "    if not belief.particles:\n",
    "        raise ValueError(\"belief has no particles\")\n",
    "\n",
    "    belief.normalize()\n",
    "    ess0 = belief.effective_sample_size()\n",
    "\n",
    "    # Predict + weight update\n",
    "    for p in belief.particles:\n",
    "        mi = p.mode_idx\n",
    "        if 0 <= mi < len(sensor_policies):\n",
    "            aS = sensor_policies[mi].action(world, p.sensor_pos, robot_pos, t)\n",
    "        else:\n",
    "            aS = \"S\"\n",
    "\n",
    "        predicted = world.step(p.sensor_pos, aS)\n",
    "        if random.random() < motion_noise:\n",
    "            predicted = world.step(predicted, random.choice(ACTIONS))\n",
    "\n",
    "        p.sensor_pos = predicted\n",
    "        p.weight *= obs_model.likelihood(obs, p.sensor_pos)\n",
    "\n",
    "    belief.normalize()\n",
    "    ess1 = belief.effective_sample_size()\n",
    "\n",
    "    # Sanity checks\n",
    "    N = len(belief.particles)\n",
    "    soft_assert(0.0 <= ess1 <= N + 1e-6, f\"ESS out of bounds: {ess1} (N={N})\", log=log, t=t)\n",
    "\n",
    "    resampled = False\n",
    "    if ess1 < resample_threshold * N:\n",
    "        belief.particles = systematic_resample(belief.particles)\n",
    "        belief.normalize()\n",
    "        resampled = True\n",
    "\n",
    "    # Controlled prints\n",
    "    if log is not None:\n",
    "        if log._should_print(t, log.cfg.pf_every_t, lvl=1) or resampled:\n",
    "            mp = belief.mode_posterior_named()\n",
    "            log.log(\n",
    "                f\"[PF] t={t} obs={obs} ESS {ess0:.1f}->{ess1:.1f} resample={resampled} | modes: {topk_str(mp, k=3)}\",\n",
    "                t=t,\n",
    "                every=log.cfg.pf_every_t,\n",
    "                lvl=1,\n",
    "                force=resampled,\n",
    "            )\n",
    "            if log.cfg.level >= 2 and t <= log.cfg.detail_until_t:\n",
    "                log.log(f\"[PF][detail] full mode posterior: {topk_str(mp, k=10)}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    return PFStepInfo(ess_before=ess0, ess_after=ess1, resampled=resampled)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# A* Search with Risk Costs\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class AStarResult:\n",
    "    path: List[Tuple[int, int]]\n",
    "    cost: float\n",
    "    expanded: int\n",
    "\n",
    "\n",
    "def astar_path(\n",
    "    world: GridWorld,\n",
    "    start: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    step_cost: Callable[[Tuple[int, int]], float],\n",
    "    heuristic: Callable[[Tuple[int, int]], float],\n",
    "    *,\n",
    "    max_expansions: int = 50_000,\n",
    ") -> Optional[AStarResult]:\n",
    "    if not world.is_free(start) or not world.is_free(goal):\n",
    "        return None\n",
    "\n",
    "    frontier: List[Tuple[float, float, Tuple[int, int]]] = []\n",
    "    heapq.heappush(frontier, (heuristic(start), 0.0, start))\n",
    "\n",
    "    came_from: Dict[Tuple[int, int], Tuple[int, int]] = {}\n",
    "    gscore: Dict[Tuple[int, int], float] = {start: 0.0}\n",
    "\n",
    "    expanded = 0\n",
    "\n",
    "    # A* with reopen: skip stale pops\n",
    "    while frontier and expanded < max_expansions:\n",
    "        f, g, cur = heapq.heappop(frontier)\n",
    "        if g > gscore.get(cur, float(\"inf\")) + 1e-12:\n",
    "            continue\n",
    "        expanded += 1\n",
    "\n",
    "        if cur == goal:\n",
    "            path = [cur]\n",
    "            while cur in came_from:\n",
    "                cur = came_from[cur]\n",
    "                path.append(cur)\n",
    "            path.reverse()\n",
    "            return AStarResult(path=path, cost=gscore[goal], expanded=expanded)\n",
    "\n",
    "        for (nxt, _) in world.neighbors(cur):\n",
    "            if not world.is_free(nxt):\n",
    "                continue\n",
    "            sc = step_cost(nxt)\n",
    "            if not math.isfinite(sc) or sc < 0:\n",
    "                continue\n",
    "            ng = gscore[cur] + sc\n",
    "            if ng + 1e-12 < gscore.get(nxt, float(\"inf\")):\n",
    "                gscore[nxt] = ng\n",
    "                came_from[nxt] = cur\n",
    "                heapq.heappush(frontier, (ng + heuristic(nxt), ng, nxt))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Multimodal Path Library\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class PathMode:\n",
    "    path: List[Tuple[int, int]]\n",
    "    total_cost: float\n",
    "    score: float\n",
    "    hypothesis_sensor_pos: Tuple[int, int]\n",
    "    hypothesis_mode_idx: int\n",
    "    hypothesis_weight: float\n",
    "    debug_info: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def build_cost_map_from_hypothesis(\n",
    "    world: GridWorld,\n",
    "    detection: \"DetectionModel\",\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    *,\n",
    "    base_step: float,\n",
    "    w_detect: float,\n",
    "    randomize: bool,\n",
    "    rand_scale: float,\n",
    ") -> Callable[[Tuple[int, int]], float]:\n",
    "    def cost_fn(s: Tuple[int, int]) -> float:\n",
    "        if not world.is_free(s):\n",
    "            return float(\"inf\")\n",
    "        p_det = detection.p_detect(robot_pos=s, sensor_pos=sensor_pos)\n",
    "        c = base_step + w_detect * p_det\n",
    "        if randomize:\n",
    "            c *= (1.0 + rand_scale * (random.random() - 0.5))\n",
    "            c = max(1e-6, c)\n",
    "        return c\n",
    "\n",
    "    return cost_fn\n",
    "\n",
    "\n",
    "def cluster_paths_by_signature(paths: List[List[Tuple[int, int]]], *, max_modes: int) -> List[int]:\n",
    "    sig_to_cluster: Dict[str, int] = {}\n",
    "    assignments: List[int] = []\n",
    "\n",
    "    def signature(path: List[Tuple[int, int]]) -> str:\n",
    "        if len(path) < 2:\n",
    "            return \"EMPTY\"\n",
    "        dirs = []\n",
    "        for i in range(1, len(path)):\n",
    "            dr = path[i][0] - path[i - 1][0]\n",
    "            dc = path[i][1] - path[i - 1][1]\n",
    "            dirs.append((dr, dc))\n",
    "\n",
    "        comp = []\n",
    "        for d in dirs:\n",
    "            if not comp or comp[-1] != d:\n",
    "                comp.append(d)\n",
    "\n",
    "        m = {(-1, 0): \"U\", (1, 0): \"D\", (0, -1): \"L\", (0, 1): \"R\", (0, 0): \"S\"}\n",
    "        return \"\".join(m.get(d, \"?\") for d in comp)[:120]\n",
    "\n",
    "    for p in paths:\n",
    "        sig = signature(p)\n",
    "\n",
    "        if sig in sig_to_cluster:\n",
    "            cid = sig_to_cluster[sig]\n",
    "        elif len(sig_to_cluster) < max_modes:\n",
    "            cid = len(sig_to_cluster)\n",
    "            sig_to_cluster[sig] = cid\n",
    "        else:\n",
    "            cid = stable_bucket(sig, len(sig_to_cluster))\n",
    "\n",
    "        assignments.append(cid)\n",
    "\n",
    "    return assignments\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModeLibraryInfo:\n",
    "    num_candidates: int\n",
    "    num_clusters: int\n",
    "\n",
    "\n",
    "def unique_weighted_sample(particles: List[Particle], weights: List[float], k: int) -> List[Particle]:\n",
    "    \"\"\"Approximate weighted sampling without replacement by oversampling then uniquing.\"\"\"\n",
    "    if not particles:\n",
    "        return []\n",
    "    if k <= 0:\n",
    "        return []\n",
    "    oversample = max(k, 3 * k)\n",
    "    picks = random.choices(particles, weights=weights, k=oversample)\n",
    "    seen = set()\n",
    "    out: List[Particle] = []\n",
    "    for p in picks:\n",
    "        key = (p.sensor_pos, p.mode_idx)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append(p)\n",
    "        if len(out) >= k:\n",
    "            break\n",
    "    # If we still don't have k, allow duplicates as a fallback\n",
    "    while len(out) < k:\n",
    "        out.append(random.choices(particles, weights=weights, k=1)[0])\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_multimodal_path_library(\n",
    "    world: GridWorld,\n",
    "    belief: BeliefState,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    detection: DetectionModel,\n",
    "    *,\n",
    "    num_hypotheses: int = 30,\n",
    "    per_hypothesis_attempts: int = 2,\n",
    "    base_step_cost: float = 1.0,\n",
    "    w_detect: float = 8.0,\n",
    "    rand_scale: float = 0.40,\n",
    "    max_modes: int = 6,\n",
    "    plausibility_lambda: float = 3.0,\n",
    "    t: int = 0,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> Tuple[List[PathMode], ModeLibraryInfo]:\n",
    "    if not belief.particles:\n",
    "        return [], ModeLibraryInfo(num_candidates=0, num_clusters=0)\n",
    "\n",
    "    # Sample particles proportional to weight\n",
    "    weights = [p.weight for p in belief.particles]\n",
    "    s = sum(weights)\n",
    "    if s <= 0.0:\n",
    "        weights = [1.0 / len(weights)] * len(weights)\n",
    "    else:\n",
    "        weights = [w / s for w in weights]\n",
    "\n",
    "    # NEW: more diverse sampling\n",
    "    sampled_particles = unique_weighted_sample(belief.particles, weights, k=num_hypotheses)\n",
    "\n",
    "    candidates: List[PathMode] = []\n",
    "\n",
    "    hyp_print_budget = log.cfg.max_hyp_print if (log and log.cfg.level >= 2 and t <= log.cfg.detail_until_t) else 0\n",
    "\n",
    "    for hi, hp in enumerate(sampled_particles):\n",
    "        hyp_sensor = hp.sensor_pos\n",
    "        hyp_mode = hp.mode_idx\n",
    "        hyp_w = float(getattr(hp, \"weight\", 0.0))\n",
    "\n",
    "        if log is not None and hyp_print_budget > 0:\n",
    "            log.log(\n",
    "                f\"[Modes][detail] t={t} hyp#{hi+1}/{num_hypotheses} sensor={hyp_sensor} mode={belief.mode_names[hyp_mode] if 0<=hyp_mode<len(belief.mode_names) else hyp_mode} w={hyp_w:.4f}\",\n",
    "                t=t,\n",
    "                every=None,\n",
    "                lvl=2,\n",
    "            )\n",
    "            hyp_print_budget -= 1\n",
    "\n",
    "        for attempt in range(per_hypothesis_attempts):\n",
    "            cost_fn = build_cost_map_from_hypothesis(\n",
    "                world,\n",
    "                detection,\n",
    "                hyp_sensor,\n",
    "                base_step=base_step_cost,\n",
    "                w_detect=w_detect,\n",
    "                randomize=True,\n",
    "                rand_scale=rand_scale,\n",
    "            )\n",
    "            heur = lambda s: float(manhattan(s, goal))\n",
    "\n",
    "            res = astar_path(world, robot_pos, goal, step_cost=cost_fn, heuristic=heur)\n",
    "            if res is None:\n",
    "                continue\n",
    "\n",
    "            # NEW: plausibility-regularized score\n",
    "            score = float(res.cost) + plausibility_lambda * (-math.log(max(1e-12, hyp_w)))\n",
    "\n",
    "            candidates.append(\n",
    "                PathMode(\n",
    "                    path=res.path,\n",
    "                    total_cost=float(res.cost),\n",
    "                    score=score,\n",
    "                    hypothesis_sensor_pos=hyp_sensor,\n",
    "                    hypothesis_mode_idx=hyp_mode,\n",
    "                    hypothesis_weight=hyp_w,\n",
    "                    debug_info={\"expanded\": res.expanded, \"attempt\": attempt + 1},\n",
    "                )\n",
    "            )\n",
    "\n",
    "    if not candidates:\n",
    "        if log is not None and log._should_print(t, log.cfg.modes_every_t, lvl=1):\n",
    "            log.log(f\"[Modes] t={t} candidates=0 (no paths found)\", t=t, every=log.cfg.modes_every_t, lvl=1)\n",
    "        return [], ModeLibraryInfo(num_candidates=0, num_clusters=0)\n",
    "\n",
    "    cluster_ids = cluster_paths_by_signature([c.path for c in candidates], max_modes=max_modes)\n",
    "\n",
    "    # NEW: pick best by *score* per cluster\n",
    "    best_by_cluster: Dict[int, PathMode] = {}\n",
    "    for c, cid in zip(candidates, cluster_ids):\n",
    "        if cid not in best_by_cluster or c.score < best_by_cluster[cid].score:\n",
    "            best_by_cluster[cid] = c\n",
    "\n",
    "    # NEW: sort by score, not raw cost\n",
    "    library = sorted(best_by_cluster.values(), key=lambda pm: pm.score)[:max_modes]\n",
    "\n",
    "    if log is not None and log._should_print(t, log.cfg.modes_every_t, lvl=1):\n",
    "        best = \", \".join(\n",
    "            f\"{belief.mode_names[pm.hypothesis_mode_idx] if 0<=pm.hypothesis_mode_idx<len(belief.mode_names) else pm.hypothesis_mode_idx}:\"\n",
    "            f\"w={pm.hypothesis_weight:.3f},cost={pm.total_cost:.1f},score={pm.score:.1f}\"\n",
    "            for pm in library[:min(3, len(library))]\n",
    "        )\n",
    "        log.log(\n",
    "            f\"[Modes] t={t} candidates={len(candidates)} clusters={len(best_by_cluster)} kept={len(library)} | top3: {best}\",\n",
    "            t=t,\n",
    "            every=log.cfg.modes_every_t,\n",
    "            lvl=1,\n",
    "        )\n",
    "\n",
    "        if log.cfg.level >= 2 and t <= log.cfg.detail_until_t:\n",
    "            for i, pm in enumerate(library):\n",
    "                a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "                mname = belief.mode_names[pm.hypothesis_mode_idx] if 0 <= pm.hypothesis_mode_idx < len(belief.mode_names) else str(pm.hypothesis_mode_idx)\n",
    "                log.log(\n",
    "                    f\"[ModesKept] t={t} #{i+1} mode={mname} hypS={pm.hypothesis_sensor_pos} a0={a0} w={pm.hypothesis_weight:.4f} cost={pm.total_cost:.2f} score={pm.score:.2f}\",\n",
    "                    t=t,\n",
    "                    every=None,\n",
    "                    lvl=2,\n",
    "                )\n",
    "\n",
    "    return library, ModeLibraryInfo(num_candidates=len(candidates), num_clusters=len(best_by_cluster))\n",
    "\n",
    "\n",
    "def first_action_from_path(world: GridWorld, start: Tuple[int, int], path: List[Tuple[int, int]]) -> Action:\n",
    "    if len(path) < 2:\n",
    "        return \"S\"\n",
    "    nxt = path[1]\n",
    "    dr = nxt[0] - start[0]\n",
    "    dc = nxt[1] - start[1]\n",
    "    for a, (adr, adc) in ACTION_DELTAS.items():\n",
    "        if (dr, dc) == (adr, adc):\n",
    "            return a\n",
    "    return \"S\"\n",
    "\n",
    "\n",
    "def build_action_prior_from_library(\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    library: List[PathMode],\n",
    "    *,\n",
    "    temp: float = 25.0,\n",
    ") -> Dict[Action, float]:\n",
    "    \"\"\"Mixture prior over kept modes: weight = hyp_weight * exp(-cost/temp).\"\"\"\n",
    "    if not library:\n",
    "        return {a: 1.0 / len(ACTIONS) for a in ACTIONS}\n",
    "\n",
    "    pri_raw: Dict[Action, float] = defaultdict(float)\n",
    "    for pm in library:\n",
    "        a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "        w = max(1e-12, pm.hypothesis_weight)\n",
    "        w *= math.exp(-pm.total_cost / max(1e-6, temp))\n",
    "        pri_raw[a0] += w\n",
    "\n",
    "    return normalize_probs_dict(pri_raw, ACTIONS)\n",
    "\n",
    "\n",
    "def prior_entropy(prior: Dict[Action, float]) -> float:\n",
    "    ent = 0.0\n",
    "    for a in ACTIONS:\n",
    "        p = float(prior.get(a, 0.0))\n",
    "        if p > 1e-12:\n",
    "            ent -= p * math.log(p)\n",
    "    return ent\n",
    "\n",
    "\n",
    "def prior_diagnostics(prior: Dict[Action, float]) -> str:\n",
    "    ent = prior_entropy(prior)\n",
    "    return f\"H={ent:.3f} top={topk_str(prior, k=3)}\"\n",
    "\n",
    "\n",
    "def prior_check_and_log(\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    library: List[PathMode],\n",
    "    raw_prior: Dict[Action, float],\n",
    "    smoothed_prior: Dict[Action, float],\n",
    "    *,\n",
    "    temp: float,\n",
    "    eps: float,\n",
    "    mode_names: List[str],\n",
    "    warn_maxp: float,\n",
    "    warn_minH: float,\n",
    "    t: int,\n",
    "    log: Optional[Logger],\n",
    ") -> None:\n",
    "    \"\"\"Warn when the library induces a near-delta prior.\n",
    "\n",
    "    When it triggers, we print *why* (first-action mass + kept-mode breakdown), so you can\n",
    "    tell whether it's a real collapse or just a legitimately one-sided situation.\n",
    "    \"\"\"\n",
    "    if log is None or not log.cfg.enabled:\n",
    "        return\n",
    "    if not library:\n",
    "        return\n",
    "\n",
    "    kept_a0: List[Action] = [first_action_from_path(world, robot_pos, pm.path) for pm in library]\n",
    "    distinct_a0 = sorted(set(kept_a0))\n",
    "\n",
    "    rawH = prior_entropy(raw_prior)\n",
    "    rawMax = max(float(raw_prior.get(a, 0.0)) for a in ACTIONS)\n",
    "    smH = prior_entropy(smoothed_prior)\n",
    "    smMax = max(float(smoothed_prior.get(a, 0.0)) for a in ACTIONS)\n",
    "\n",
    "    warn = False\n",
    "    if len(library) >= 2 and len(distinct_a0) <= 1:\n",
    "        warn = True\n",
    "    if rawMax >= warn_maxp:\n",
    "        warn = True\n",
    "    if rawH <= warn_minH:\n",
    "        warn = True\n",
    "\n",
    "    if not warn:\n",
    "        return\n",
    "\n",
    "    log.log(\n",
    "        f\"[PriorCheck][WARN] t={t} kept={len(library)} distinct_a0={len(distinct_a0)}({','.join(distinct_a0) if distinct_a0 else '-'}) \"\n",
    "        f\"rawH={rawH:.3f} rawMax={rawMax:.3f} | eps={eps:.2f} smH={smH:.3f} smMax={smMax:.3f}\",\n",
    "        t=t,\n",
    "        every=None,\n",
    "        lvl=1,\n",
    "        force=True,\n",
    "    )\n",
    "    log.log(f\"[PriorDiagRaw] {prior_diagnostics(raw_prior)}\", t=t, every=None, lvl=1, force=True)\n",
    "    log.log(f\"[PriorDiagSm]  eps={eps:.2f} {prior_diagnostics(smoothed_prior)}\", t=t, every=None, lvl=1, force=True)\n",
    "\n",
    "    mix_by_a: Dict[Action, float] = defaultdict(float)\n",
    "    for pm in library:\n",
    "        a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "        mix_w = max(1e-12, pm.hypothesis_weight) * math.exp(-pm.total_cost / max(1e-6, temp))\n",
    "        mix_by_a[a0] += mix_w\n",
    "\n",
    "    mix_norm = normalize_probs_dict(mix_by_a, ACTIONS)\n",
    "    log.log(f\"[PriorCheck] mix_mass(raw): {topk_str(mix_by_a, k=5, fmt='{k}:{v:.3g}')}\", t=t, every=None, lvl=1, force=True)\n",
    "    log.log(f\"[PriorCheck] mix_mass(nrm): {topk_str(mix_norm, k=5)}\", t=t, every=None, lvl=1, force=True)\n",
    "\n",
    "    for i, pm in enumerate(library, start=1):\n",
    "        a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "        mname = mode_names[pm.hypothesis_mode_idx] if 0 <= pm.hypothesis_mode_idx < len(mode_names) else str(pm.hypothesis_mode_idx)\n",
    "        mix_w = max(1e-12, pm.hypothesis_weight) * math.exp(-pm.total_cost / max(1e-6, temp))\n",
    "        log.log(\n",
    "            f\"[PriorCheck][Kept] t={t} #{i} a0={a0} mix_w={mix_w:.3g} mode={mname} hypS={pm.hypothesis_sensor_pos} \"\n",
    "            f\"hyp_w={pm.hypothesis_weight:.4f} cost={pm.total_cost:.2f} score={pm.score:.2f}\",\n",
    "            t=t,\n",
    "            every=None,\n",
    "            lvl=1,\n",
    "            force=True,\n",
    "        )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# GenBR-lite: Belief-space MCTS with PUCT\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class MCTSNode:\n",
    "    robot_pos: Tuple[int, int]\n",
    "    depth: int\n",
    "\n",
    "    N: int = 0\n",
    "    N_a: Dict[Action, int] = field(default_factory=lambda: {a: 0 for a in ACTIONS})\n",
    "    W_a: Dict[Action, float] = field(default_factory=lambda: {a: 0.0 for a in ACTIONS})\n",
    "    Q_a: Dict[Action, float] = field(default_factory=lambda: {a: 0.0 for a in ACTIONS})\n",
    "\n",
    "    P_a: Dict[Action, float] = field(default_factory=lambda: {a: 1.0 / len(ACTIONS) for a in ACTIONS})\n",
    "\n",
    "    children: Dict[Action, \"MCTSNode\"] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def select_action_puct(node: MCTSNode, *, c_puct: float) -> Action:\n",
    "    \"\"\"PUCT: argmax_a Q + c*P*sqrt(N)/(1+N_a). Uses node.P_a.\"\"\"\n",
    "    sqrtN = math.sqrt(max(1, node.N))\n",
    "\n",
    "    best_a: Optional[Action] = None\n",
    "    best_score = -1e18\n",
    "\n",
    "    for a in ACTIONS:\n",
    "        q = node.Q_a[a]\n",
    "        u = c_puct * node.P_a[a] * sqrtN / (1.0 + node.N_a[a])\n",
    "        score = q + u + random.uniform(-1e-9, 1e-9)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_a = a\n",
    "\n",
    "    assert best_a is not None\n",
    "    return best_a\n",
    "\n",
    "\n",
    "def backprop_path(path: List[Tuple[MCTSNode, Action]], value: float) -> None:\n",
    "    for node, a in reversed(path):\n",
    "        node.N += 1\n",
    "        node.N_a[a] += 1\n",
    "        node.W_a[a] += value\n",
    "        node.Q_a[a] = node.W_a[a] / node.N_a[a]\n",
    "\n",
    "\n",
    "def choose_final_action(root: MCTSNode) -> Action:\n",
    "    maxN = max(root.N_a.values())\n",
    "    cand = [a for a in ACTIONS if root.N_a[a] == maxN]\n",
    "    if len(cand) == 1:\n",
    "        return cand[0]\n",
    "\n",
    "    maxQ = max(root.Q_a[a] for a in cand)\n",
    "    cand2 = [a for a in cand if abs(root.Q_a[a] - maxQ) < 1e-12]\n",
    "    if len(cand2) == 1:\n",
    "        return cand2[0]\n",
    "\n",
    "    maxP = max(root.P_a[a] for a in cand2)\n",
    "    cand3 = [a for a in cand2 if abs(root.P_a[a] - maxP) < 1e-12]\n",
    "    return random.choice(cand3)\n",
    "\n",
    "\n",
    "def rollout_value(\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    detection: DetectionModel,\n",
    "    *,\n",
    "    max_steps: int,\n",
    "    w_step: float,\n",
    "    w_detect: float,\n",
    ") -> float:\n",
    "    total_cost = 0.0\n",
    "    cur = robot_pos\n",
    "    for _ in range(max_steps):\n",
    "        if cur == goal:\n",
    "            break\n",
    "        a = deterministic_greedy_step_toward(world, cur, goal)\n",
    "        cur = world.step(cur, a)\n",
    "        total_cost += w_step\n",
    "        total_cost += w_detect * detection.p_detect(cur, sensor_pos)\n",
    "    if cur == goal:\n",
    "        total_cost -= 20.0\n",
    "    return -total_cost\n",
    "\n",
    "\n",
    "def simulate_sensor_step(\n",
    "    world: GridWorld,\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    robot_pos: Tuple[int, int],\n",
    "    t: int,\n",
    "    mode_idx: int,\n",
    "    policies: List[SensorModePolicy],\n",
    ") -> Tuple[int, int]:\n",
    "    if 0 <= mode_idx < len(policies):\n",
    "        aS = policies[mode_idx].action(world, sensor_pos, robot_pos, t)\n",
    "        return world.step(sensor_pos, aS)\n",
    "    return sensor_pos\n",
    "\n",
    "\n",
    "def mcts_search_action(\n",
    "    world: GridWorld,\n",
    "    belief: BeliefState,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    sensor_policies: List[SensorModePolicy],\n",
    "    detection: DetectionModel,\n",
    "    action_prior: Dict[Action, float],\n",
    "    *,\n",
    "    t: int,\n",
    "    num_sims: int = 250,\n",
    "    max_depth: int = 10,\n",
    "    c_puct: float = 1.4,\n",
    "    w_step: float = 1.0,\n",
    "    w_detect: float = 7.0,\n",
    "    gamma: float = 0.95,\n",
    "    prior_eps: float = 0.10,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> Action:\n",
    "    prior = normalize_probs_dict(action_prior, ACTIONS, eps=prior_eps)\n",
    "\n",
    "    root = MCTSNode(robot_pos=robot_pos, depth=0)\n",
    "    root.P_a = prior\n",
    "\n",
    "    # Prepare particle sampling distribution\n",
    "    particles = belief.particles if belief.particles else [Particle(sensor_pos=robot_pos, mode_idx=0, weight=1.0)]\n",
    "    weights = [float(getattr(p, \"weight\", 1.0)) for p in particles]\n",
    "    s = sum(weights)\n",
    "    if s <= 0.0:\n",
    "        weights = [1.0 / len(weights)] * len(weights)\n",
    "    else:\n",
    "        weights = [w / s for w in weights]\n",
    "\n",
    "    if log is not None and (log._should_print(t, log.cfg.mcts_every_t, lvl=1)):\n",
    "        log.log(f\"[MCTS] t={t} sims={num_sims} depth={max_depth} prior: {prior_diagnostics(prior)}\", t=t, every=log.cfg.mcts_every_t, lvl=1)\n",
    "\n",
    "    for sim in range(num_sims):\n",
    "        hp = random.choices(particles, weights=weights, k=1)[0]\n",
    "        sim_sensor = hp.sensor_pos\n",
    "        sim_mode = hp.mode_idx\n",
    "\n",
    "        node = root\n",
    "        cur_robot = robot_pos\n",
    "        cur_sensor = sim_sensor\n",
    "\n",
    "        path: List[Tuple[MCTSNode, Action]] = []\n",
    "        total_return = 0.0\n",
    "        disc = 1.0\n",
    "\n",
    "        if cur_robot == goal:\n",
    "            root.N += 1\n",
    "            continue\n",
    "\n",
    "        for depth in range(max_depth):\n",
    "            if cur_robot == goal:\n",
    "                total_return += disc * 50.0\n",
    "                break\n",
    "\n",
    "            a = select_action_puct(node, c_puct=c_puct)\n",
    "            path.append((node, a))\n",
    "\n",
    "            nxt_robot = world.step(cur_robot, a)\n",
    "            nxt_sensor = simulate_sensor_step(world, cur_sensor, nxt_robot, t + depth, sim_mode, sensor_policies)\n",
    "\n",
    "            step_cost = w_step + w_detect * detection.p_detect(nxt_robot, nxt_sensor)\n",
    "            total_return += disc * (-step_cost)\n",
    "            disc *= gamma\n",
    "\n",
    "            if a not in node.children:\n",
    "                child = MCTSNode(robot_pos=nxt_robot, depth=node.depth + 1)\n",
    "                child.P_a = prior\n",
    "                node.children[a] = child\n",
    "\n",
    "                leaf_v = rollout_value(\n",
    "                    world,\n",
    "                    nxt_robot,\n",
    "                    nxt_sensor,\n",
    "                    goal,\n",
    "                    detection,\n",
    "                    max_steps=max_depth - depth - 1,\n",
    "                    w_step=w_step,\n",
    "                    w_detect=w_detect,\n",
    "                )\n",
    "                total_return += disc * leaf_v\n",
    "                break\n",
    "\n",
    "            node = node.children[a]\n",
    "            cur_robot, cur_sensor = nxt_robot, nxt_sensor\n",
    "\n",
    "        if path:\n",
    "            backprop_path(path, total_return)\n",
    "        else:\n",
    "            root.N += 1\n",
    "\n",
    "        if log is not None and log.cfg.level >= 2 and (sim < 2 or ((sim + 1) % log.cfg.mcts_progress_every_sims == 0 and t <= log.cfg.detail_until_t)):\n",
    "            log.log(f\"[MCTS][detail] t={t} sim={sim+1}/{num_sims} root.N={root.N}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    total_edge_visits = sum(root.N_a.values())\n",
    "    if log is not None and log._should_print(t, log.cfg.mcts_every_t, lvl=1):\n",
    "        bestN = max(root.N_a, key=lambda a: root.N_a[a])\n",
    "        log.log(\n",
    "            f\"[MCTS] t={t} root.N={root.N} sum(N_a)={total_edge_visits} best_by_N={bestN}\",\n",
    "            t=t,\n",
    "            every=log.cfg.mcts_every_t,\n",
    "            lvl=1,\n",
    "        )\n",
    "        if log.cfg.level >= 2 and t <= log.cfg.detail_until_t:\n",
    "            for a in ACTIONS:\n",
    "                log.log(f\"[MCTS][detail] a={a} N={root.N_a[a]:4d} Q={root.Q_a[a]:+8.3f} P={root.P_a[a]:.3f}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    return choose_final_action(root)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Main Simulation\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    seed: int = 7\n",
    "\n",
    "    H: int = 12\n",
    "    W: int = 18\n",
    "    T: int = 40\n",
    "\n",
    "    num_particles: int = 250\n",
    "\n",
    "    # PF\n",
    "    motion_noise: float = 0.15\n",
    "    resample_threshold: float = 0.55\n",
    "\n",
    "    # Mode library\n",
    "    num_hypotheses: int = 25\n",
    "    per_hypothesis_attempts: int = 2\n",
    "    max_modes: int = 6\n",
    "    w_detect_astar: float = 10.0\n",
    "    rand_scale: float = 0.45\n",
    "\n",
    "    # NEW: plausibility-vs-cost tradeoff\n",
    "    plausibility_lambda: float = 3.0\n",
    "\n",
    "    # NEW: prior temperature\n",
    "    prior_temp: float = 25.0\n",
    "\n",
    "    # Prior smoothing/diagnostics (helps catch \"prior collapse\" from the mode library)\n",
    "    prior_eps_main: float = 0.15\n",
    "    prior_warn_maxp: float = 0.97\n",
    "    prior_warn_minH: float = 0.05\n",
    "\n",
    "    # MCTS\n",
    "    num_sims: int = 250\n",
    "    max_depth: int = 10\n",
    "    c_puct: float = 1.4\n",
    "    w_step_mcts: float = 1.0\n",
    "    w_detect_mcts: float = 7.0\n",
    "\n",
    "    # NEW: force a specific true mode for reproducibility\n",
    "    true_mode_name: Optional[str] = \"chase_robot\"  # set None for random\n",
    "\n",
    "    # Debug\n",
    "    debug: DebugConfig = field(default_factory=DebugConfig)\n",
    "\n",
    "\n",
    "def make_demo_world(cfg: Config) -> Tuple[GridWorld, Tuple[int, int], Tuple[int, int], Tuple[int, int]]:\n",
    "    obs = set()\n",
    "    for c in range(3, 15):\n",
    "        obs.add((5, c))\n",
    "    for r in range(1, 9):\n",
    "        obs.add((r, 9))\n",
    "    obs.discard((5, 7))\n",
    "    obs.discard((6, 9))\n",
    "\n",
    "    world = GridWorld(H=cfg.H, W=cfg.W, obstacles=obs)\n",
    "    robot_start = (10, 2)\n",
    "    goal = (1, 16)\n",
    "    sensor_start = (2, 2)\n",
    "    return world, robot_start, sensor_start, goal\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = Config()\n",
    "    seed_all(cfg.seed)\n",
    "\n",
    "    log = Logger(cfg.debug)\n",
    "\n",
    "    world, robot_pos, sensor_pos, goal = make_demo_world(cfg)\n",
    "\n",
    "    sensor_modes: List[SensorModePolicy] = [\n",
    "        PatrolLoopPolicy(name=\"patrol_left\", loop=[(2, 2), (2, 6), (4, 6), (4, 2)]),\n",
    "        PatrolLoopPolicy(name=\"patrol_mid\", loop=[(2, 10), (2, 13), (4, 13), (4, 10)]),\n",
    "        ChasePolicy(name=\"chase_robot\"),\n",
    "        RandomWalkPolicy(name=\"random_walk\"),\n",
    "    ]\n",
    "    mode_names = [m.name for m in sensor_modes]\n",
    "\n",
    "    # NEW: deterministic true mode option\n",
    "    if cfg.true_mode_name is None:\n",
    "        true_mode_idx = random.randrange(len(sensor_modes))\n",
    "    else:\n",
    "        try:\n",
    "            true_mode_idx = mode_names.index(cfg.true_mode_name)\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"true_mode_name={cfg.true_mode_name!r} not in modes {mode_names}\")\n",
    "\n",
    "    detection = DetectionModel()\n",
    "    obs_model = ObservationModel(sigma=1.3)\n",
    "\n",
    "    sensor_init_candidates = [(2, 2), (2, 10), (3, 3), (3, 9), (1, 1)]\n",
    "    mode_prior = [1.0] * len(sensor_modes)\n",
    "    belief = initialize_belief(world, sensor_init_candidates, mode_prior, mode_names, cfg.num_particles)\n",
    "\n",
    "    log.log(f\"[INIT] true_mode={mode_names[true_mode_idx]} robot={robot_pos} sensor={sensor_pos} goal={goal}\", force=True)\n",
    "    log.log(f\"[INIT] belief modes: {topk_str(belief.mode_posterior_named(), k=4)}\", force=True)\n",
    "\n",
    "    for t in range(cfg.T):\n",
    "        show_header = (t <= cfg.debug.detail_until_t) or (cfg.debug.enabled and cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)\n",
    "        if show_header:\n",
    "            log.log(\"=\" * 80, force=True)\n",
    "            log.log(f\"[TIME] t={t}\", force=True)\n",
    "\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.render_every_t > 0 and t % cfg.debug.render_every_t == 0)):\n",
    "            log.log(\"[WORLD]\", t=t, every=cfg.debug.render_every_t, lvl=1, force=(t <= cfg.debug.detail_until_t))\n",
    "            world.render(robot=robot_pos, sensor=sensor_pos, goal=goal)\n",
    "\n",
    "        obs = obs_model.sample_observation(sensor_pos, world)\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[OBS] obs={obs} (true sensor={sensor_pos})\", force=True)\n",
    "\n",
    "        # PF update\n",
    "        _ = belief_predict_update(\n",
    "            belief,\n",
    "            world,\n",
    "            robot_pos,\n",
    "            sensor_modes,\n",
    "            obs_model,\n",
    "            obs,\n",
    "            t,\n",
    "            motion_noise=cfg.motion_noise,\n",
    "            resample_threshold=cfg.resample_threshold,\n",
    "            log=log,\n",
    "        )\n",
    "\n",
    "        # Mode library -> prior\n",
    "        library, _ = build_multimodal_path_library(\n",
    "            world,\n",
    "            belief,\n",
    "            robot_pos,\n",
    "            goal,\n",
    "            detection,\n",
    "            num_hypotheses=cfg.num_hypotheses,\n",
    "            per_hypothesis_attempts=cfg.per_hypothesis_attempts,\n",
    "            w_detect=cfg.w_detect_astar,\n",
    "            rand_scale=cfg.rand_scale,\n",
    "            max_modes=cfg.max_modes,\n",
    "            plausibility_lambda=cfg.plausibility_lambda,\n",
    "            t=t,\n",
    "            log=log,\n",
    "        )\n",
    "\n",
    "        raw_prior = build_action_prior_from_library(world, robot_pos, library, temp=cfg.prior_temp)\n",
    "        action_prior = normalize_probs_dict(raw_prior, ACTIONS, eps=cfg.prior_eps_main)\n",
    "\n",
    "        # Catch and explain \"prior collapse\" (degenerate action prior)\n",
    "        prior_check_and_log(\n",
    "            world,\n",
    "            robot_pos,\n",
    "            library,\n",
    "            raw_prior,\n",
    "            action_prior,\n",
    "            temp=cfg.prior_temp,\n",
    "            eps=cfg.prior_eps_main,\n",
    "            mode_names=belief.mode_names,\n",
    "            warn_maxp=cfg.prior_warn_maxp,\n",
    "            warn_minH=cfg.prior_warn_minH,\n",
    "            t=t,\n",
    "            log=log,\n",
    "        )\n",
    "\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[PriorDiag] eps={cfg.prior_eps_main:.2f} {prior_diagnostics(action_prior)}\", force=True)\n",
    "\n",
    "        # MCTS choose action\n",
    "        aR = mcts_search_action(\n",
    "            world,\n",
    "            belief,\n",
    "            robot_pos,\n",
    "            goal,\n",
    "            sensor_modes,\n",
    "            detection,\n",
    "            action_prior,\n",
    "            t=t,\n",
    "            num_sims=cfg.num_sims,\n",
    "            max_depth=cfg.max_depth,\n",
    "            c_puct=cfg.c_puct,\n",
    "            w_step=cfg.w_step_mcts,\n",
    "            w_detect=cfg.w_detect_mcts,\n",
    "            prior_eps=0.0,\n",
    "            log=log,\n",
    "        )\n",
    "\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[ACT] robot aR={aR}\", force=True)\n",
    "\n",
    "        # Step robot and true sensor\n",
    "        new_robot = world.step(robot_pos, aR)\n",
    "        aS_true = sensor_modes[true_mode_idx].action(world, sensor_pos, new_robot, t)\n",
    "\n",
    "        # NEW: chase sanity check on TRUE sensor if chase mode\n",
    "        if mode_names[true_mode_idx] == \"chase_robot\":\n",
    "            chase_sanity_check(world, sensor_pos, new_robot, aS_true, log=log, t=t, tag=\"true\")\n",
    "\n",
    "        new_sensor = world.step(sensor_pos, aS_true)\n",
    "\n",
    "        robot_pos, sensor_pos = new_robot, new_sensor\n",
    "\n",
    "        # Detection\n",
    "        p_det = detection.p_detect(robot_pos, sensor_pos)\n",
    "        detected = (random.random() < p_det)\n",
    "\n",
    "        if cfg.debug.enabled and (t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)):\n",
    "            log.log(f\"[STEP] robot={robot_pos} sensor={sensor_pos} aS={aS_true} p_det={p_det:.3f} detected={detected}\", force=True)\n",
    "\n",
    "        # Terminate\n",
    "        if robot_pos == goal:\n",
    "            log.log(\"[TERMINAL] reached goal \", force=True)\n",
    "            break\n",
    "        if detected and manhattan(robot_pos, sensor_pos) <= detection.d0:\n",
    "            log.log(\"[TERMINAL] caught \", force=True)\n",
    "            break\n",
    "\n",
    "    log.log(\"[DONE]\", force=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686e819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] true_mode=chase_robot robot=(10, 2) sensor=(2, 2) goal=(1, 16)\n",
      "[INIT] belief modes: patrol_left:0.272 | patrol_mid:0.252 | random_walk:0.240 | chase_robot:0.236\n",
      "================================================================================\n",
      "[TIME] t=0\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      "..S......#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..R...............\n",
      "..................\n",
      "[OBS] obs=(2, 4) (true sensor=(2, 2))\n",
      "[PF] t=0 obs=(2, 4) ESS 250.0->103.6 resample=True | modes: patrol_mid:0.416 | patrol_left:0.280 | random_walk:0.176\n",
      "[ModesRescue][WARN] t=0 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=0 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=0 new kept distinct_a0=1(R)\n",
      "[ModesRescue][FORCE] t=0 replaced a0=R score=53.62 with a0=S score=58.91 -> distinct_a0=2(R,S)\n",
      "[Modes] t=0 candidates=62 clusters=6 kept=6 | top3: patrol_left:w=0.004,cost=35.2,score=51.7, patrol_mid:w=0.004,cost=36.2,score=52.7, patrol_left:w=0.004,cost=36.5,score=53.1\n",
      "[PriorDiag] eps=0.15 H=0.801 top=R:0.764 | S:0.146 | U:0.030\n",
      "[MCTS] t=0 sims=250 depth=10 prior: H=0.801 top=R:0.764 | S:0.146 | U:0.030\n",
      "[MCTS] t=0 root.N=250 sum(N_a)=250 best_by_N=D\n",
      "[ACT] robot aR=D\n",
      "[CHASE] true t=0 src=(2, 2) dst=(11, 2) a=D nxt=(3, 2) d:9->8 best_d=8 best=['D']\n",
      "[STEP] robot=(11, 2) sensor=(3, 2) aS=D d=8 p_det=0.191 detected=True\n",
      "================================================================================\n",
      "[TIME] t=1\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      "..S......#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "..R...............\n",
      "[OBS] obs=(4, 0) (true sensor=(3, 2))\n",
      "[PF] t=1 obs=(4, 0) ESS 250.0->63.1 resample=True | modes: chase_robot:0.608 | random_walk:0.172 | patrol_left:0.128\n",
      "[ModesRescue][WARN] t=1 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=1 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=1 new kept distinct_a0=1(R)\n",
      "[ModesRescue][FORCE] t=1 replaced a0=R score=54.85 with a0=S score=61.95 -> distinct_a0=2(R,S)\n",
      "[Modes] t=1 candidates=62 clusters=6 kept=6 | top3: random_walk:w=0.004,cost=35.2,score=51.8, chase_robot:w=0.004,cost=35.7,score=52.2, random_walk:w=0.004,cost=37.1,score=53.7\n",
      "[PriorDiag] eps=0.15 H=0.785 top=R:0.774 | S:0.136 | U:0.030\n",
      "[MCTS] t=1 sims=250 depth=10 prior: H=0.785 top=R:0.774 | S:0.136 | U:0.030\n",
      "[MCTS] t=1 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[CHASE] true t=1 src=(3, 2) dst=(11, 3) a=D nxt=(4, 2) d:9->8 best_d=8 best=['D', 'R']\n",
      "[STEP] robot=(11, 3) sensor=(4, 2) aS=D d=8 p_det=0.191 detected=False\n",
      "================================================================================\n",
      "[TIME] t=2\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      "..S......#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "...R..............\n",
      "[OBS] obs=(3, 4) (true sensor=(4, 2))\n",
      "[PF] t=2 obs=(3, 4) ESS 250.0->90.1 resample=True | modes: patrol_left:0.440 | random_walk:0.216 | chase_robot:0.192\n",
      "[ModesRescue][WARN] t=2 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=2 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=2 new kept distinct_a0=1(R)\n",
      "[ModesRescue][FORCE] t=2 replaced a0=R score=59.41 with a0=U score=56.12 -> distinct_a0=2(R,U)\n",
      "[Modes] t=2 candidates=62 clusters=6 kept=6 | top3: patrol_left:w=0.004,cost=35.1,score=51.7, random_walk:w=0.004,cost=35.7,score=52.3, patrol_left:w=0.004,cost=36.5,score=53.1\n",
      "[PriorDiag] eps=0.15 H=0.820 top=R:0.753 | U:0.157 | D:0.030\n",
      "[MCTS] t=2 sims=250 depth=10 prior: H=0.820 top=R:0.753 | U:0.157 | D:0.030\n",
      "[MCTS] t=2 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[CHASE] true t=2 src=(4, 2) dst=(11, 4) a=D nxt=(5, 2) d:9->8 best_d=8 best=['D', 'R']\n",
      "[STEP] robot=(11, 4) sensor=(5, 2) aS=D d=8 p_det=0.191 detected=False\n",
      "[PF] t=3 obs=(6, 2) ESS 250.0->48.6 resample=True | modes: chase_robot:0.728 | patrol_left:0.172 | random_walk:0.096\n",
      "[ModesRescue][WARN] t=3 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=3 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=3 new kept distinct_a0=1(R)\n",
      "[ModesRescue][FORCE] t=3 replaced a0=R score=53.31 with a0=U score=56.34 -> distinct_a0=2(R,U)\n",
      "[ModesRescue][WARN] t=4 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=4 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=4 new kept distinct_a0=2(L,R)\n",
      "================================================================================\n",
      "[TIME] t=5\n",
      "[OBS] obs=(6, 1) (true sensor=(7, 2))\n",
      "[PF] t=5 obs=(6, 1) ESS 164.2->98.8 resample=True | modes: chase_robot:0.992 | random_walk:0.008\n",
      "[ModesRescue][WARN] t=5 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=5 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=5 new kept distinct_a0=1(R)\n",
      "[ModesRescue][FORCE] t=5 replaced a0=R score=49.81 with a0=U score=48.84 -> distinct_a0=2(R,U)\n",
      "[Modes] t=5 candidates=62 clusters=6 kept=6 | top3: chase_robot:w=0.004,cost=30.1,score=46.6, chase_robot:w=0.004,cost=31.6,score=48.1, chase_robot:w=0.004,cost=32.1,score=48.6\n",
      "[PriorDiag] eps=0.15 H=0.839 top=R:0.740 | U:0.170 | D:0.030\n",
      "[MCTS] t=5 sims=250 depth=10 prior: H=0.839 top=R:0.740 | U:0.170 | D:0.030\n",
      "[MCTS] t=5 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[CHASE] true t=5 src=(7, 2) dst=(11, 7) a=R nxt=(7, 3) d:9->8 best_d=8 best=['D', 'R']\n",
      "[STEP] robot=(11, 7) sensor=(7, 3) aS=R d=8 p_det=0.191 detected=False\n",
      "[ModesRescue][WARN] t=6 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=6 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=6 new kept distinct_a0=1(R)\n",
      "[ModesRescue][FORCE] t=6 replaced a0=R score=51.87 with a0=S score=53.27 -> distinct_a0=2(R,S)\n",
      "[ModesRescue][WARN] t=7 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=7 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=7 new kept distinct_a0=1(R)\n",
      "[ModesRescue][FORCE] t=7 replaced a0=R score=48.54 with a0=S score=51.17 -> distinct_a0=2(R,S)\n",
      "[ModesRescue][WARN] t=8 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=8 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=8 new kept distinct_a0=2(R,U)\n",
      "[PF] t=9 obs=(9, 6) ESS 148.5->69.8 resample=True | modes: chase_robot:1.000\n",
      "[ModesRescue][WARN] t=9 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=9 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=9 new kept distinct_a0=2(R,U)\n",
      "================================================================================\n",
      "[TIME] t=10\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".......S.#........\n",
      ".........#........\n",
      "..................\n",
      "..................\n",
      "...........R......\n",
      "[OBS] obs=(7, 8) (true sensor=(7, 7))\n",
      "[PF] t=10 obs=(7, 8) ESS 250.0->190.2 resample=False | modes: chase_robot:1.000\n",
      "[ModesRescue][WARN] t=10 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=10 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=10 new kept distinct_a0=3(R,S,U)\n",
      "[Modes] t=10 candidates=62 clusters=6 kept=6 | top3: chase_robot:w=0.009,cost=28.9,score=43.2, chase_robot:w=0.009,cost=29.0,score=43.3, chase_robot:w=0.009,cost=30.7,score=44.9\n",
      "[PriorDiag] eps=0.15 H=1.121 top=R:0.599 | U:0.172 | S:0.170\n",
      "[MCTS] t=10 sims=250 depth=10 prior: H=1.121 top=R:0.599 | U:0.172 | S:0.170\n",
      "[MCTS] t=10 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[CHASE] true t=10 src=(7, 7) dst=(11, 12) a=R nxt=(7, 8) d:9->8 best_d=8 best=['D', 'R']\n",
      "[STEP] robot=(11, 12) sensor=(7, 8) aS=R d=8 p_det=0.191 detected=False\n",
      "[PF] t=11 obs=(5, 9) ESS 190.2->112.1 resample=True | modes: chase_robot:1.000\n",
      "[ModesRescue][WARN] t=11 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=11 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=11 new kept distinct_a0=3(R,S,U)\n",
      "[ModesRescue][WARN] t=12 all kept paths start with R; attempting forced-first-action rescue\n",
      "[ModesRescue] t=12 added=12 forced-a0 candidates (excluding R)\n",
      "[ModesRescue] t=12 new kept distinct_a0=3(R,S,U)\n",
      "================================================================================\n",
      "[TIME] t=15\n",
      "[OBS] obs=(7, 8) (true sensor=(9, 10))\n",
      "[PF] t=15 obs=(7, 8) ESS 168.7->160.6 resample=False | modes: chase_robot:1.000\n",
      "[Modes] t=15 candidates=50 clusters=3 kept=3 | top3: chase_robot:w=0.023,cost=25.5,score=36.8, chase_robot:w=0.011,cost=27.8,score=41.5, chase_robot:w=0.005,cost=30.7,score=46.7\n",
      "[PriorDiag] eps=0.15 H=1.006 top=U:0.563 | R:0.347 | D:0.030\n",
      "[MCTS] t=15 sims=250 depth=10 prior: H=1.006 top=U:0.563 | R:0.347 | D:0.030\n",
      "[MCTS] t=15 root.N=250 sum(N_a)=250 best_by_N=R\n",
      "[ACT] robot aR=R\n",
      "[CHASE] true t=15 src=(9, 10) dst=(11, 17) a=R nxt=(9, 11) d:9->8 best_d=8 best=['D', 'R']\n",
      "[STEP] robot=(11, 17) sensor=(9, 11) aS=R d=8 p_det=0.191 detected=False\n",
      "[PF] t=16 obs=(7, 9) ESS 160.6->97.7 resample=True | modes: chase_robot:1.000\n",
      "[ModesRescue][WARN] t=16 all kept paths start with U; attempting forced-first-action rescue\n",
      "[ModesRescue] t=16 added=12 forced-a0 candidates (excluding U)\n",
      "[ModesRescue] t=16 new kept distinct_a0=3(L,S,U)\n",
      "[ModesRescue][WARN] t=17 all kept paths start with U; attempting forced-first-action rescue\n",
      "[ModesRescue] t=17 added=12 forced-a0 candidates (excluding U)\n",
      "[ModesRescue] t=17 new kept distinct_a0=3(L,S,U)\n",
      "[PF] t=18 obs=(8, 14) ESS 192.2->130.9 resample=True | modes: chase_robot:1.000\n",
      "[ModesRescue][WARN] t=18 all kept paths start with U; attempting forced-first-action rescue\n",
      "[ModesRescue] t=18 added=12 forced-a0 candidates (excluding U)\n",
      "[ModesRescue] t=18 new kept distinct_a0=3(L,S,U)\n",
      "[ModesRescue][WARN] t=19 all kept paths start with U; attempting forced-first-action rescue\n",
      "[ModesRescue] t=19 added=12 forced-a0 candidates (excluding U)\n",
      "[ModesRescue] t=19 new kept distinct_a0=3(L,S,U)\n",
      "================================================================================\n",
      "[TIME] t=20\n",
      "[WORLD]\n",
      "..................\n",
      ".........#......G.\n",
      ".........#........\n",
      ".........#........\n",
      ".........#........\n",
      "...####.#######...\n",
      "..................\n",
      ".........#........\n",
      ".........#........\n",
      "...............S..\n",
      "..................\n",
      ".................R\n",
      "[OBS] obs=(11, 15) (true sensor=(9, 15))\n",
      "[PF] t=20 obs=(11, 15) ESS 165.6->138.0 resample=False | modes: chase_robot:1.000\n",
      "[ModesRescue][WARN] t=20 all kept paths start with U; attempting forced-first-action rescue\n",
      "[ModesRescue] t=20 added=12 forced-a0 candidates (excluding U)\n",
      "[ModesRescue] t=20 new kept distinct_a0=3(L,S,U)\n",
      "[Modes] t=20 candidates=62 clusters=5 kept=5 | top3: chase_robot:w=0.026,cost=39.5,score=50.5, chase_robot:w=0.026,cost=39.7,score=50.7, chase_robot:w=0.026,cost=46.3,score=57.3\n",
      "[PriorDiag] eps=0.15 H=1.195 top=U:0.530 | S:0.221 | L:0.188\n",
      "[MCTS] t=20 sims=250 depth=10 prior: H=1.195 top=U:0.530 | S:0.221 | L:0.188\n",
      "[MCTS] t=20 root.N=250 sum(N_a)=250 best_by_N=S\n",
      "[ACT] robot aR=S\n",
      "[CHASE] true t=20 src=(9, 15) dst=(11, 17) a=D nxt=(10, 15) d:4->3 best_d=3 best=['D', 'R']\n",
      "[STEP] robot=(11, 17) sensor=(10, 15) aS=D d=3 p_det=0.680 detected=True\n",
      "[PF] t=21 obs=(9, 16) ESS 138.0->108.7 resample=True | modes: chase_robot:1.000\n",
      "[ModesRescue][WARN] t=21 all kept paths start with U; attempting forced-first-action rescue\n",
      "[ModesRescue] t=21 added=12 forced-a0 candidates (excluding U)\n",
      "[ModesRescue] t=21 new kept distinct_a0=3(L,S,U)\n",
      "[TERMINAL] caught \n",
      "[PLOTS] saved to artifacts\\run_seed_8\n",
      "[DONE]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"GenBR-lite + PF Belief + Multimodal Path Library (debug-robust)\n",
    "\n",
    "This version includes the specific fixes suggested from your logs:\n",
    "1) **Chase policy sanity + determinism**:\n",
    "   - Chase now uses a deterministic tie-break (no random sideways moves on ties).\n",
    "   - We print (and warn on) any chase step that *increases* Manhattan distance when a decreasing move exists.\n",
    "\n",
    "2) **Mode-library selection uses plausibility + cost** (not cost-only optimism):\n",
    "   - Each candidate path is scored as:  score = cost + lambda_plaus * (-log(hyp_weight)).\n",
    "   - Best-per-cluster and final sorting use this score.\n",
    "\n",
    "3) **Action prior is a mixture over modes** (not single-best-path):\n",
    "   - Prior weights each kept mode by: hyp_weight * exp(-cost/temp).\n",
    "\n",
    "4) **Detection is actually terminal**:\n",
    "   - If detected and within d0, episode terminates as \"caught\".\n",
    "\n",
    "What to send me to verify correctness:\n",
    "- Run with DebugConfig(level=2, detail_until_t=6, summary_every_t=1, render_every_t=1) for ~10 steps.\n",
    "- Paste the log lines that start with: [CHASE], [CHASE][WARN], [ModesKept], [PriorDiag], [MCTS]\n",
    "\n",
    "Run:\n",
    "  python3 this_file.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import random\n",
    "import heapq\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional, Iterable, Callable, Any, Set\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Debug / Logging utilities\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class DebugConfig:\n",
    "    enabled: bool = True\n",
    "    level: int = 1\n",
    "    # 0 = silent\n",
    "    # 1 = periodic summaries\n",
    "    # 2 = detailed (still gated)\n",
    "\n",
    "    # Print detail for the first few timesteps\n",
    "    detail_until_t: int = 2\n",
    "\n",
    "    # Periodic summary controls\n",
    "    summary_every_t: int = 5\n",
    "    render_every_t: int = 10\n",
    "\n",
    "    # Stage-specific periodic prints\n",
    "    pf_every_t: int = 5\n",
    "    modes_every_t: int = 5\n",
    "    mcts_every_t: int = 5\n",
    "\n",
    "    # Within MCTS\n",
    "    mcts_progress_every_sims: int = 50\n",
    "\n",
    "    # Safety: cap printing of mode hypotheses even at detail level\n",
    "    max_hyp_print: int = 3\n",
    "\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, cfg: DebugConfig):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def _should_print(self, t: Optional[int], every: Optional[int], lvl: int) -> bool:\n",
    "        if not self.cfg.enabled:\n",
    "            return False\n",
    "        if lvl > self.cfg.level:\n",
    "            return False\n",
    "        if t is None:\n",
    "            return True\n",
    "        if t <= self.cfg.detail_until_t:\n",
    "            return True\n",
    "        if every is None:\n",
    "            return False\n",
    "        return (every > 0) and (t % every == 0)\n",
    "\n",
    "    def log(self, msg: str, *, t: Optional[int] = None, every: Optional[int] = None, lvl: int = 1, force: bool = False) -> None:\n",
    "        if force or self._should_print(t, every, lvl):\n",
    "            print(msg)\n",
    "\n",
    "\n",
    "def soft_assert(cond: bool, msg: str, *, fatal: bool = False, log: Optional[Logger] = None, t: Optional[int] = None) -> None:\n",
    "    if cond:\n",
    "        return\n",
    "    if log is not None:\n",
    "        log.log(f\"[WARN] {msg}\", t=t, every=None, lvl=1, force=True)\n",
    "    if fatal:\n",
    "        raise AssertionError(msg)\n",
    "\n",
    "\n",
    "def clamp(x: float, lo: float, hi: float) -> float:\n",
    "    return max(lo, min(hi, x))\n",
    "\n",
    "\n",
    "def manhattan(a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "\n",
    "def seed_all(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "def stable_bucket(sig: str, m: int) -> int:\n",
    "    \"\"\"Stable mapping sig -> [0..m-1] independent of Python's randomized hash.\"\"\"\n",
    "    if m <= 0:\n",
    "        return 0\n",
    "    h = hashlib.md5(sig.encode(\"utf-8\")).hexdigest()\n",
    "    return int(h[:8], 16) % m\n",
    "\n",
    "\n",
    "def normalize_probs_dict(d: Dict[Any, float], keys: Iterable[Any], *, eps: float = 0.0) -> Dict[Any, float]:\n",
    "    \"\"\"Return a normalized distribution over `keys` from possibly-missing/negative inputs.\n",
    "\n",
    "    - Clips negatives to 0\n",
    "    - Adds optional epsilon smoothing to avoid degeneracy\n",
    "    - Falls back to uniform if total mass is 0\n",
    "    \"\"\"\n",
    "    klist = list(keys)\n",
    "    out = {k: max(0.0, float(d.get(k, 0.0))) for k in klist}\n",
    "    s = sum(out.values())\n",
    "\n",
    "    if s <= 0.0:\n",
    "        u = 1.0 / max(1, len(klist))\n",
    "        return {k: u for k in klist}\n",
    "\n",
    "    out = {k: v / s for k, v in out.items()}\n",
    "\n",
    "    if eps > 0.0:\n",
    "        u = 1.0 / max(1, len(klist))\n",
    "        out = {k: (1.0 - eps) * out[k] + eps * u for k in klist}\n",
    "        s2 = sum(out.values())\n",
    "        out = {k: v / s2 for k, v in out.items()}\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def topk_str(d: Dict[Any, float], k: int = 3, fmt: str = \"{k}:{v:.3f}\") -> str:\n",
    "    items = sorted(d.items(), key=lambda kv: kv[1], reverse=True)[:k]\n",
    "    return \" | \".join(fmt.format(k=kk, v=vv) for kk, vv in items)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Gridworld Environment\n",
    "# =========================\n",
    "\n",
    "Action = str  # 'U','D','L','R','S'\n",
    "\n",
    "ACTIONS: List[Action] = [\"U\", \"D\", \"L\", \"R\", \"S\"]\n",
    "ACTION_DELTAS: Dict[Action, Tuple[int, int]] = {\n",
    "    \"U\": (-1, 0),\n",
    "    \"D\": (1, 0),\n",
    "    \"L\": (0, -1),\n",
    "    \"R\": (0, 1),\n",
    "    \"S\": (0, 0),\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GridWorld:\n",
    "    H: int\n",
    "    W: int\n",
    "    obstacles: Set[Tuple[int, int]] = field(default_factory=set)\n",
    "\n",
    "    def in_bounds(self, p: Tuple[int, int]) -> bool:\n",
    "        r, c = p\n",
    "        return 0 <= r < self.H and 0 <= c < self.W\n",
    "\n",
    "    def is_free(self, p: Tuple[int, int]) -> bool:\n",
    "        return self.in_bounds(p) and (p not in self.obstacles)\n",
    "\n",
    "    def step(self, p: Tuple[int, int], a: Action) -> Tuple[int, int]:\n",
    "        if a not in ACTION_DELTAS:\n",
    "            raise ValueError(f\"Unknown action: {a}\")\n",
    "        dr, dc = ACTION_DELTAS[a]\n",
    "        np = (p[0] + dr, p[1] + dc)\n",
    "        return np if self.is_free(np) else p\n",
    "\n",
    "    def neighbors(self, p: Tuple[int, int]) -> List[Tuple[Tuple[int, int], Action]]:\n",
    "        return [(self.step(p, a), a) for a in ACTIONS]\n",
    "\n",
    "    def render(self, robot: Tuple[int, int], sensor: Tuple[int, int], goal: Tuple[int, int]) -> None:\n",
    "        grid = [[\".\" for _ in range(self.W)] for _ in range(self.H)]\n",
    "        for (r, c) in self.obstacles:\n",
    "            grid[r][c] = \"#\"\n",
    "        rr, rc = robot\n",
    "        sr, sc = sensor\n",
    "        gr, gc = goal\n",
    "        grid[gr][gc] = \"G\"\n",
    "        grid[sr][sc] = \"S\"\n",
    "        grid[rr][rc] = \"R\"\n",
    "        for r in range(self.H):\n",
    "            print(\"\".join(grid[r]))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Sensor Models (Modes)\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class SensorModePolicy:\n",
    "    name: str\n",
    "\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def best_actions_toward(world: GridWorld, src: Tuple[int, int], dst: Tuple[int, int]) -> Tuple[List[Action], int]:\n",
    "    \"\"\"Return (best_actions, best_dist) minimizing manhattan(next(src,a), dst).\"\"\"\n",
    "    best_actions: List[Action] = []\n",
    "    best_dist = 10**9\n",
    "    for a in ACTIONS:\n",
    "        np = world.step(src, a)\n",
    "        d = manhattan(np, dst)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_actions = [a]\n",
    "        elif d == best_dist:\n",
    "            best_actions.append(a)\n",
    "    return best_actions, best_dist\n",
    "\n",
    "\n",
    "def deterministic_greedy_step_toward(world: GridWorld, src: Tuple[int, int], dst: Tuple[int, int]) -> Action:\n",
    "    \"\"\"Greedy toward dst with deterministic tie-break (easier to debug than random ties).\"\"\"\n",
    "    best_as, _ = best_actions_toward(world, src, dst)\n",
    "    if not best_as:\n",
    "        return \"S\"\n",
    "\n",
    "    # Preferred axis: move along the larger |delta| if possible\n",
    "    dr = dst[0] - src[0]\n",
    "    dc = dst[1] - src[1]\n",
    "\n",
    "    preferred: List[Action] = []\n",
    "    if abs(dr) >= abs(dc):\n",
    "        if dr > 0:\n",
    "            preferred.append(\"D\")\n",
    "        elif dr < 0:\n",
    "            preferred.append(\"U\")\n",
    "    if abs(dc) > abs(dr):\n",
    "        if dc > 0:\n",
    "            preferred.append(\"R\")\n",
    "        elif dc < 0:\n",
    "            preferred.append(\"L\")\n",
    "\n",
    "    # If the preferred move is among best actions, take it\n",
    "    for a in preferred:\n",
    "        if a in best_as:\n",
    "            return a\n",
    "\n",
    "    # Otherwise deterministic order\n",
    "    for a in [\"U\", \"D\", \"L\", \"R\", \"S\"]:\n",
    "        if a in best_as:\n",
    "            return a\n",
    "\n",
    "    return best_as[0]\n",
    "\n",
    "\n",
    "def chase_sanity_check(\n",
    "    world: GridWorld,\n",
    "    src: Tuple[int, int],\n",
    "    dst: Tuple[int, int],\n",
    "    chosen: Action,\n",
    "    *,\n",
    "    log: Optional[Logger],\n",
    "    t: int,\n",
    "    tag: str,\n",
    ") -> None:\n",
    "    \"\"\"Warn if chosen action increases distance when a non-increasing action exists.\"\"\"\n",
    "    d0 = manhattan(src, dst)\n",
    "    nxt = world.step(src, chosen)\n",
    "    d1 = manhattan(nxt, dst)\n",
    "\n",
    "    best_as, best_d = best_actions_toward(world, src, dst)\n",
    "\n",
    "    if log is not None and log.cfg.enabled and (t <= log.cfg.detail_until_t or (log.cfg.summary_every_t > 0 and t % log.cfg.summary_every_t == 0)):\n",
    "        log.log(\n",
    "            f\"[CHASE] {tag} t={t} src={src} dst={dst} a={chosen} nxt={nxt} d:{d0}->{d1} best_d={best_d} best={best_as}\",\n",
    "            t=t,\n",
    "            every=log.cfg.summary_every_t,\n",
    "            lvl=1,\n",
    "        )\n",
    "\n",
    "    # If chosen isn't among best actions, it's suspicious\n",
    "    if chosen not in best_as:\n",
    "        if log is not None:\n",
    "            log.log(\n",
    "                f\"[CHASE][WARN] {tag} t={t} chose {chosen} but best={best_as} (d:{d0}->{d1}, best_d={best_d})\",\n",
    "                t=t,\n",
    "                every=None,\n",
    "                lvl=1,\n",
    "                force=True,\n",
    "            )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PatrolLoopPolicy(SensorModePolicy):\n",
    "    loop: List[Tuple[int, int]] = field(default_factory=list)\n",
    "\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        if not self.loop:\n",
    "            return \"S\"\n",
    "        idx = t % len(self.loop)\n",
    "        return deterministic_greedy_step_toward(world, sensor_pos, self.loop[idx])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ChasePolicy(SensorModePolicy):\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        return deterministic_greedy_step_toward(world, sensor_pos, robot_pos)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RandomWalkPolicy(SensorModePolicy):\n",
    "    def action(self, world: GridWorld, sensor_pos: Tuple[int, int], robot_pos: Tuple[int, int], t: int) -> Action:\n",
    "        return random.choice(ACTIONS)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Detection / Observation\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class DetectionModel:\n",
    "    d0: int = 2\n",
    "    p_close: float = 0.9\n",
    "    p_far: float = 0.05\n",
    "    decay: float = 0.3\n",
    "\n",
    "    def p_detect(self, robot_pos: Tuple[int, int], sensor_pos: Tuple[int, int]) -> float:\n",
    "        dist = manhattan(robot_pos, sensor_pos)\n",
    "        if dist <= self.d0:\n",
    "            return self.p_close\n",
    "        return self.p_far + (self.p_close - self.p_far) * math.exp(-self.decay * (dist - self.d0))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ObservationModel:\n",
    "    sigma: float = 1.2\n",
    "\n",
    "    def sample_observation(self, sensor_pos: Tuple[int, int], world: GridWorld) -> Tuple[int, int]:\n",
    "        max_jump = 2\n",
    "        dr = random.randint(-max_jump, max_jump)\n",
    "        dc = random.randint(-max_jump, max_jump)\n",
    "        o = (sensor_pos[0] + dr, sensor_pos[1] + dc)\n",
    "        o = (int(clamp(o[0], 0, world.H - 1)), int(clamp(o[1], 0, world.W - 1)))\n",
    "        return o\n",
    "\n",
    "    def likelihood(self, obs: Tuple[int, int], sensor_pos: Tuple[int, int]) -> float:\n",
    "        d = manhattan(obs, sensor_pos)\n",
    "        return max(1e-12, math.exp(-d / max(1e-6, self.sigma)))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Particle Filter over (sensor_pos, mode)\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class Particle:\n",
    "    sensor_pos: Tuple[int, int]\n",
    "    mode_idx: int\n",
    "    weight: float = 1.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BeliefState:\n",
    "    particles: List[Particle]\n",
    "    mode_names: List[str]\n",
    "\n",
    "    def normalize(self) -> None:\n",
    "        s = sum(p.weight for p in self.particles)\n",
    "        if s <= 0.0:\n",
    "            w = 1.0 / max(1, len(self.particles))\n",
    "            for p in self.particles:\n",
    "                p.weight = w\n",
    "            return\n",
    "        for p in self.particles:\n",
    "            p.weight /= s\n",
    "\n",
    "    def effective_sample_size(self) -> float:\n",
    "        s = sum(p.weight * p.weight for p in self.particles)\n",
    "        return 0.0 if s <= 0.0 else 1.0 / s\n",
    "\n",
    "    def mode_posterior(self) -> Dict[int, float]:\n",
    "        post: Dict[int, float] = defaultdict(float)\n",
    "        for p in self.particles:\n",
    "            post[p.mode_idx] += p.weight\n",
    "        return dict(post)\n",
    "\n",
    "    def mode_posterior_named(self) -> Dict[str, float]:\n",
    "        post_i = self.mode_posterior()\n",
    "        out: Dict[str, float] = {}\n",
    "        for i, v in post_i.items():\n",
    "            name = self.mode_names[i] if 0 <= i < len(self.mode_names) else f\"mode{i}\"\n",
    "            out[name] = out.get(name, 0.0) + v\n",
    "        return out\n",
    "\n",
    "\n",
    "def systematic_resample(particles: List[Particle]) -> List[Particle]:\n",
    "    n = len(particles)\n",
    "    if n == 0:\n",
    "        return []\n",
    "    positions = [(random.random() + i) / n for i in range(n)]\n",
    "    cumulative = []\n",
    "    csum = 0.0\n",
    "    for p in particles:\n",
    "        csum += p.weight\n",
    "        cumulative.append(csum)\n",
    "\n",
    "    out: List[Particle] = []\n",
    "    i = 0\n",
    "    for pos in positions:\n",
    "        while i < n - 1 and pos > cumulative[i]:\n",
    "            i += 1\n",
    "        chosen = particles[i]\n",
    "        out.append(Particle(sensor_pos=chosen.sensor_pos, mode_idx=chosen.mode_idx, weight=1.0 / n))\n",
    "    return out\n",
    "\n",
    "\n",
    "def initialize_belief(\n",
    "    world: GridWorld,\n",
    "    sensor_init_candidates: List[Tuple[int, int]],\n",
    "    mode_prior: List[float],\n",
    "    mode_names: List[str],\n",
    "    num_particles: int = 200,\n",
    ") -> BeliefState:\n",
    "    if len(mode_prior) != len(mode_names):\n",
    "        raise ValueError(\"mode_prior and mode_names must have same length\")\n",
    "    if not sensor_init_candidates:\n",
    "        raise ValueError(\"Need at least one sensor init candidate\")\n",
    "    if num_particles <= 0:\n",
    "        raise ValueError(\"num_particles must be > 0\")\n",
    "\n",
    "    # normalize prior\n",
    "    s = sum(mode_prior)\n",
    "    if s <= 0.0:\n",
    "        mode_prior = [1.0 / len(mode_prior)] * len(mode_prior)\n",
    "    else:\n",
    "        mode_prior = [p / s for p in mode_prior]\n",
    "\n",
    "    def sample_mode() -> int:\n",
    "        r = random.random()\n",
    "        c = 0.0\n",
    "        for i, p in enumerate(mode_prior):\n",
    "            c += p\n",
    "            if r <= c:\n",
    "                return i\n",
    "        return len(mode_prior) - 1\n",
    "\n",
    "    particles: List[Particle] = []\n",
    "    for _ in range(num_particles):\n",
    "        sp = random.choice(sensor_init_candidates)\n",
    "        z = sample_mode()\n",
    "        particles.append(Particle(sensor_pos=sp, mode_idx=z, weight=1.0 / num_particles))\n",
    "\n",
    "    b = BeliefState(particles=particles, mode_names=mode_names)\n",
    "    b.normalize()\n",
    "    return b\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PFStepInfo:\n",
    "    ess_before: float\n",
    "    ess_after: float\n",
    "    resampled: bool\n",
    "\n",
    "\n",
    "def belief_predict_update(\n",
    "    belief: BeliefState,\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    sensor_policies: List[SensorModePolicy],\n",
    "    obs_model: ObservationModel,\n",
    "    obs: Tuple[int, int],\n",
    "    t: int,\n",
    "    *,\n",
    "    motion_noise: float = 0.10,\n",
    "    resample_threshold: float = 0.5,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> PFStepInfo:\n",
    "    if not belief.particles:\n",
    "        raise ValueError(\"belief has no particles\")\n",
    "\n",
    "    belief.normalize()\n",
    "    ess0 = belief.effective_sample_size()\n",
    "\n",
    "    # Predict + weight update\n",
    "    for p in belief.particles:\n",
    "        mi = p.mode_idx\n",
    "        if 0 <= mi < len(sensor_policies):\n",
    "            aS = sensor_policies[mi].action(world, p.sensor_pos, robot_pos, t)\n",
    "        else:\n",
    "            aS = \"S\"\n",
    "\n",
    "        predicted = world.step(p.sensor_pos, aS)\n",
    "        if random.random() < motion_noise:\n",
    "            predicted = world.step(predicted, random.choice(ACTIONS))\n",
    "\n",
    "        p.sensor_pos = predicted\n",
    "        p.weight *= obs_model.likelihood(obs, p.sensor_pos)\n",
    "\n",
    "    belief.normalize()\n",
    "    ess1 = belief.effective_sample_size()\n",
    "\n",
    "    # Sanity checks\n",
    "    N = len(belief.particles)\n",
    "    soft_assert(0.0 <= ess1 <= N + 1e-6, f\"ESS out of bounds: {ess1} (N={N})\", log=log, t=t)\n",
    "\n",
    "    resampled = False\n",
    "    if ess1 < resample_threshold * N:\n",
    "        belief.particles = systematic_resample(belief.particles)\n",
    "        belief.normalize()\n",
    "        resampled = True\n",
    "\n",
    "    # Controlled prints\n",
    "    if log is not None:\n",
    "        if log._should_print(t, log.cfg.pf_every_t, lvl=1) or resampled:\n",
    "            mp = belief.mode_posterior_named()\n",
    "            log.log(\n",
    "                f\"[PF] t={t} obs={obs} ESS {ess0:.1f}->{ess1:.1f} resample={resampled} | modes: {topk_str(mp, k=3)}\",\n",
    "                t=t,\n",
    "                every=log.cfg.pf_every_t,\n",
    "                lvl=1,\n",
    "                force=resampled,\n",
    "            )\n",
    "            if log.cfg.level >= 2 and t <= log.cfg.detail_until_t:\n",
    "                log.log(f\"[PF][detail] full mode posterior: {topk_str(mp, k=10)}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    return PFStepInfo(ess_before=ess0, ess_after=ess1, resampled=resampled)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# A* Search with Risk Costs\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class AStarResult:\n",
    "    path: List[Tuple[int, int]]\n",
    "    cost: float\n",
    "    expanded: int\n",
    "\n",
    "\n",
    "def astar_path(\n",
    "    world: GridWorld,\n",
    "    start: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    step_cost: Callable[[Tuple[int, int]], float],\n",
    "    heuristic: Callable[[Tuple[int, int]], float],\n",
    "    *,\n",
    "    max_expansions: int = 50_000,\n",
    ") -> Optional[AStarResult]:\n",
    "    if not world.is_free(start) or not world.is_free(goal):\n",
    "        return None\n",
    "\n",
    "    frontier: List[Tuple[float, float, Tuple[int, int]]] = []\n",
    "    heapq.heappush(frontier, (heuristic(start), 0.0, start))\n",
    "\n",
    "    came_from: Dict[Tuple[int, int], Tuple[int, int]] = {}\n",
    "    gscore: Dict[Tuple[int, int], float] = {start: 0.0}\n",
    "\n",
    "    expanded = 0\n",
    "\n",
    "    # A* with reopen: skip stale pops\n",
    "    while frontier and expanded < max_expansions:\n",
    "        f, g, cur = heapq.heappop(frontier)\n",
    "        if g > gscore.get(cur, float(\"inf\")) + 1e-12:\n",
    "            continue\n",
    "        expanded += 1\n",
    "\n",
    "        if cur == goal:\n",
    "            path = [cur]\n",
    "            while cur in came_from:\n",
    "                cur = came_from[cur]\n",
    "                path.append(cur)\n",
    "            path.reverse()\n",
    "            return AStarResult(path=path, cost=gscore[goal], expanded=expanded)\n",
    "\n",
    "        for (nxt, _) in world.neighbors(cur):\n",
    "            if not world.is_free(nxt):\n",
    "                continue\n",
    "            sc = step_cost(nxt)\n",
    "            if not math.isfinite(sc) or sc < 0:\n",
    "                continue\n",
    "            ng = gscore[cur] + sc\n",
    "            if ng + 1e-12 < gscore.get(nxt, float(\"inf\")):\n",
    "                gscore[nxt] = ng\n",
    "                came_from[nxt] = cur\n",
    "                heapq.heappush(frontier, (ng + heuristic(nxt), ng, nxt))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Multimodal Path Library\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class PathMode:\n",
    "    path: List[Tuple[int, int]]\n",
    "    total_cost: float\n",
    "    score: float\n",
    "    hypothesis_sensor_pos: Tuple[int, int]\n",
    "    hypothesis_mode_idx: int\n",
    "    hypothesis_weight: float\n",
    "    debug_info: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def build_cost_map_from_hypothesis(\n",
    "    world: GridWorld,\n",
    "    detection: \"DetectionModel\",\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    *,\n",
    "    base_step: float,\n",
    "    w_detect: float,\n",
    "    randomize: bool,\n",
    "    rand_scale: float,\n",
    ") -> Callable[[Tuple[int, int]], float]:\n",
    "    def cost_fn(s: Tuple[int, int]) -> float:\n",
    "        if not world.is_free(s):\n",
    "            return float(\"inf\")\n",
    "        p_det = detection.p_detect(robot_pos=s, sensor_pos=sensor_pos)\n",
    "        c = base_step + w_detect * p_det\n",
    "        if randomize:\n",
    "            c *= (1.0 + rand_scale * (random.random() - 0.5))\n",
    "            c = max(1e-6, c)\n",
    "        return c\n",
    "\n",
    "    return cost_fn\n",
    "\n",
    "\n",
    "def cluster_paths_by_signature(paths: List[List[Tuple[int, int]]], *, max_modes: int) -> List[int]:\n",
    "    sig_to_cluster: Dict[str, int] = {}\n",
    "    assignments: List[int] = []\n",
    "\n",
    "    def signature(path: List[Tuple[int, int]]) -> str:\n",
    "        if len(path) < 2:\n",
    "            return \"EMPTY\"\n",
    "        dirs = []\n",
    "        for i in range(1, len(path)):\n",
    "            dr = path[i][0] - path[i - 1][0]\n",
    "            dc = path[i][1] - path[i - 1][1]\n",
    "            dirs.append((dr, dc))\n",
    "\n",
    "        comp = []\n",
    "        for d in dirs:\n",
    "            if not comp or comp[-1] != d:\n",
    "                comp.append(d)\n",
    "\n",
    "        m = {(-1, 0): \"U\", (1, 0): \"D\", (0, -1): \"L\", (0, 1): \"R\", (0, 0): \"S\"}\n",
    "        return \"\".join(m.get(d, \"?\") for d in comp)[:120]\n",
    "\n",
    "    for p in paths:\n",
    "        sig = signature(p)\n",
    "\n",
    "        if sig in sig_to_cluster:\n",
    "            cid = sig_to_cluster[sig]\n",
    "        elif len(sig_to_cluster) < max_modes:\n",
    "            cid = len(sig_to_cluster)\n",
    "            sig_to_cluster[sig] = cid\n",
    "        else:\n",
    "            cid = stable_bucket(sig, len(sig_to_cluster))\n",
    "\n",
    "        assignments.append(cid)\n",
    "\n",
    "    return assignments\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModeLibraryInfo:\n",
    "    num_candidates: int\n",
    "    num_clusters: int\n",
    "\n",
    "\n",
    "def unique_weighted_sample(particles: List[Particle], weights: List[float], k: int) -> List[Particle]:\n",
    "    \"\"\"Approximate weighted sampling without replacement by oversampling then uniquing.\"\"\"\n",
    "    if not particles:\n",
    "        return []\n",
    "    if k <= 0:\n",
    "        return []\n",
    "    oversample = max(k, 3 * k)\n",
    "    picks = random.choices(particles, weights=weights, k=oversample)\n",
    "    seen = set()\n",
    "    out: List[Particle] = []\n",
    "    for p in picks:\n",
    "        key = (p.sensor_pos, p.mode_idx)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append(p)\n",
    "        if len(out) >= k:\n",
    "            break\n",
    "    # If we still don't have k, allow duplicates as a fallback\n",
    "    while len(out) < k:\n",
    "        out.append(random.choices(particles, weights=weights, k=1)[0])\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_multimodal_path_library(\n",
    "    world: GridWorld,\n",
    "    belief: BeliefState,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    detection: DetectionModel,\n",
    "    *,\n",
    "    num_hypotheses: int = 30,\n",
    "    per_hypothesis_attempts: int = 2,\n",
    "    base_step_cost: float = 1.0,\n",
    "    w_detect: float = 8.0,\n",
    "    rand_scale: float = 0.40,\n",
    "    max_modes: int = 6,\n",
    "    plausibility_lambda: float = 3.0,\n",
    "    t: int = 0,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> Tuple[List[PathMode], ModeLibraryInfo]:\n",
    "    if not belief.particles:\n",
    "        return [], ModeLibraryInfo(num_candidates=0, num_clusters=0)\n",
    "\n",
    "    # Sample particles proportional to weight\n",
    "    weights = [p.weight for p in belief.particles]\n",
    "    s = sum(weights)\n",
    "    if s <= 0.0:\n",
    "        weights = [1.0 / len(weights)] * len(weights)\n",
    "    else:\n",
    "        weights = [w / s for w in weights]\n",
    "\n",
    "    # NEW: more diverse sampling\n",
    "    sampled_particles = unique_weighted_sample(belief.particles, weights, k=num_hypotheses)\n",
    "\n",
    "    candidates: List[PathMode] = []\n",
    "\n",
    "    hyp_print_budget = log.cfg.max_hyp_print if (log and log.cfg.level >= 2 and t <= log.cfg.detail_until_t) else 0\n",
    "\n",
    "    for hi, hp in enumerate(sampled_particles):\n",
    "        hyp_sensor = hp.sensor_pos\n",
    "        hyp_mode = hp.mode_idx\n",
    "        hyp_w = float(getattr(hp, \"weight\", 0.0))\n",
    "\n",
    "        if log is not None and hyp_print_budget > 0:\n",
    "            log.log(\n",
    "                f\"[Modes][detail] t={t} hyp#{hi+1}/{num_hypotheses} sensor={hyp_sensor} mode={belief.mode_names[hyp_mode] if 0<=hyp_mode<len(belief.mode_names) else hyp_mode} w={hyp_w:.4f}\",\n",
    "                t=t,\n",
    "                every=None,\n",
    "                lvl=2,\n",
    "            )\n",
    "            hyp_print_budget -= 1\n",
    "\n",
    "        for attempt in range(per_hypothesis_attempts):\n",
    "            cost_fn = build_cost_map_from_hypothesis(\n",
    "                world,\n",
    "                detection,\n",
    "                hyp_sensor,\n",
    "                base_step=base_step_cost,\n",
    "                w_detect=w_detect,\n",
    "                randomize=True,\n",
    "                rand_scale=rand_scale,\n",
    "            )\n",
    "            heur = lambda s: float(manhattan(s, goal))\n",
    "\n",
    "            res = astar_path(world, robot_pos, goal, step_cost=cost_fn, heuristic=heur)\n",
    "            if res is None:\n",
    "                continue\n",
    "\n",
    "            # NEW: plausibility-regularized score\n",
    "            score = float(res.cost) + plausibility_lambda * (-math.log(max(1e-12, hyp_w)))\n",
    "\n",
    "            candidates.append(\n",
    "                PathMode(\n",
    "                    path=res.path,\n",
    "                    total_cost=float(res.cost),\n",
    "                    score=score,\n",
    "                    hypothesis_sensor_pos=hyp_sensor,\n",
    "                    hypothesis_mode_idx=hyp_mode,\n",
    "                    hypothesis_weight=hyp_w,\n",
    "                    debug_info={\"expanded\": res.expanded, \"attempt\": attempt + 1},\n",
    "                )\n",
    "            )\n",
    "\n",
    "    if not candidates:\n",
    "        if log is not None and log._should_print(t, log.cfg.modes_every_t, lvl=1):\n",
    "            log.log(f\"[Modes] t={t} candidates=0 (no paths found)\", t=t, every=log.cfg.modes_every_t, lvl=1)\n",
    "        return [], ModeLibraryInfo(num_candidates=0, num_clusters=0)\n",
    "\n",
    "    def _select_library(cands: List[PathMode]) -> Tuple[List[PathMode], Dict[int, PathMode]]:\n",
    "        cluster_ids = cluster_paths_by_signature([c.path for c in cands], max_modes=max_modes)\n",
    "\n",
    "        # pick best by *score* per cluster\n",
    "        best_by_cluster: Dict[int, PathMode] = {}\n",
    "        for c, cid in zip(cands, cluster_ids):\n",
    "            if cid not in best_by_cluster or c.score < best_by_cluster[cid].score:\n",
    "                best_by_cluster[cid] = c\n",
    "\n",
    "        # sort by score, not raw cost\n",
    "        library = sorted(best_by_cluster.values(), key=lambda pm: pm.score)[:max_modes]\n",
    "        return library, best_by_cluster\n",
    "\n",
    "    library, best_by_cluster = _select_library(candidates)\n",
    "\n",
    "    # DIVERSITY RESCUE: if all kept modes agree on the same first robot action,\n",
    "    # inject additional candidates by forcing alternative first actions, then re-cluster.\n",
    "    kept_a0 = [first_action_from_path(world, robot_pos, pm.path) for pm in library]\n",
    "    distinct_a0 = sorted(set(kept_a0))\n",
    "\n",
    "    if len(library) >= 2 and len(distinct_a0) <= 1:\n",
    "        dom = distinct_a0[0] if distinct_a0 else \"?\"\n",
    "        if log is not None:\n",
    "            log.log(\n",
    "                f\"[ModesRescue][WARN] t={t} all kept paths start with {dom}; attempting forced-first-action rescue\",\n",
    "                t=t,\n",
    "                every=None,\n",
    "                lvl=1,\n",
    "                force=True,\n",
    "            )\n",
    "\n",
    "        # Pick a few high-weight hypotheses (unique (sensor_pos, mode_idx))\n",
    "        uniq: Dict[Tuple[Tuple[int, int], int], Particle] = {}\n",
    "        for hp in sampled_particles:\n",
    "            uniq[(hp.sensor_pos, hp.mode_idx)] = hp\n",
    "        top_hyps = sorted(uniq.values(), key=lambda p: float(getattr(p, \"weight\", 0.0)), reverse=True)\n",
    "        top_hyps = top_hyps[: min(3, len(top_hyps))]\n",
    "\n",
    "        added = 0\n",
    "        for hp in top_hyps:\n",
    "            hyp_sensor = hp.sensor_pos\n",
    "            hyp_mode = hp.mode_idx\n",
    "            hyp_w = float(getattr(hp, \"weight\", 0.0))\n",
    "\n",
    "            # deterministic cost map for rescue (no randomization)\n",
    "            cost_fn = build_cost_map_from_hypothesis(\n",
    "                world,\n",
    "                detection,\n",
    "                hyp_sensor,\n",
    "                base_step=base_step_cost,\n",
    "                w_detect=w_detect,\n",
    "                randomize=False,\n",
    "                rand_scale=0.0,\n",
    "            )\n",
    "            heur = lambda s: float(manhattan(s, goal))\n",
    "\n",
    "            for a0 in ACTIONS:\n",
    "                if a0 == dom:\n",
    "                    continue\n",
    "\n",
    "                nxt0 = world.step(robot_pos, a0)\n",
    "\n",
    "                if a0 == \"S\":\n",
    "                    res2 = astar_path(world, robot_pos, goal, step_cost=cost_fn, heuristic=heur)\n",
    "                    if res2 is None:\n",
    "                        continue\n",
    "                    forced_path = [robot_pos, robot_pos] + res2.path[1:]\n",
    "                    forced_cost = float(cost_fn(robot_pos)) + float(res2.cost)\n",
    "                    expanded = res2.expanded\n",
    "                else:\n",
    "                    res2 = astar_path(world, nxt0, goal, step_cost=cost_fn, heuristic=heur)\n",
    "                    if res2 is None:\n",
    "                        continue\n",
    "                    forced_path = [robot_pos] + res2.path\n",
    "                    forced_cost = float(cost_fn(nxt0)) + float(res2.cost)\n",
    "                    expanded = res2.expanded\n",
    "\n",
    "                score = float(forced_cost) + plausibility_lambda * (-math.log(max(1e-12, hyp_w)))\n",
    "                candidates.append(\n",
    "                    PathMode(\n",
    "                        path=forced_path,\n",
    "                        total_cost=float(forced_cost),\n",
    "                        score=float(score),\n",
    "                        hypothesis_sensor_pos=hyp_sensor,\n",
    "                        hypothesis_mode_idx=hyp_mode,\n",
    "                        hypothesis_weight=hyp_w,\n",
    "                        debug_info={\"expanded\": expanded, \"attempt\": \"rescue\", \"forced_a0\": a0},\n",
    "                    )\n",
    "                )\n",
    "                added += 1\n",
    "\n",
    "        if log is not None:\n",
    "            log.log(\n",
    "                f\"[ModesRescue] t={t} added={added} forced-a0 candidates (excluding {dom})\",\n",
    "                t=t,\n",
    "                every=None,\n",
    "                lvl=1,\n",
    "                force=True,\n",
    "            )\n",
    "\n",
    "        # Re-select after rescue\n",
    "        library, best_by_cluster = _select_library(candidates)\n",
    "        kept2 = sorted(set(first_action_from_path(world, robot_pos, pm.path) for pm in library))\n",
    "        if log is not None:\n",
    "            log.log(\n",
    "                f\"[ModesRescue] t={t} new kept distinct_a0={len(kept2)}({','.join(kept2) if kept2 else '-'})\",\n",
    "                t=t,\n",
    "                every=None,\n",
    "                lvl=1,\n",
    "                force=True,\n",
    "            )\n",
    "\n",
    "    # FINAL DIVERSITY GUARANTEE:\n",
    "    # Even after rescue, clustering/score-sorting can still throw away all non-dominant a0.\n",
    "    # Here we *force* at least 2 distinct first-actions in the kept library whenever possible.\n",
    "    min_diverse_a0 = 2\n",
    "    kept_a0 = [first_action_from_path(world, robot_pos, pm.path) for pm in library]\n",
    "    distinct_a0 = sorted(set(kept_a0))\n",
    "\n",
    "    if library and len(distinct_a0) < min_diverse_a0:\n",
    "        dom = distinct_a0[0] if distinct_a0 else \"S\"\n",
    "        missing = [a for a in ACTIONS if a not in distinct_a0]\n",
    "\n",
    "        # Best candidate for each missing first-action\n",
    "        best_by_missing: Dict[Action, PathMode] = {}\n",
    "        for pm in candidates:\n",
    "            a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "            if a0 in missing:\n",
    "                if (a0 not in best_by_missing) or (pm.score < best_by_missing[a0].score):\n",
    "                    best_by_missing[a0] = pm\n",
    "\n",
    "        if best_by_missing:\n",
    "            inject = min(best_by_missing.values(), key=lambda pm: pm.score)\n",
    "            inject_a0 = first_action_from_path(world, robot_pos, inject.path)\n",
    "\n",
    "            replaced: Optional[PathMode] = None\n",
    "            if len(library) < max_modes:\n",
    "                library.append(inject)\n",
    "            else:\n",
    "                # Prefer replacing a dominant-action entry, otherwise replace worst overall.\n",
    "                dom_idxs = [i for i, pm in enumerate(library) if first_action_from_path(world, robot_pos, pm.path) == dom]\n",
    "                if dom_idxs:\n",
    "                    worst_idx = max(dom_idxs, key=lambda i: library[i].score)\n",
    "                else:\n",
    "                    worst_idx = max(range(len(library)), key=lambda i: library[i].score)\n",
    "                replaced = library[worst_idx]\n",
    "                library[worst_idx] = inject\n",
    "\n",
    "            library = sorted(library, key=lambda pm: pm.score)[:max_modes]\n",
    "            distinct2 = sorted(set(first_action_from_path(world, robot_pos, pm.path) for pm in library))\n",
    "\n",
    "            if log is not None:\n",
    "                if replaced is None:\n",
    "                    log.log(\n",
    "                        f\"[ModesRescue][FORCE] t={t} appended a0={inject_a0} score={inject.score:.2f} -> distinct_a0={len(distinct2)}({','.join(distinct2)})\",\n",
    "                        t=t,\n",
    "                        every=None,\n",
    "                        lvl=1,\n",
    "                        force=True,\n",
    "                    )\n",
    "                else:\n",
    "                    rep_a0 = first_action_from_path(world, robot_pos, replaced.path)\n",
    "                    log.log(\n",
    "                        f\"[ModesRescue][FORCE] t={t} replaced a0={rep_a0} score={replaced.score:.2f} with a0={inject_a0} score={inject.score:.2f} -> distinct_a0={len(distinct2)}({','.join(distinct2)})\",\n",
    "                        t=t,\n",
    "                        every=None,\n",
    "                        lvl=1,\n",
    "                        force=True,\n",
    "                    )\n",
    "        else:\n",
    "            if log is not None:\n",
    "                log.log(\n",
    "                    f\"[ModesRescue][FORCE][FAIL] t={t} no viable non-{dom} candidates found; keeping degenerate a0\",\n",
    "                    t=t,\n",
    "                    every=None,\n",
    "                    lvl=1,\n",
    "                    force=True,\n",
    "                )\n",
    "\n",
    "    if log is not None and log._should_print(t, log.cfg.modes_every_t, lvl=1):\n",
    "        best = \", \".join(\n",
    "            f\"{belief.mode_names[pm.hypothesis_mode_idx] if 0<=pm.hypothesis_mode_idx<len(belief.mode_names) else pm.hypothesis_mode_idx}:\"\n",
    "            f\"w={pm.hypothesis_weight:.3f},cost={pm.total_cost:.1f},score={pm.score:.1f}\"\n",
    "            for pm in library[:min(3, len(library))]\n",
    "        )\n",
    "        log.log(\n",
    "            f\"[Modes] t={t} candidates={len(candidates)} clusters={len(best_by_cluster)} kept={len(library)} | top3: {best}\",\n",
    "            t=t,\n",
    "            every=log.cfg.modes_every_t,\n",
    "            lvl=1,\n",
    "        )\n",
    "\n",
    "        if log.cfg.level >= 2 and t <= log.cfg.detail_until_t:\n",
    "            for i, pm in enumerate(library):\n",
    "                a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "                mname = belief.mode_names[pm.hypothesis_mode_idx] if 0 <= pm.hypothesis_mode_idx < len(belief.mode_names) else str(pm.hypothesis_mode_idx)\n",
    "                log.log(\n",
    "                    f\"[ModesKept] t={t} #{i+1} mode={mname} hypS={pm.hypothesis_sensor_pos} a0={a0} w={pm.hypothesis_weight:.4f} cost={pm.total_cost:.2f} score={pm.score:.2f}\",\n",
    "                    t=t,\n",
    "                    every=None,\n",
    "                    lvl=2,\n",
    "                )\n",
    "\n",
    "    return library, ModeLibraryInfo(num_candidates=len(candidates), num_clusters=len(best_by_cluster))\n",
    "\n",
    "\n",
    "def first_action_from_path(world: GridWorld, start: Tuple[int, int], path: List[Tuple[int, int]]) -> Action:\n",
    "    if len(path) < 2:\n",
    "        return \"S\"\n",
    "    nxt = path[1]\n",
    "    dr = nxt[0] - start[0]\n",
    "    dc = nxt[1] - start[1]\n",
    "    for a, (adr, adc) in ACTION_DELTAS.items():\n",
    "        if (dr, dc) == (adr, adc):\n",
    "            return a\n",
    "    return \"S\"\n",
    "\n",
    "\n",
    "def build_action_prior_from_library(\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    library: List[PathMode],\n",
    "    *,\n",
    "    temp: float = 25.0,\n",
    ") -> Dict[Action, float]:\n",
    "    \"\"\"Mixture prior over kept modes: weight = hyp_weight * exp(-cost/temp).\"\"\"\n",
    "    if not library:\n",
    "        return {a: 1.0 / len(ACTIONS) for a in ACTIONS}\n",
    "\n",
    "    pri_raw: Dict[Action, float] = defaultdict(float)\n",
    "    for pm in library:\n",
    "        a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "        w = max(1e-12, pm.hypothesis_weight)\n",
    "        w *= math.exp(-pm.total_cost / max(1e-6, temp))\n",
    "        pri_raw[a0] += w\n",
    "\n",
    "    return normalize_probs_dict(pri_raw, ACTIONS)\n",
    "\n",
    "\n",
    "def prior_entropy(prior: Dict[Action, float]) -> float:\n",
    "    ent = 0.0\n",
    "    for a in ACTIONS:\n",
    "        p = float(prior.get(a, 0.0))\n",
    "        if p > 1e-12:\n",
    "            ent -= p * math.log(p)\n",
    "    return ent\n",
    "\n",
    "\n",
    "def prior_diagnostics(prior: Dict[Action, float]) -> str:\n",
    "    ent = prior_entropy(prior)\n",
    "    return f\"H={ent:.3f} top={topk_str(prior, k=3)}\"\n",
    "\n",
    "\n",
    "def prior_check_and_log(\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    library: List[PathMode],\n",
    "    raw_prior: Dict[Action, float],\n",
    "    smoothed_prior: Dict[Action, float],\n",
    "    *,\n",
    "    temp: float,\n",
    "    eps: float,\n",
    "    mode_names: List[str],\n",
    "    warn_maxp: float,\n",
    "    warn_minH: float,\n",
    "    t: int,\n",
    "    log: Optional[Logger],\n",
    ") -> None:\n",
    "    \"\"\"Warn when the library induces a near-delta prior.\n",
    "\n",
    "    When it triggers, we print *why* (first-action mass + kept-mode breakdown), so you can\n",
    "    tell whether it's a real collapse or just a legitimately one-sided situation.\n",
    "    \"\"\"\n",
    "    if log is None or not log.cfg.enabled:\n",
    "        return\n",
    "    if not library:\n",
    "        return\n",
    "\n",
    "    kept_a0: List[Action] = [first_action_from_path(world, robot_pos, pm.path) for pm in library]\n",
    "    distinct_a0 = sorted(set(kept_a0))\n",
    "\n",
    "    rawH = prior_entropy(raw_prior)\n",
    "    rawMax = max(float(raw_prior.get(a, 0.0)) for a in ACTIONS)\n",
    "    smH = prior_entropy(smoothed_prior)\n",
    "    smMax = max(float(smoothed_prior.get(a, 0.0)) for a in ACTIONS)\n",
    "\n",
    "    warn = False\n",
    "    if len(library) >= 2 and len(distinct_a0) <= 1:\n",
    "        warn = True\n",
    "    if rawMax >= warn_maxp:\n",
    "        warn = True\n",
    "    if rawH <= warn_minH:\n",
    "        warn = True\n",
    "\n",
    "    if not warn:\n",
    "        return\n",
    "\n",
    "    log.log(\n",
    "        f\"[PriorCheck][WARN] t={t} kept={len(library)} distinct_a0={len(distinct_a0)}({','.join(distinct_a0) if distinct_a0 else '-'}) \"\n",
    "        f\"rawH={rawH:.3f} rawMax={rawMax:.3f} | eps={eps:.2f} smH={smH:.3f} smMax={smMax:.3f}\",\n",
    "        t=t,\n",
    "        every=None,\n",
    "        lvl=1,\n",
    "        force=True,\n",
    "    )\n",
    "    log.log(f\"[PriorDiagRaw] {prior_diagnostics(raw_prior)}\", t=t, every=None, lvl=1, force=True)\n",
    "    log.log(f\"[PriorDiagSm]  eps={eps:.2f} {prior_diagnostics(smoothed_prior)}\", t=t, every=None, lvl=1, force=True)\n",
    "\n",
    "    mix_by_a: Dict[Action, float] = defaultdict(float)\n",
    "    for pm in library:\n",
    "        a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "        mix_w = max(1e-12, pm.hypothesis_weight) * math.exp(-pm.total_cost / max(1e-6, temp))\n",
    "        mix_by_a[a0] += mix_w\n",
    "\n",
    "    mix_norm = normalize_probs_dict(mix_by_a, ACTIONS)\n",
    "    log.log(f\"[PriorCheck] mix_mass(raw): {topk_str(mix_by_a, k=5, fmt='{k}:{v:.3g}')}\", t=t, every=None, lvl=1, force=True)\n",
    "    log.log(f\"[PriorCheck] mix_mass(nrm): {topk_str(mix_norm, k=5)}\", t=t, every=None, lvl=1, force=True)\n",
    "\n",
    "    for i, pm in enumerate(library, start=1):\n",
    "        a0 = first_action_from_path(world, robot_pos, pm.path)\n",
    "        mname = mode_names[pm.hypothesis_mode_idx] if 0 <= pm.hypothesis_mode_idx < len(mode_names) else str(pm.hypothesis_mode_idx)\n",
    "        mix_w = max(1e-12, pm.hypothesis_weight) * math.exp(-pm.total_cost / max(1e-6, temp))\n",
    "        log.log(\n",
    "            f\"[PriorCheck][Kept] t={t} #{i} a0={a0} mix_w={mix_w:.3g} mode={mname} hypS={pm.hypothesis_sensor_pos} \"\n",
    "            f\"hyp_w={pm.hypothesis_weight:.4f} cost={pm.total_cost:.2f} score={pm.score:.2f}\",\n",
    "            t=t,\n",
    "            every=None,\n",
    "            lvl=1,\n",
    "            force=True,\n",
    "        )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# GenBR-lite: Belief-space MCTS with PUCT\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class MCTSNode:\n",
    "    robot_pos: Tuple[int, int]\n",
    "    depth: int\n",
    "\n",
    "    N: int = 0\n",
    "    N_a: Dict[Action, int] = field(default_factory=lambda: {a: 0 for a in ACTIONS})\n",
    "    W_a: Dict[Action, float] = field(default_factory=lambda: {a: 0.0 for a in ACTIONS})\n",
    "    Q_a: Dict[Action, float] = field(default_factory=lambda: {a: 0.0 for a in ACTIONS})\n",
    "\n",
    "    P_a: Dict[Action, float] = field(default_factory=lambda: {a: 1.0 / len(ACTIONS) for a in ACTIONS})\n",
    "\n",
    "    children: Dict[Action, \"MCTSNode\"] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def select_action_puct(node: MCTSNode, *, c_puct: float) -> Action:\n",
    "    \"\"\"PUCT: argmax_a Q + c*P*sqrt(N)/(1+N_a). Uses node.P_a.\"\"\"\n",
    "    sqrtN = math.sqrt(max(1, node.N))\n",
    "\n",
    "    best_a: Optional[Action] = None\n",
    "    best_score = -1e18\n",
    "\n",
    "    for a in ACTIONS:\n",
    "        q = node.Q_a[a]\n",
    "        u = c_puct * node.P_a[a] * sqrtN / (1.0 + node.N_a[a])\n",
    "        score = q + u + random.uniform(-1e-9, 1e-9)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_a = a\n",
    "\n",
    "    assert best_a is not None\n",
    "    return best_a\n",
    "\n",
    "\n",
    "def backprop_path(path: List[Tuple[MCTSNode, Action]], value: float) -> None:\n",
    "    for node, a in reversed(path):\n",
    "        node.N += 1\n",
    "        node.N_a[a] += 1\n",
    "        node.W_a[a] += value\n",
    "        node.Q_a[a] = node.W_a[a] / node.N_a[a]\n",
    "\n",
    "\n",
    "def choose_final_action(root: MCTSNode) -> Action:\n",
    "    maxN = max(root.N_a.values())\n",
    "    cand = [a for a in ACTIONS if root.N_a[a] == maxN]\n",
    "    if len(cand) == 1:\n",
    "        return cand[0]\n",
    "\n",
    "    maxQ = max(root.Q_a[a] for a in cand)\n",
    "    cand2 = [a for a in cand if abs(root.Q_a[a] - maxQ) < 1e-12]\n",
    "    if len(cand2) == 1:\n",
    "        return cand2[0]\n",
    "\n",
    "    maxP = max(root.P_a[a] for a in cand2)\n",
    "    cand3 = [a for a in cand2 if abs(root.P_a[a] - maxP) < 1e-12]\n",
    "    return random.choice(cand3)\n",
    "\n",
    "\n",
    "def rollout_value(\n",
    "    world: GridWorld,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    detection: DetectionModel,\n",
    "    *,\n",
    "    max_steps: int,\n",
    "    w_step: float,\n",
    "    w_detect: float,\n",
    ") -> float:\n",
    "    total_cost = 0.0\n",
    "    cur = robot_pos\n",
    "    for _ in range(max_steps):\n",
    "        if cur == goal:\n",
    "            break\n",
    "        a = deterministic_greedy_step_toward(world, cur, goal)\n",
    "        cur = world.step(cur, a)\n",
    "        total_cost += w_step\n",
    "        total_cost += w_detect * detection.p_detect(cur, sensor_pos)\n",
    "    if cur == goal:\n",
    "        total_cost -= 20.0\n",
    "    return -total_cost\n",
    "\n",
    "\n",
    "def simulate_sensor_step(\n",
    "    world: GridWorld,\n",
    "    sensor_pos: Tuple[int, int],\n",
    "    robot_pos: Tuple[int, int],\n",
    "    t: int,\n",
    "    mode_idx: int,\n",
    "    policies: List[SensorModePolicy],\n",
    ") -> Tuple[int, int]:\n",
    "    if 0 <= mode_idx < len(policies):\n",
    "        aS = policies[mode_idx].action(world, sensor_pos, robot_pos, t)\n",
    "        return world.step(sensor_pos, aS)\n",
    "    return sensor_pos\n",
    "\n",
    "\n",
    "def mcts_search_action(\n",
    "    world: GridWorld,\n",
    "    belief: BeliefState,\n",
    "    robot_pos: Tuple[int, int],\n",
    "    goal: Tuple[int, int],\n",
    "    sensor_policies: List[SensorModePolicy],\n",
    "    detection: DetectionModel,\n",
    "    action_prior: Dict[Action, float],\n",
    "    *,\n",
    "    t: int,\n",
    "    num_sims: int = 250,\n",
    "    max_depth: int = 10,\n",
    "    c_puct: float = 1.4,\n",
    "    w_step: float = 1.0,\n",
    "    w_detect: float = 7.0,\n",
    "    gamma: float = 0.95,\n",
    "    prior_eps: float = 0.10,\n",
    "    log: Optional[Logger] = None,\n",
    ") -> Action:\n",
    "    prior = normalize_probs_dict(action_prior, ACTIONS, eps=prior_eps)\n",
    "\n",
    "    root = MCTSNode(robot_pos=robot_pos, depth=0)\n",
    "    root.P_a = prior\n",
    "\n",
    "    # Prepare particle sampling distribution\n",
    "    particles = belief.particles if belief.particles else [Particle(sensor_pos=robot_pos, mode_idx=0, weight=1.0)]\n",
    "    weights = [float(getattr(p, \"weight\", 1.0)) for p in particles]\n",
    "    s = sum(weights)\n",
    "    if s <= 0.0:\n",
    "        weights = [1.0 / len(weights)] * len(weights)\n",
    "    else:\n",
    "        weights = [w / s for w in weights]\n",
    "\n",
    "    if log is not None and (log._should_print(t, log.cfg.mcts_every_t, lvl=1)):\n",
    "        log.log(f\"[MCTS] t={t} sims={num_sims} depth={max_depth} prior: {prior_diagnostics(prior)}\", t=t, every=log.cfg.mcts_every_t, lvl=1)\n",
    "\n",
    "    for sim in range(num_sims):\n",
    "        hp = random.choices(particles, weights=weights, k=1)[0]\n",
    "        sim_sensor = hp.sensor_pos\n",
    "        sim_mode = hp.mode_idx\n",
    "\n",
    "        node = root\n",
    "        cur_robot = robot_pos\n",
    "        cur_sensor = sim_sensor\n",
    "\n",
    "        path: List[Tuple[MCTSNode, Action]] = []\n",
    "        total_return = 0.0\n",
    "        disc = 1.0\n",
    "\n",
    "        if cur_robot == goal:\n",
    "            root.N += 1\n",
    "            continue\n",
    "\n",
    "        for depth in range(max_depth):\n",
    "            if cur_robot == goal:\n",
    "                total_return += disc * 50.0\n",
    "                break\n",
    "\n",
    "            a = select_action_puct(node, c_puct=c_puct)\n",
    "            path.append((node, a))\n",
    "\n",
    "            nxt_robot = world.step(cur_robot, a)\n",
    "            nxt_sensor = simulate_sensor_step(world, cur_sensor, nxt_robot, t + depth, sim_mode, sensor_policies)\n",
    "\n",
    "            step_cost = w_step + w_detect * detection.p_detect(nxt_robot, nxt_sensor)\n",
    "            total_return += disc * (-step_cost)\n",
    "            disc *= gamma\n",
    "\n",
    "            if a not in node.children:\n",
    "                child = MCTSNode(robot_pos=nxt_robot, depth=node.depth + 1)\n",
    "                child.P_a = prior\n",
    "                node.children[a] = child\n",
    "\n",
    "                leaf_v = rollout_value(\n",
    "                    world,\n",
    "                    nxt_robot,\n",
    "                    nxt_sensor,\n",
    "                    goal,\n",
    "                    detection,\n",
    "                    max_steps=max_depth - depth - 1,\n",
    "                    w_step=w_step,\n",
    "                    w_detect=w_detect,\n",
    "                )\n",
    "                total_return += disc * leaf_v\n",
    "                break\n",
    "\n",
    "            node = node.children[a]\n",
    "            cur_robot, cur_sensor = nxt_robot, nxt_sensor\n",
    "\n",
    "        if path:\n",
    "            backprop_path(path, total_return)\n",
    "        else:\n",
    "            root.N += 1\n",
    "\n",
    "        if log is not None and log.cfg.level >= 2 and (sim < 2 or ((sim + 1) % log.cfg.mcts_progress_every_sims == 0 and t <= log.cfg.detail_until_t)):\n",
    "            log.log(f\"[MCTS][detail] t={t} sim={sim+1}/{num_sims} root.N={root.N}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    total_edge_visits = sum(root.N_a.values())\n",
    "    if log is not None and log._should_print(t, log.cfg.mcts_every_t, lvl=1):\n",
    "        bestN = max(root.N_a, key=lambda a: root.N_a[a])\n",
    "        log.log(\n",
    "            f\"[MCTS] t={t} root.N={root.N} sum(N_a)={total_edge_visits} best_by_N={bestN}\",\n",
    "            t=t,\n",
    "            every=log.cfg.mcts_every_t,\n",
    "            lvl=1,\n",
    "        )\n",
    "        if log.cfg.level >= 2 and t <= log.cfg.detail_until_t:\n",
    "            for a in ACTIONS:\n",
    "                log.log(f\"[MCTS][detail] a={a} N={root.N_a[a]:4d} Q={root.Q_a[a]:+8.3f} P={root.P_a[a]:.3f}\", t=t, every=None, lvl=2)\n",
    "\n",
    "    return choose_final_action(root)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Run-wide plots (\"what happened in the whole game\")\n",
    "# =========================\n",
    "\n",
    "# NOTE: Uses matplotlib, but you only need it for plotting.\n",
    "# If you don't have it: pip install matplotlib\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RunHistory:\n",
    "    mode_names: List[str]\n",
    "    t: List[int] = field(default_factory=list)\n",
    "\n",
    "    # positions\n",
    "    robot_r: List[int] = field(default_factory=list)\n",
    "    robot_c: List[int] = field(default_factory=list)\n",
    "    sensor_r: List[int] = field(default_factory=list)\n",
    "    sensor_c: List[int] = field(default_factory=list)\n",
    "\n",
    "    # observation\n",
    "    obs_r: List[int] = field(default_factory=list)\n",
    "    obs_c: List[int] = field(default_factory=list)\n",
    "\n",
    "    # core signals\n",
    "    dist_RS: List[int] = field(default_factory=list)\n",
    "    p_detect: List[float] = field(default_factory=list)\n",
    "\n",
    "    # event flags\n",
    "    caught: List[int] = field(default_factory=list)\n",
    "\n",
    "    # belief over modes (posterior mass each mode)\n",
    "    mode_post: Dict[str, List[float]] = field(default_factory=dict)\n",
    "\n",
    "    # action prior and chosen action\n",
    "    prior_by_a: Dict[Action, List[float]] = field(default_factory=dict)\n",
    "    chosen_action: List[Action] = field(default_factory=list)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.mode_post = {m: [] for m in self.mode_names}\n",
    "        self.prior_by_a = {a: [] for a in ACTIONS}\n",
    "\n",
    "    def add(\n",
    "        self,\n",
    "        *,\n",
    "        t: int,\n",
    "        robot_pos: Tuple[int, int],\n",
    "        sensor_pos: Tuple[int, int],\n",
    "        goal: Tuple[int, int],\n",
    "        obs: Tuple[int, int],\n",
    "        mode_post: Dict[str, float],\n",
    "        action_prior: Dict[Action, float],\n",
    "        chosen_action: Action,\n",
    "        p_detect: float,\n",
    "        dist_RS: int,\n",
    "        caught: bool,\n",
    "    ) -> None:\n",
    "        self.t.append(int(t))\n",
    "        self.robot_r.append(int(robot_pos[0])); self.robot_c.append(int(robot_pos[1]))\n",
    "        self.sensor_r.append(int(sensor_pos[0])); self.sensor_c.append(int(sensor_pos[1]))\n",
    "        self.obs_r.append(int(obs[0])); self.obs_c.append(int(obs[1]))\n",
    "\n",
    "        self.dist_RS.append(int(dist_RS))\n",
    "        self.p_detect.append(float(p_detect))\n",
    "        self.caught.append(1 if caught else 0)\n",
    "\n",
    "        for m in self.mode_names:\n",
    "            self.mode_post[m].append(float(mode_post.get(m, 0.0)))\n",
    "\n",
    "        for a in ACTIONS:\n",
    "            self.prior_by_a[a].append(float(action_prior.get(a, 0.0)))\n",
    "\n",
    "        self.chosen_action.append(chosen_action)\n",
    "\n",
    "\n",
    "def make_artifact_dir(seed: int) -> str:\n",
    "    out_dir = os.path.join(\"artifacts\", f\"run_seed_{seed}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    return out_dir\n",
    "\n",
    "\n",
    "def _savefig(path: str) -> None:\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_whole_game_plots(out_dir: str, hist: RunHistory, detection: DetectionModel) -> None:\n",
    "    if not hist.t:\n",
    "        return\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Plot 1: \"How dangerous was it over time?\"  (p_detect + distance)\n",
    "    # ------------------------------------------------------------------\n",
    "    plt.figure(figsize=(10.5, 4.5))\n",
    "    plt.plot(hist.t, hist.p_detect, label=\"p_detect(robot | sensor)\", linewidth=2)\n",
    "    plt.plot(hist.t, hist.dist_RS, label=\"Manhattan distance d(R,S)\")\n",
    "\n",
    "    # Mark caught timesteps (if any)\n",
    "    for i, t in enumerate(hist.t):\n",
    "        if hist.caught[i]:\n",
    "            plt.axvline(t, linestyle=\"--\", linewidth=1.5, label=\"caught timestep\" if i == 0 else None)\n",
    "\n",
    "    plt.axhline(y=detection.p_close, linestyle=\":\", linewidth=1, label=\"p_close\")\n",
    "    plt.axhline(y=detection.p_far, linestyle=\":\", linewidth=1, label=\"p_far\")\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"risk\")\n",
    "    plt.title(\"Risk timeline: detection probability and robotsensor distance\")\n",
    "    plt.legend()\n",
    "    _savefig(os.path.join(out_dir, \"01_risk_timeline.png\"))\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Plot 2: \"What did we believe the sensor was doing?\" (mode posterior)\n",
    "    # stacked area = sums to 1, easy to see dominance shifts\n",
    "    # ------------------------------------------------------------------\n",
    "    plt.figure(figsize=(10.5, 4.5))\n",
    "    ys = [hist.mode_post[m] for m in hist.mode_names]\n",
    "    plt.stackplot(hist.t, *ys, labels=hist.mode_names)\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"posterior mass\")\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.title(\"Belief over sensor modes (particle filter posterior)\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    _savefig(os.path.join(out_dir, \"02_mode_posterior_stack.png\"))\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Plot 3: \"What was the planner leaning toward?\" (action prior + chosen)\n",
    "    # Show prior curves and put a dot on the action we actually took.\n",
    "    # ------------------------------------------------------------------\n",
    "    plt.figure(figsize=(10.5, 4.5))\n",
    "    for a in ACTIONS:\n",
    "        plt.plot(hist.t, hist.prior_by_a[a], label=f\"prior({a})\")\n",
    "\n",
    "    # Overlay chosen actions as markers at their prior value\n",
    "    for i, t in enumerate(hist.t):\n",
    "        a = hist.chosen_action[i]\n",
    "        y = hist.prior_by_a[a][i]\n",
    "        plt.scatter([t], [y], marker=\"o\", s=40, label=\"chosen action\" if i == 0 else None)\n",
    "\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"probability\")\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.title(\"Robot action prior over time (and the action actually selected)\")\n",
    "    plt.legend(ncol=3)\n",
    "    _savefig(os.path.join(out_dir, \"03_action_prior_and_choice.png\"))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Main Simulation\n",
    "# =========================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    seed: int = 8\n",
    "\n",
    "    H: int = 12\n",
    "    W: int = 18\n",
    "    T: int = 40\n",
    "\n",
    "    num_particles: int = 250\n",
    "\n",
    "    # PF\n",
    "    motion_noise: float = 0.15\n",
    "    resample_threshold: float = 0.55\n",
    "\n",
    "    # Mode library\n",
    "    num_hypotheses: int = 25\n",
    "    per_hypothesis_attempts: int = 2\n",
    "    max_modes: int = 6\n",
    "    w_detect_astar: float = 10.0\n",
    "    rand_scale: float = 0.45\n",
    "\n",
    "    # NEW: plausibility-vs-cost tradeoff\n",
    "    plausibility_lambda: float = 3.0\n",
    "\n",
    "    # NEW: prior temperature\n",
    "    prior_temp: float = 25.0\n",
    "\n",
    "    # Prior smoothing/diagnostics (helps catch \"prior collapse\" from the mode library)\n",
    "    prior_eps_main: float = 0.15\n",
    "    prior_warn_maxp: float = 0.97\n",
    "    prior_warn_minH: float = 0.05\n",
    "\n",
    "    # MCTS\n",
    "    num_sims: int = 250\n",
    "    max_depth: int = 10\n",
    "    c_puct: float = 1.4\n",
    "    w_step_mcts: float = 1.0\n",
    "    w_detect_mcts: float = 7.0\n",
    "\n",
    "    # NEW: force a specific true mode for reproducibility\n",
    "    true_mode_name: Optional[str] = \"chase_robot\"  # set None for random\n",
    "\n",
    "    # Debug\n",
    "    debug: DebugConfig = field(default_factory=DebugConfig)\n",
    "\n",
    "\n",
    "def make_demo_world(cfg: Config) -> Tuple[GridWorld, Tuple[int, int], Tuple[int, int], Tuple[int, int]]:\n",
    "    obs = set()\n",
    "    for c in range(3, 15):\n",
    "        obs.add((5, c))\n",
    "    for r in range(1, 9):\n",
    "        obs.add((r, 9))\n",
    "    obs.discard((5, 7))\n",
    "    obs.discard((6, 9))\n",
    "\n",
    "    world = GridWorld(H=cfg.H, W=cfg.W, obstacles=obs)\n",
    "    robot_start = (10, 2)\n",
    "    goal = (1, 16)\n",
    "    sensor_start = (2, 2)\n",
    "    return world, robot_start, sensor_start, goal\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    cfg = Config()\n",
    "    seed_all(cfg.seed)\n",
    "\n",
    "    log = Logger(cfg.debug)\n",
    "\n",
    "    world, robot_pos, sensor_pos, goal = make_demo_world(cfg)\n",
    "\n",
    "    sensor_modes: List[SensorModePolicy] = [\n",
    "        PatrolLoopPolicy(name=\"patrol_left\", loop=[(2, 2), (2, 6), (4, 6), (4, 2)]),\n",
    "        PatrolLoopPolicy(name=\"patrol_mid\", loop=[(2, 10), (2, 13), (4, 13), (4, 10)]),\n",
    "        ChasePolicy(name=\"chase_robot\"),\n",
    "        RandomWalkPolicy(name=\"random_walk\"),\n",
    "    ]\n",
    "    mode_names = [m.name for m in sensor_modes]\n",
    "\n",
    "    # Deterministic true mode option\n",
    "    if cfg.true_mode_name is None:\n",
    "        true_mode_idx = random.randrange(len(sensor_modes))\n",
    "    else:\n",
    "        try:\n",
    "            true_mode_idx = mode_names.index(cfg.true_mode_name)\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"true_mode_name={cfg.true_mode_name!r} not in modes {mode_names}\")\n",
    "\n",
    "    detection = DetectionModel()\n",
    "    obs_model = ObservationModel(sigma=1.3)\n",
    "\n",
    "    sensor_init_candidates = [(2, 2), (2, 10), (3, 3), (3, 9), (1, 1)]\n",
    "    mode_prior = [1.0] * len(sensor_modes)\n",
    "    belief = initialize_belief(world, sensor_init_candidates, mode_prior, mode_names, cfg.num_particles)\n",
    "\n",
    "    # ----------------------\n",
    "    # NEW: Run-wide history\n",
    "    # (these graphs tell you what is happening in the whole game)\n",
    "    # ----------------------\n",
    "    hist = RunHistory(mode_names=mode_names)\n",
    "\n",
    "    log.log(f\"[INIT] true_mode={mode_names[true_mode_idx]} robot={robot_pos} sensor={sensor_pos} goal={goal}\", force=True)\n",
    "    log.log(f\"[INIT] belief modes: {topk_str(belief.mode_posterior_named(), k=4)}\", force=True)\n",
    "\n",
    "    # Save plots even if we terminate early\n",
    "    try:\n",
    "        for t in range(cfg.T):\n",
    "            show_header = (t <= cfg.debug.detail_until_t) or (\n",
    "                cfg.debug.enabled and cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0\n",
    "            )\n",
    "            if show_header:\n",
    "                log.log(\"=\" * 80, force=True)\n",
    "                log.log(f\"[TIME] t={t}\", force=True)\n",
    "\n",
    "            if cfg.debug.enabled and (\n",
    "                t <= cfg.debug.detail_until_t or (cfg.debug.render_every_t > 0 and t % cfg.debug.render_every_t == 0)\n",
    "            ):\n",
    "                log.log(\"[WORLD]\", t=t, every=cfg.debug.render_every_t, lvl=1, force=(t <= cfg.debug.detail_until_t))\n",
    "                world.render(robot=robot_pos, sensor=sensor_pos, goal=goal)\n",
    "\n",
    "            # ----------------------\n",
    "            # 1) Noisy observation\n",
    "            # ----------------------\n",
    "            obs = obs_model.sample_observation(sensor_pos, world)\n",
    "            if cfg.debug.enabled and (\n",
    "                t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)\n",
    "            ):\n",
    "                log.log(f\"[OBS] obs={obs} (true sensor={sensor_pos})\", force=True)\n",
    "\n",
    "            # ----------------------\n",
    "            # 2) PF belief update\n",
    "            # ----------------------\n",
    "            _ = belief_predict_update(\n",
    "                belief,\n",
    "                world,\n",
    "                robot_pos,\n",
    "                sensor_modes,\n",
    "                obs_model,\n",
    "                obs,\n",
    "                t,\n",
    "                motion_noise=cfg.motion_noise,\n",
    "                resample_threshold=cfg.resample_threshold,\n",
    "                log=log,\n",
    "            )\n",
    "\n",
    "            # ----------------------\n",
    "            # 3) Mode/path library -> action prior\n",
    "            # ----------------------\n",
    "            library, _ = build_multimodal_path_library(\n",
    "                world,\n",
    "                belief,\n",
    "                robot_pos,\n",
    "                goal,\n",
    "                detection,\n",
    "                num_hypotheses=cfg.num_hypotheses,\n",
    "                per_hypothesis_attempts=cfg.per_hypothesis_attempts,\n",
    "                w_detect=cfg.w_detect_astar,\n",
    "                rand_scale=cfg.rand_scale,\n",
    "                max_modes=cfg.max_modes,\n",
    "                plausibility_lambda=cfg.plausibility_lambda,\n",
    "                t=t,\n",
    "                log=log,\n",
    "            )\n",
    "\n",
    "            raw_prior = build_action_prior_from_library(world, robot_pos, library, temp=cfg.prior_temp)\n",
    "            action_prior = normalize_probs_dict(raw_prior, ACTIONS, eps=cfg.prior_eps_main)\n",
    "\n",
    "            prior_check_and_log(\n",
    "                world,\n",
    "                robot_pos,\n",
    "                library,\n",
    "                raw_prior,\n",
    "                action_prior,\n",
    "                temp=cfg.prior_temp,\n",
    "                eps=cfg.prior_eps_main,\n",
    "                mode_names=belief.mode_names,\n",
    "                warn_maxp=cfg.prior_warn_maxp,\n",
    "                warn_minH=cfg.prior_warn_minH,\n",
    "                t=t,\n",
    "                log=log,\n",
    "            )\n",
    "\n",
    "            if cfg.debug.enabled and (\n",
    "                t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)\n",
    "            ):\n",
    "                log.log(f\"[PriorDiag] eps={cfg.prior_eps_main:.2f} {prior_diagnostics(action_prior)}\", force=True)\n",
    "\n",
    "            # ----------------------\n",
    "            # 4) MCTS chooses robot action\n",
    "            # ----------------------\n",
    "            aR = mcts_search_action(\n",
    "                world,\n",
    "                belief,\n",
    "                robot_pos,\n",
    "                goal,\n",
    "                sensor_modes,\n",
    "                detection,\n",
    "                action_prior,\n",
    "                t=t,\n",
    "                num_sims=cfg.num_sims,\n",
    "                max_depth=cfg.max_depth,\n",
    "                c_puct=cfg.c_puct,\n",
    "                w_step=cfg.w_step_mcts,\n",
    "                w_detect=cfg.w_detect_mcts,\n",
    "                prior_eps=0.0,\n",
    "                log=log,\n",
    "            )\n",
    "\n",
    "            if cfg.debug.enabled and (\n",
    "                t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)\n",
    "            ):\n",
    "                log.log(f\"[ACT] robot aR={aR}\", force=True)\n",
    "\n",
    "            # ----------------------\n",
    "            # 5) Step the real world (robot then true sensor)\n",
    "            # ----------------------\n",
    "            new_robot = world.step(robot_pos, aR)\n",
    "            aS_true = sensor_modes[true_mode_idx].action(world, sensor_pos, new_robot, t)\n",
    "\n",
    "            if mode_names[true_mode_idx] == \"chase_robot\":\n",
    "                chase_sanity_check(world, sensor_pos, new_robot, aS_true, log=log, t=t, tag=\"true\")\n",
    "\n",
    "            new_sensor = world.step(sensor_pos, aS_true)\n",
    "            robot_pos, sensor_pos = new_robot, new_sensor\n",
    "\n",
    "            # ----------------------\n",
    "            # 6) Detection event\n",
    "            # ----------------------\n",
    "            dist = manhattan(robot_pos, sensor_pos)\n",
    "            p_det = detection.p_detect(robot_pos, sensor_pos)\n",
    "            detected = (random.random() < p_det)\n",
    "\n",
    "            if cfg.debug.enabled and (\n",
    "                t <= cfg.debug.detail_until_t or (cfg.debug.summary_every_t > 0 and t % cfg.debug.summary_every_t == 0)\n",
    "            ):\n",
    "                log.log(\n",
    "                    f\"[STEP] robot={robot_pos} sensor={sensor_pos} aS={aS_true} d={dist} p_det={p_det:.3f} detected={detected}\",\n",
    "                    force=True,\n",
    "                )\n",
    "\n",
    "            # ----------------------\n",
    "            # NEW: Record everything we need for \"whole game\" plots\n",
    "            # ----------------------\n",
    "            hist.add(\n",
    "                t=t,\n",
    "                robot_pos=robot_pos,\n",
    "                sensor_pos=sensor_pos,\n",
    "                goal=goal,\n",
    "                obs=obs,\n",
    "                mode_post=belief.mode_posterior_named(),\n",
    "                action_prior=action_prior,\n",
    "                chosen_action=aR,\n",
    "                p_detect=p_det,\n",
    "                dist_RS=dist,\n",
    "                caught=(detected and dist <= detection.d0),\n",
    "            )\n",
    "\n",
    "            # Terminate\n",
    "            if robot_pos == goal:\n",
    "                log.log(\"[TERMINAL] reached goal \", force=True)\n",
    "                break\n",
    "            if detected and dist <= detection.d0:\n",
    "                log.log(\"[TERMINAL] caught \", force=True)\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        # ----------------------\n",
    "        # NEW: Save \"whole game\" graphs\n",
    "        # ----------------------\n",
    "        out_dir = make_artifact_dir(cfg.seed)\n",
    "        save_whole_game_plots(out_dir, hist, detection)\n",
    "        log.log(f\"[PLOTS] saved to {out_dir}\", force=True)\n",
    "\n",
    "    log.log(\"[DONE]\", force=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af6190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
